{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b979f1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpprint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pprint\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwandb\u001b[39;00m\n",
      "File \u001b[0;32m/ceph/lfertig/miniconda3/envs/thesis-baselines/lib/python3.10/site-packages/pandas/__init__.py:26\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m         is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev,  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _err:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     _module \u001b[38;5;241m=\u001b[39m _err\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m/ceph/lfertig/miniconda3/envs/thesis-baselines/lib/python3.10/site-packages/pandas/compat/__init__.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressors\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     pa_version_under10p1,\n\u001b[1;32m     29\u001b[0m     pa_version_under11p0,\n\u001b[1;32m     30\u001b[0m     pa_version_under13p0,\n\u001b[1;32m     31\u001b[0m     pa_version_under14p0,\n\u001b[1;32m     32\u001b[0m     pa_version_under14p1,\n\u001b[1;32m     33\u001b[0m     pa_version_under16p0,\n\u001b[1;32m     34\u001b[0m     pa_version_under17p0,\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m F\n",
      "File \u001b[0;32m/ceph/lfertig/miniconda3/envs/thesis-baselines/lib/python3.10/site-packages/pandas/compat/pyarrow.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     _palv \u001b[38;5;241m=\u001b[39m Version(Version(pa\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mbase_version)\n\u001b[1;32m     11\u001b[0m     pa_version_under10p1 \u001b[38;5;241m=\u001b[39m _palv \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10.0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/ceph/lfertig/miniconda3/envs/thesis-baselines/lib/python3.10/site-packages/pyarrow/__init__.py:61\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m         __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (BuildInfo, RuntimeInfo, set_timezone_db_path,\n\u001b[1;32m     63\u001b[0m                          MonthDayNano, VersionInfo, cpp_build_info,\n\u001b[1;32m     64\u001b[0m                          cpp_version, cpp_version_info, runtime_info,\n\u001b[1;32m     65\u001b[0m                          cpu_count, set_cpu_count, enable_signal_handlers,\n\u001b[1;32m     66\u001b[0m                          io_thread_count, set_io_thread_count)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mshow_versions\u001b[39m():\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:404\u001b[0m, in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from peft import LoraConfig, TaskType\n",
    "\n",
    "from ppm.wandb_utils import fetch_experiments\n",
    "from ppm.models import NextEventPredictor\n",
    "from ppm.models.config import FreezeConfig\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "os.chdir(project_root)\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "entity = os.environ.get(\"ENTITY\")\n",
    "project = os.environ.get(\"PROJECT\")\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"project_root in sys.path:\", project_root in sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d407aeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_csv = \"/ceph/lfertig/Thesis/notebook/llm-peft-ppm/notebooks/csv\"\n",
    "output_dir_plots = \"/ceph/lfertig/Thesis/notebook/llm-peft-ppm/notebooks/plots\"\n",
    "os.makedirs(output_dir_csv, exist_ok=True)\n",
    "os.makedirs(output_dir_plots, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adf8acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all lines pandas\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    \"figure.figsize\": (6, 4),          \n",
    "    \"font.size\": 10,                   \n",
    "    \"axes.labelsize\": 10,              \n",
    "    \"axes.titlesize\": 10,              \n",
    "    \"legend.fontsize\": 9,              \n",
    "    \"xtick.labelsize\": 9,              \n",
    "    \"ytick.labelsize\": 9,\n",
    "    \"lines.linewidth\": 1.5,            \n",
    "    \"lines.markersize\": 5,             \n",
    "    \"axes.grid\": True,                 \n",
    "    \"grid.linestyle\": \"--\",\n",
    "    \"grid.linewidth\": 0.5,\n",
    "    \"legend.frameon\": False,           \n",
    "    \"pdf.fonttype\": 42,                \n",
    "    \"ps.fonttype\": 42,\n",
    "    \"savefig.bbox\": \"tight\",           \n",
    "    \"savefig.dpi\": 300,                \n",
    "})\n",
    "\n",
    "colors = [\n",
    "    \"#9467bd\",\n",
    "    \"#2ca02c\",\n",
    "    \"#bcbd22\",\n",
    "    \"#7f7f7f\",\n",
    "    \"#e377c2\",\n",
    "    \"#8c564b\",\n",
    "    \"#d62728\",\n",
    "    \"#17becf\",\n",
    "    \"#1f77b4\",\n",
    "    \"#ff7f0e\",\n",
    "]\n",
    "\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(color=colors)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45623d55",
   "metadata": {
    "title": "Experimental setup"
   },
   "outputs": [],
   "source": [
    "# - datasets' characteristics\n",
    "# - Architecture illustration\n",
    "\n",
    "# Datasets\n",
    "from skpm.event_logs import (\n",
    "    BPI12,\n",
    "    BPI17,\n",
    "    BPI20PrepaidTravelCosts,\n",
    "    BPI20TravelPermitData,\n",
    "    BPI20RequestForPayment,\n",
    ")\n",
    "\n",
    "logs = [\n",
    "    BPI12,\n",
    "    BPI17,\n",
    "    BPI20PrepaidTravelCosts,\n",
    "    BPI20TravelPermitData,\n",
    "    BPI20RequestForPayment,\n",
    "]\n",
    "\n",
    "properties = pd.DataFrame()\n",
    "for log in logs:\n",
    "    df = log().dataframe\n",
    "\n",
    "    p = {\n",
    "        \"Log\": log.__name__,\n",
    "        \"# cases\": len(df[\"case:concept:name\"].unique()),\n",
    "        \"# evt.\": len(df),\n",
    "        \"# act.\": len(df[\"concept:name\"].unique()),\n",
    "        \"tlmean\": df.groupby(\"case:concept:name\").size().mean(),\n",
    "        \"tlstd\": df.groupby(\"case:concept:name\").size().std(),\n",
    "    }\n",
    "\n",
    "    p = pd.DataFrame(p, index=[0])\n",
    "    properties = pd.concat([properties, p], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923906ee",
   "metadata": {
    "title": "Datasets' characteristics"
   },
   "outputs": [],
   "source": [
    "properties['Trace length'] = properties.apply(\n",
    "    lambda row: f\"{row['tlmean']:.4f}±{row['tlstd']:.1f}\",\n",
    "    axis=1\n",
    ")\n",
    "properties = properties.drop(columns=[\"tlmean\", \"tlstd\"])\n",
    "log_props_path = os.path.join(output_dir_csv, \"log_properties.csv\")\n",
    "properties.sort_values(by=\"# evt.\").round(4).to_csv(log_props_path, index=False)\n",
    "print(\"Log properties:\")\n",
    "print(properties.sort_values(by=\"# evt.\").round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440f2ca",
   "metadata": {
    "title": "Architecture illustration"
   },
   "outputs": [],
   "source": [
    "\n",
    "rnn_example = NextEventPredictor(\n",
    "    embedding_size=32,\n",
    "    categorical_cols=[\"activity\"],\n",
    "    numerical_cols=[\"accumulated_time\"],\n",
    "    categorical_sizes={\n",
    "        \"activity\": 20,\n",
    "    },\n",
    "    categorical_targets=[\"activity\"],\n",
    "    numerical_targets=[\"remaining_time\"],\n",
    "    backbone_name=\"rnn\",\n",
    "    backbone_hidden_size=64,\n",
    "    backbone_n_layers=2,\n",
    "    padding_idx=0,\n",
    "    strategy=\"sum\",\n",
    "    backbone_pretrained=False,\n",
    "    backbone_finetuning=None,\n",
    "    backbone_type=\"lstm\",\n",
    "    device=\"cuda\",\n",
    ")\n",
    "pprint(rnn_example)\n",
    "\n",
    "fine_tuning = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=2,\n",
    "    lora_alpha=4,\n",
    "    use_rslora=True,\n",
    ")\n",
    "\n",
    "# NOTE: you must set the enviroment variable HF_TOKEN on your local machine to access models from the huggingface hub\n",
    "qwen_input_size = 896\n",
    "qwen_example = NextEventPredictor(\n",
    "    embedding_size=qwen_input_size,\n",
    "    categorical_cols=[\"activity\"],\n",
    "    numerical_cols=[\"accumulated_time\"],\n",
    "    categorical_sizes={\n",
    "        \"activity\": 20,\n",
    "    },\n",
    "    categorical_targets=[\"activity\"],\n",
    "    numerical_targets=[\"remaining_time\", \"time_to_next_event\"],\n",
    "    backbone_name=\"Qwen/Qwen2.5-0.5B\",\n",
    "    backbone_pretrained=True,\n",
    "    backbone_hidden_size=qwen_input_size,\n",
    "    backbone_finetuning=fine_tuning,\n",
    "\n",
    "    backbone_type=None,\n",
    "    backbone_n_layers=None,\n",
    "    padding_idx=0,\n",
    "    strategy=\"sum\",\n",
    "    device=\"cuda\",\n",
    ")\n",
    "pprint(qwen_example)\n",
    "del qwen_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ca0c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_config = FreezeConfig(\n",
    "    ix_layers=[0, 1, 2],\n",
    "    module_path=\"layers\",\n",
    ")\n",
    "\n",
    "# NOTE: you must set the enviroment variable HF_TOKEN on your local machine to access models from the huggingface hub\n",
    "llama_input_size = 2048\n",
    "llama_example = NextEventPredictor(\n",
    "    embedding_size=llama_input_size,\n",
    "    categorical_cols=[\"activity\"],\n",
    "    numerical_cols=[\"accumulated_time\"],\n",
    "    categorical_sizes={\n",
    "        \"activity\": 20,\n",
    "    },\n",
    "    categorical_targets=[\"activity\"],\n",
    "    numerical_targets=[\"remaining_time\", \"time_to_next_event\"],\n",
    "    backbone_name=\"unsloth/Llama-3.2-1B\",\n",
    "    backbone_pretrained=True,\n",
    "    backbone_hidden_size=llama_input_size,\n",
    "    backbone_finetuning=freeze_config,\n",
    "\n",
    "    backbone_type=None,\n",
    "    backbone_n_layers=None,\n",
    "    padding_idx=0,\n",
    "    strategy=\"sum\",\n",
    "    device=\"cuda\",\n",
    ")\n",
    "pprint(llama_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448ab84",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Illustrating how the freezing fine-tuning works."
   },
   "outputs": [],
   "source": [
    "# In the `freeze_config` we pass as argument a list of `ix_layers` indicating which layer must be fine-tuned. In this case, we are fine-tuning the three first layers. All the other layers are frozen.\n",
    "\n",
    "LAYER_TO_TUNE = 0\n",
    "LAYER_TO_FREEZE = 3\n",
    "\n",
    "print(\"Tuning layer[0]:\")    \n",
    "for name, param in llama_example.backbone.layers[LAYER_TO_TUNE].named_parameters():\n",
    "    print(name, param.requires_grad)\n",
    "\n",
    "print(\"-\"*80 + \"\\nFreezing layer[3]:\")    \n",
    "for name, param in llama_example.backbone.layers[LAYER_TO_FREEZE].named_parameters():\n",
    "    print(name, param.requires_grad)\n",
    "\n",
    "del llama_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689e01c4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def map_setting(row):\n",
    "    ft = row[\"fine_tuning\"]\n",
    "    k  = row.get(\"few_shot_k\", None)\n",
    "    fl = row.get(\"freeze_layers\", None)\n",
    "    epochs = row.get(\"epochs\", None)\n",
    "\n",
    "    # LoRA Few-Shot\n",
    "    if ft == \"lora\" and k == 8:\n",
    "        return \"FewShot-LoRA\"\n",
    "\n",
    "    # LoRA Full\n",
    "    if ft == \"lora\" and pd.isna(k):\n",
    "        return \"LoRA\"\n",
    "\n",
    "    # Zero-Shot\n",
    "    if ft == \"freeze\" and epochs == 0:\n",
    "        return \"ZeroShot\"\n",
    "\n",
    "    # Freezing Few-Shot\n",
    "    if ft == \"freeze\" and k == 8:\n",
    "        return \"FewShot-Freezing\"\n",
    "\n",
    "    # Freezing standard\n",
    "    if ft == \"freeze\" and pd.isna(fl):\n",
    "        return \"Freezing\"\n",
    "\n",
    "    # Freezing layer configs\n",
    "    if ft == \"freeze\" and isinstance(fl, str):\n",
    "        fl_clean = fl.replace(\"[\",\"\").replace(\"]\",\"\").split()\n",
    "        return \"Freezing-\" + str(fl_clean)\n",
    "\n",
    "    return \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723b0b89",
   "metadata": {
    "title": "Checking best models"
   },
   "outputs": [],
   "source": [
    "\n",
    "BACKBONE_PROJECTS = {\n",
    "    \"majority\":         \"llm-peft-ppm_majority_baseline\",\n",
    "    \"rnn\":              \"llm-peft-ppm_rnn\",\n",
    "    \"transformer\":      \"llm-peft-ppm_transformer_baseline\",\n",
    "    \"tabpfn\":           \"llm-peft-ppm_tabpfn_baseline\",\n",
    "    \"gpt2\":             \"llm-peft-ppm_gpt2\",\n",
    "    \"gptneo-1b3\":       \"llm-peft-ppm_gpt-neo-1.3B\",\n",
    "    \"qwen25-05b\":       \"llm-peft-ppm_qwen25-05b\",\n",
    "    \"llama32-1b\":       \"llm-peft-ppm_llama32-1b\",\n",
    "    \"gemma-2-2b\":       \"llm-peft-ppm_gemma-2-2b\",\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for backbone, project_name in BACKBONE_PROJECTS.items():\n",
    "    df = fetch_experiments(project=project_name, entity=entity, include_metrics=True)\n",
    "    df[\"backbone\"] = backbone  # force consistent naming\n",
    "    df[\"project\"] = project_name\n",
    "    all_results.append(df)\n",
    "\n",
    "global_results = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "cols = [\n",
    "    \"id\",\n",
    "    \"log\",\n",
    "    \"backbone\",\n",
    "    \"project\",\n",
    "    \"fine_tuning\",\n",
    "    \"total_params\",\n",
    "    \"trainable_params\",\n",
    "    \"test_next_activity_acc\",\n",
    "    \"test_next_activity_loss\",\n",
    "    \"test_next_remaining_time_loss\",\n",
    "    \"test_next_time_to_next_event_loss\",\n",
    "    \"best_test_next_activity_acc\",\n",
    "    \"best_test_next_activity_loss\",\n",
    "    \"best_test_next_remaining_time_loss\",\n",
    "    \"best_test_next_time_to_next_event_loss\",\n",
    "    \"_runtime\",\n",
    "    \"mt_score\",\n",
    "]\n",
    "\n",
    "global_results_eval = global_results[\n",
    "    (~global_results[\"test_next_activity_acc\"].isna()) &\n",
    "    (~global_results[\"test_next_remaining_time_loss\"].isna()) &\n",
    "    (~global_results[\"test_next_time_to_next_event_loss\"].isna())\n",
    "].copy()\n",
    "\n",
    "# normalize metrics and build equal-weight multi-task score\n",
    "sc_acc = MinMaxScaler()\n",
    "sc_rt  = MinMaxScaler()\n",
    "sc_nt  = MinMaxScaler()\n",
    "\n",
    "global_results_eval[\"na_norm\"] = sc_acc.fit_transform(\n",
    "    global_results_eval[[\"test_next_activity_acc\"]]\n",
    ")\n",
    "# losses: lower is better -> negate before scaling\n",
    "global_results_eval[\"rt_norm\"] = sc_rt.fit_transform(\n",
    "    -global_results_eval[[\"test_next_remaining_time_loss\"]]\n",
    ")\n",
    "global_results_eval[\"nt_norm\"] = sc_nt.fit_transform(\n",
    "    -global_results_eval[[\"test_next_time_to_next_event_loss\"]]\n",
    ")\n",
    "\n",
    "global_results_eval[\"mt_score\"] = (\n",
    "    global_results_eval[\"na_norm\"] +\n",
    "    global_results_eval[\"rt_norm\"] +\n",
    "    global_results_eval[\"nt_norm\"]\n",
    ")\n",
    "\n",
    "best_scores = (\n",
    "    global_results_eval\n",
    "    .groupby([\"log\", \"backbone\"])[\"mt_score\"]\n",
    "    .max()\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "best = global_results_eval.merge(best_scores, on=[\"log\",\"backbone\",\"mt_score\"])\n",
    "best = best[cols].reset_index(drop=True)\n",
    "\n",
    "for log_name, df_log in best.groupby(\"log\"):\n",
    "    csv_path = os.path.join(\n",
    "        output_dir_csv,\n",
    "        f\"best_runs_mt_score_{log_name}.csv\"\n",
    "    )\n",
    "    df_log.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved best models for log={log_name} to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872e9b00",
   "metadata": {
    "title": "Multi-task models"
   },
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    \"best_test_next_activity_acc\",\n",
    "    \"best_test_next_remaining_time_loss\",\n",
    "    \"best_test_next_time_to_next_event_loss\",\n",
    "]\n",
    "\n",
    "# derive high-level setting labels (LoRA, FewShot-LoRA, Freezing, etc.)\n",
    "best = best.copy()\n",
    "best[\"Setting\"] = best.apply(map_setting, axis=1)\n",
    "\n",
    "tmp = best.reset_index(drop=True).copy()\n",
    "tmp = tmp[\n",
    "    [\"log\", \"backbone\", \"Setting\", \"fine_tuning\"]\n",
    "    + METRICS\n",
    "    + [\"total_params\", \"trainable_params\", \"_runtime\"]\n",
    "]\n",
    "\n",
    "# seconds to hours\n",
    "tmp[\"_runtime\"] = (tmp[\"_runtime\"] / 3600.0).round(3)\n",
    "\n",
    "# params formatting\n",
    "tmp[\"trainable_params\"] = (\n",
    "    (tmp.trainable_params / tmp.total_params) * 100\n",
    ").astype(int).astype(str) + \"%\"\n",
    "tmp[\"total_params\"] = tmp[\"total_params\"].apply(\n",
    "    lambda x: np.format_float_scientific(x, precision=1)\n",
    ")\n",
    "tmp[\"# params\\n(%trainable)\"] = (\n",
    "    tmp[\"total_params\"] + \"(\" + tmp[\"trainable_params\"] + \")\"\n",
    ")\n",
    "\n",
    "data = tmp.rename(\n",
    "    columns={\n",
    "        \"log\":                              \"Dataset\",\n",
    "        \"backbone\":                         \"Backbone\",\n",
    "        \"best_test_next_activity_acc\":      \"NA Acc.\",\n",
    "        \"best_test_next_remaining_time_loss\": \"RT MSE\",\n",
    "        \"best_test_next_time_to_next_event_loss\": \"NT MSE\",\n",
    "        \"total_params\":                     \"# params\\n(total)\",\n",
    "        \"trainable_params\":                 \"% params\\n(trainable)\",\n",
    "        \"_runtime\":                         \"Runtime (h)\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# pretty dataset names (optional – you already use this)\n",
    "data.Dataset = data.Dataset.map(\n",
    "    {\n",
    "        \"BPI12\":                            \"BPI12\",\n",
    "        \"BPI17\":                            \"BPI17\",\n",
    "        \"BPI20PrepaidTravelCosts\":          \"BPI20PTC\",\n",
    "        \"BPI20RequestForPayment\":           \"BPI20RfP\",\n",
    "        \"BPI20TravelPermitData\":            \"BPI20TPD\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# pretty backbone names (no [LoRA] etc!)\n",
    "data.Backbone = data.Backbone.map(\n",
    "    {\n",
    "        \"majority\":                         \"Majority\",\n",
    "        \"rnn\":                              \"RNN\",\n",
    "        \"transformer\":                      \"Transformer\",\n",
    "        \"tabpfn\":                           \"TabPFN\",\n",
    "        \"gpt2\":                             \"GPT2\",\n",
    "        \"gptneo-1b3\":                       \"GPT-Neo-1b3\",\n",
    "        \"qwen25-05b\":                       \"Qwen2.5-0.5b\",\n",
    "        \"llama32-1b\":                       \"Llama3.2-1b\",\n",
    "        \"gemma-2-2b\":                       \"Gemma-2-2b\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# you can optionally order Setting explicitly, e.g.:\n",
    "SETTING_ORDER = [\n",
    "    \"ZeroShot\",\n",
    "    \"LoRA\",\n",
    "    \"FewShot-LoRA\",\n",
    "    \"Freezing\",\n",
    "    \"FewShot-Freezing\",\n",
    "    \"Freezing-[-1]\",\n",
    "    \"Freezing-[-1, -2]\",\n",
    "    \"Freezing-[0]\",\n",
    "    \"Freezing-[0, 1]\",\n",
    "    \"Other\",\n",
    "]\n",
    "data[\"Setting\"] = pd.Categorical(data[\"Setting\"], categories=SETTING_ORDER, ordered=True)\n",
    "\n",
    "# final sort: by Dataset, Backbone, then Setting\n",
    "data = data.sort_values(by=[\"Dataset\", \"Backbone\", \"Setting\"]).reset_index(drop=True)\n",
    "\n",
    "csv_path = os.path.join(output_dir_csv, \"multi-task_benchmark_results.csv\")\n",
    "data.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b28cb5b",
   "metadata": {
    "title": "Experimental evaluation"
   },
   "outputs": [],
   "source": [
    "global_multi_task_results = global_results[\n",
    "    (~global_results[\"test_next_remaining_time_loss\"].isna()) &\n",
    "    (~global_results[\"test_next_time_to_next_event_loss\"].isna()) &\n",
    "    (~global_results[\"test_next_activity_loss\"].isna())\n",
    "].copy()\n",
    "\n",
    "BACKBONE_LABELS = {\n",
    "    \"gpt2\":                                 \"GPT2\",\n",
    "    \"gptneo-1b3\":                           \"GPT-Neo-1.3B\",\n",
    "    \"qwen25-05b\":                           \"Qwen-2.5-0.5B\",\n",
    "    \"llama32-1b\":                           \"Llama-3.2-1B\",\n",
    "    \"gemma-2-2b\":                           \"Gemma-2-2B\",\n",
    "}\n",
    "global_multi_task_results[\"Backbone\"] = global_multi_task_results[\"backbone\"].map(BACKBONE_LABELS)\n",
    "\n",
    "logs_to_plot = sorted(global_multi_task_results[\"log\"].unique())\n",
    "\n",
    "for log_name in logs_to_plot:\n",
    "    subset = global_multi_task_results[global_multi_task_results[\"log\"] == log_name]\n",
    "\n",
    "    if subset.empty:\n",
    "        continue\n",
    "\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(6, 6), sharex=True, dpi=100)\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=subset,\n",
    "        x=\"Backbone\",\n",
    "        y=\"test_next_activity_acc\",\n",
    "        ax=ax[0],\n",
    "    )\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=subset,\n",
    "        x=\"Backbone\",\n",
    "        y=\"test_next_remaining_time_loss\",\n",
    "        ax=ax[1],\n",
    "    )\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=subset,\n",
    "        x=\"Backbone\",\n",
    "        y=\"test_next_time_to_next_event_loss\",\n",
    "        ax=ax[2],\n",
    "    )\n",
    "\n",
    "    ax[0].set_ylabel(\"NA Acc.\")\n",
    "    ax[1].set_ylabel(\"RT MSE\")\n",
    "    ax[2].set_ylabel(\"NT MSE\")\n",
    "\n",
    "    for a in ax:\n",
    "        a.set_xlabel(\"\")\n",
    "        a.set_title(log_name)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    pdf_path = os.path.join(output_dir_plots, f\"loss_distribution_{log_name}.pdf\")\n",
    "    png_path = os.path.join(output_dir_plots, f\"loss_distribution_{log_name}.png\")\n",
    "    plt.savefig(pdf_path, dpi=300)\n",
    "    plt.savefig(png_path, dpi=300)\n",
    "\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecc6157",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_results_multi = global_results.copy()\n",
    "global_results_multi[\"Setting\"] = global_results_multi.apply(map_setting, axis=1)\n",
    "\n",
    "SETTING_ORDER = [\n",
    "    \"ZeroShot\",\n",
    "    \"LoRA\",\n",
    "    \"FewShot-LoRA\",\n",
    "    \"Freezing\",\n",
    "    \"FewShot-Freezing\",\n",
    "    \"Freezing-[0]\",\n",
    "    \"Freezing-[0,1]\",\n",
    "    \"Freezing-[-1]\",\n",
    "    \"Freezing-[-1,-2]\",\n",
    "]\n",
    "\n",
    "for backbone in sorted(global_results_multi[\"backbone\"].unique()):\n",
    "    subset = global_results_multi[global_results_multi[\"backbone\"] == backbone]\n",
    "\n",
    "    subset = subset[subset[\"Setting\"].notna()].copy()\n",
    "    if subset.empty:\n",
    "        continue\n",
    "        \n",
    "    setting_order_current = [\n",
    "        s for s in SETTING_ORDER if s in subset[\"Setting\"].unique()\n",
    "    ]\n",
    "    if not setting_order_current:\n",
    "        continue\n",
    "\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(7, 7), sharex=True, dpi=100)\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=subset,\n",
    "        x=\"Setting\",\n",
    "        y=\"test_next_activity_acc\",\n",
    "        order=setting_order_current,\n",
    "        ax=ax[0],\n",
    "    )\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=subset,\n",
    "        x=\"Setting\",\n",
    "        y=\"test_next_remaining_time_loss\",\n",
    "        order=setting_order_current,\n",
    "        ax=ax[1],\n",
    "    )\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=subset,\n",
    "        x=\"Setting\",\n",
    "        y=\"test_next_time_to_next_event_loss\",\n",
    "        order=setting_order_current,\n",
    "        ax=ax[2],\n",
    "    )\n",
    "\n",
    "    ax[0].set_ylabel(\"NA Acc.\")\n",
    "    ax[1].set_ylabel(\"RT MSE\")\n",
    "    ax[2].set_ylabel(\"NT MSE\")\n",
    "    ax[2].set_xticklabels(ax[2].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "    fig.suptitle(f\"Backbone: {backbone}\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    path = os.path.join(output_dir_plots, f\"loss_distribution_settings_comparison_{backbone}.pdf\")\n",
    "    plt.savefig(path, dpi=300)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b476c2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "param_summary = best[[\"log\", \"total_params\", \"trainable_params\"]].copy()\n",
    "\n",
    "param_summary[\"trainable_percent\"] = (\n",
    "    (param_summary[\"trainable_params\"] / param_summary[\"total_params\"]) * 100\n",
    ").astype(int).astype(str) + \"%\"\n",
    "\n",
    "param_summary[\"total_params_fmt\"] = param_summary[\"total_params\"].apply(\n",
    "    lambda x: np.format_float_scientific(x, precision=1)\n",
    ")\n",
    "\n",
    "param_summary[\"# params\\n(%trainable)\"] = (\n",
    "    param_summary[\"total_params_fmt\"] + \"(\" + param_summary[\"trainable_percent\"] + \")\"\n",
    ")\n",
    "\n",
    "csv_path = os.path.join(output_dir_csv, \"param_summary.csv\")\n",
    "param_summary.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"=== PARAMETER SUMMARY PER DATASET ===\")\n",
    "print(param_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebe26be",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Loss curves"
   },
   "outputs": [],
   "source": [
    "# multi-task models\n",
    "\n",
    "def fetch_single(\n",
    "    wandb_id: str,\n",
    "    targets=[\"na\", \"rt\", \"nt\"], \n",
    "    project_name: str | None = None,\n",
    "    entity: str | None = None,\n",
    "):\n",
    "    if isinstance(targets, str):\n",
    "        targets = [targets]\n",
    "\n",
    "    if project_name is None:\n",
    "        raise ValueError(\"fetch_single requires an explicit project_name (model project).\")\n",
    "    entity = os.environ[\"ENTITY\"] if entity is None else entity\n",
    "        \n",
    "    api = wandb.Api()\n",
    "    run = api.run(f\"{entity}/{project_name}/{wandb_id}\")\n",
    "    history = list(run.scan_history())\n",
    "\n",
    "    na_acc, na_loss, rt_loss, nt_loss = None, None, None, None\n",
    "\n",
    "    if \"rt\" in targets:\n",
    "        rt_loss = [row[\"test_next_remaining_time_loss\"] \n",
    "                   for row in history \n",
    "                   if \"test_next_remaining_time_loss\" in row]\n",
    "\n",
    "    if \"na\" in targets:\n",
    "        na_loss = [row[\"test_next_activity_loss\"] \n",
    "                   for row in history \n",
    "                   if \"test_next_activity_loss\" in row]\n",
    "        na_acc = [row[\"test_next_activity_acc\"] \n",
    "                  for row in history \n",
    "                  if \"test_next_activity_acc\" in row]\n",
    "\n",
    "    if \"nt\" in targets:\n",
    "        nt_loss = [row[\"test_next_time_to_next_event_loss\"] \n",
    "                   for row in history \n",
    "                   if \"test_next_time_to_next_event_loss\" in row]\n",
    "\n",
    "    return na_acc, na_loss, rt_loss, nt_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d76931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_csv_path = os.path.join(output_dir_csv, \"final_loss_curves_multitask.csv\")\n",
    "\n",
    "if os.path.exists(loss_csv_path):\n",
    "    losses = pd.read_csv(loss_csv_path)\n",
    "else:\n",
    "    losses_list = []\n",
    "    \n",
    "    # iterate over best multi-task runs (one per log × backbone)\n",
    "    for _, row in best.iterrows():\n",
    "        na_acc, na_loss, rt_loss, nt_loss = fetch_single(\n",
    "            row.id,\n",
    "            project_name=row.project,\n",
    "            targets=[\"na\", \"rt\", \"nt\"],\n",
    "        )\n",
    "        \n",
    "        # build per-epoch dataframe for this run\n",
    "        tmp = pd.DataFrame({\n",
    "            \"epoch\": range(len(na_loss)),\n",
    "            \"na_acc\": na_acc,\n",
    "            \"na_loss\": na_loss,\n",
    "            \"rt_loss\": rt_loss,\n",
    "            \"nt_loss\": nt_loss,\n",
    "        })\n",
    "        tmp[\"log\"] = row.log\n",
    "        tmp[\"backbone\"] = row.backbone\n",
    "\n",
    "        losses_list.append(tmp)\n",
    "    \n",
    "    losses = pd.concat(losses_list, axis=0, ignore_index=True)\n",
    "    \n",
    "    losses.to_csv(loss_csv_path, index=False)\n",
    "    \n",
    "# print a small sample into the log\n",
    "print(\"=== MULTI-TASK LOSS CURVES (head) ===\")\n",
    "print(losses.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd653b",
   "metadata": {
    "title": "Loss curve visualization (multi-task)"
   },
   "outputs": [],
   "source": [
    "LOGS_TO_PLOT = sorted(losses[\"log\"].unique())\n",
    "\n",
    "HUE_MAP = {\n",
    "    \"gpt2\":         \"GPT2\",\n",
    "    \"gptneo-1b3\":   \"GPT-Neo-1b3\",\n",
    "    \"qwen25-05b\":   \"Qwen2.5-0.5b\",\n",
    "    \"llama32-1b\":   \"Llama3.2-1b\",\n",
    "    \"gemma-2-2b\":   \"Gemma-2-2b\",\n",
    "}\n",
    "\n",
    "HUE_ORDER = [\n",
    "    \"GPT2\",\n",
    "    \"GPT-Neo-1b3\",\n",
    "    \"Qwen2.5-0.5b\",\n",
    "    \"Llama3.2-1b\",\n",
    "    \"Gemma-2-2b\",\n",
    "]\n",
    "\n",
    "# reshape into tidy format\n",
    "l = losses.melt(\n",
    "    id_vars=[\"log\", \"backbone\", \"epoch\"],\n",
    "    value_vars=[\"na_loss\", \"rt_loss\", \"nt_loss\"],\n",
    "    var_name=\"Loss\",\n",
    "    value_name=\"Value\",\n",
    ").dropna(subset=[\"Value\"])\n",
    "\n",
    "# map model names to readable labels\n",
    "l[\"Backbone\"] = l[\"backbone\"].map(HUE_MAP)\n",
    "l = l[l[\"Backbone\"].notna()]\n",
    "\n",
    "LOSS_LABELS = {\n",
    "    \"na_loss\": \"NA Loss\",\n",
    "    \"rt_loss\": \"RT Loss\",\n",
    "    \"nt_loss\": \"NT Loss\",\n",
    "}\n",
    "\n",
    "# prepare grid\n",
    "fig, axes = plt.subplots(3, len(LOGS_TO_PLOT), figsize=(4 * len(LOGS_TO_PLOT), 8), sharex=True)\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "for loss_name in [\"na_loss\", \"rt_loss\", \"nt_loss\"]:\n",
    "    for log_name in LOGS_TO_PLOT:\n",
    "        ax = next(axes_iter)\n",
    "        tmp = l[(l[\"Loss\"] == loss_name) & (l[\"log\"] == log_name)]\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=tmp,\n",
    "            x=\"epoch\",\n",
    "            y=\"Value\",\n",
    "            hue=\"Backbone\",\n",
    "            hue_order=[h for h in HUE_ORDER if h in tmp[\"Backbone\"].unique()],\n",
    "            ax=ax,\n",
    "            linewidth=2.0,\n",
    "        )\n",
    "\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(LOSS_LABELS[loss_name])\n",
    "        ax.set_title(log_name)\n",
    "\n",
    "        # legend handling\n",
    "        if (loss_name, log_name) != (\"nt_loss\", LOGS_TO_PLOT[-1]):\n",
    "            if ax.get_legend() is not None:\n",
    "                ax.get_legend().remove()\n",
    "        else:\n",
    "            leg = ax.legend(title=\"\", ncol=3, bbox_to_anchor=(1.05, -0.3))\n",
    "            for line in leg.get_lines():\n",
    "                line.set_linewidth(2.0)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_path = os.path.join(output_dir_plots, \"loss_curves_multitask.png\")\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "thesis-baselines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
