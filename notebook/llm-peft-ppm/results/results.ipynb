{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b979f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results\n",
      "project_root in sys.path: True\n",
      "ENTITY: privajet-university-of-mannheim\n",
      "WANDB_MODE: offline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import wandb\n",
    "\n",
    "project_root = os.path.abspath(\"..\")\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from ppm.wandb_utils import fetch_experiments\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ.setdefault(\"ENTITY\", \"privajet-university-of-mannheim\")\n",
    "entity = os.environ[\"ENTITY\"]\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"project_root in sys.path:\", project_root in sys.path)\n",
    "print(\"ENTITY:\", entity)\n",
    "print(\"WANDB_MODE:\", os.environ.get(\"WANDB_MODE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d407aeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_csv = \"/ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv\"\n",
    "output_dir_plots = \"/ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots\"\n",
    "os.makedirs(output_dir_csv, exist_ok=True)\n",
    "os.makedirs(output_dir_plots, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6adf8acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all lines pandas\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    \"figure.figsize\": (6, 4),          \n",
    "    \"font.size\": 10,                   \n",
    "    \"axes.labelsize\": 10,              \n",
    "    \"axes.titlesize\": 10,              \n",
    "    \"legend.fontsize\": 9,              \n",
    "    \"xtick.labelsize\": 9,              \n",
    "    \"ytick.labelsize\": 9,\n",
    "    \"lines.linewidth\": 1.5,            \n",
    "    \"lines.markersize\": 5,             \n",
    "    \"axes.grid\": True,                 \n",
    "    \"grid.linestyle\": \"--\",\n",
    "    \"grid.linewidth\": 0.5,\n",
    "    \"legend.frameon\": False,           \n",
    "    \"pdf.fonttype\": 42,                \n",
    "    \"ps.fonttype\": 42,\n",
    "    \"savefig.bbox\": \"tight\",           \n",
    "    \"savefig.dpi\": 300,                \n",
    "})\n",
    "\n",
    "colors = [\n",
    "    \"#9467bd\",\n",
    "    \"#2ca02c\",\n",
    "    \"#bcbd22\",\n",
    "    \"#7f7f7f\",\n",
    "    \"#e377c2\",\n",
    "    \"#8c564b\",\n",
    "    \"#d62728\",\n",
    "    \"#17becf\",\n",
    "    \"#1f77b4\",\n",
    "    \"#ff7f0e\",\n",
    "]\n",
    "\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(color=colors)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45623d55",
   "metadata": {
    "title": "Experimental setup"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log</th>\n",
       "      <th># cases</th>\n",
       "      <th># evt.</th>\n",
       "      <th># act.</th>\n",
       "      <th>Trace length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BPI20PrepaidTravelCosts</td>\n",
       "      <td>2099</td>\n",
       "      <td>18246</td>\n",
       "      <td>29</td>\n",
       "      <td>8.6927±2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BPI20RequestForPayment</td>\n",
       "      <td>6886</td>\n",
       "      <td>36796</td>\n",
       "      <td>19</td>\n",
       "      <td>5.3436±1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BPI20TravelPermitData</td>\n",
       "      <td>7065</td>\n",
       "      <td>86581</td>\n",
       "      <td>51</td>\n",
       "      <td>12.2549±5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>13087</td>\n",
       "      <td>262200</td>\n",
       "      <td>24</td>\n",
       "      <td>20.0351±19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BPI17</td>\n",
       "      <td>31509</td>\n",
       "      <td>1202267</td>\n",
       "      <td>26</td>\n",
       "      <td>38.1563±16.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Log  # cases   # evt.  # act.  Trace length\n",
       "0  BPI20PrepaidTravelCosts     2099    18246      29    8.6927±2.3\n",
       "1   BPI20RequestForPayment     6886    36796      19    5.3436±1.5\n",
       "2    BPI20TravelPermitData     7065    86581      51   12.2549±5.6\n",
       "3                    BPI12    13087   262200      24  20.0351±19.9\n",
       "4                    BPI17    31509  1202267      26  38.1563±16.7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties = pd.read_csv(\n",
    "    \"/ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/log_properties.csv\"\n",
    ")\n",
    "properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4440f2ca",
   "metadata": {
    "title": "Architecture illustration"
   },
   "outputs": [],
   "source": [
    "# from ppm.models import NextEventPredictor\n",
    "# import torch \n",
    "\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "# device = \"cuda\" if use_cuda else \"cpu\"\n",
    "# print(\"Using device:\", device)\n",
    "\n",
    "# rnn_example = NextEventPredictor(\n",
    "#     embedding_size=32,\n",
    "#     categorical_cols=[\"activity\"],\n",
    "#     numerical_cols=[\"accumulated_time\"],\n",
    "#     categorical_sizes={\"activity\": 20},\n",
    "#     categorical_targets=[\"activity\"],\n",
    "#     numerical_targets=[\"remaining_time\"],\n",
    "#     backbone_name=\"rnn\",\n",
    "#     backbone_hidden_size=64,\n",
    "#     backbone_n_layers=2,\n",
    "#     padding_idx=0,\n",
    "#     strategy=\"sum\",\n",
    "#     backbone_pretrained=False,\n",
    "#     backbone_finetuning=None,\n",
    "#     backbone_type=\"lstm\",\n",
    "#     device=device,\n",
    "# )\n",
    "# pprint(rnn_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "689e01c4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def _to_int_or_none(x):\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
    "        return None\n",
    "    try:\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def map_setting(row):\n",
    "    ft = row.get(\"fine_tuning\")\n",
    "    k_raw = row.get(\"few_shot_k\", None)\n",
    "    fl    = row.get(\"freeze_layers\", None)\n",
    "    ep_raw = row.get(\"epochs\", None)\n",
    "\n",
    "    k  = _to_int_or_none(k_raw)\n",
    "    ep = _to_int_or_none(ep_raw)\n",
    "\n",
    "    # LoRA Few-Shot\n",
    "    if ft == \"lora\" and k == 8:\n",
    "        return \"FewShot-LoRA\"\n",
    "\n",
    "    # LoRA Full\n",
    "    if ft == \"lora\" and k is None:\n",
    "        return \"LoRA\"\n",
    "\n",
    "    # Zero-Shot (epochs = 0)\n",
    "    if ft == \"freeze\" and ep == 0:\n",
    "        return \"ZeroShot\"\n",
    "\n",
    "    # Freezing Few-Shot\n",
    "    if ft == \"freeze\" and k == 8:\n",
    "        return \"FewShot-Freezing\"\n",
    "\n",
    "    # Freezing standard (keine freeze_layers angegeben)\n",
    "    if ft == \"freeze\" and fl in (None, \"\", [], ()):\n",
    "        return \"Freezing\"\n",
    "\n",
    "    # Freezing layer configs (z.B. -1, -2 / 0, 1)\n",
    "    if ft == \"freeze\" and fl is not None:\n",
    "        if isinstance(fl, (list, tuple)):\n",
    "            fl_clean = [_to_int_or_none(x) for x in fl]\n",
    "        else:\n",
    "            tokens = str(fl).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \" \").split()\n",
    "            fl_clean = [_to_int_or_none(x) for x in tokens]\n",
    "        fl_clean = [x for x in fl_clean if x is not None]\n",
    "        return f\"Freezing-{fl_clean}\"\n",
    "\n",
    "    return \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95ea8e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_path = os.path.join(output_dir_csv, \"global_results.pkl\")\n",
    "\n",
    "BACKBONE_PROJECTS = {\n",
    "    \"majority\":         \"llm-peft-ppm_majority_baseline\",\n",
    "    \"rnn\":              \"llm-peft-ppm_rnn\",\n",
    "    \"transformer\":      \"llm-peft-ppm_transformer_baseline\",\n",
    "    \"tabpfn\":           \"llm-peft-ppm_tabpfn_baseline\",\n",
    "    \"saprpt\":           \"llm-peft-ppm_saprpt_baseline\",\n",
    "    \"gpt2\":             \"llm-peft-ppm_gpt2\",\n",
    "    \"gptneo-1b3\":       \"llm-peft-ppm_gpt-neo-1.3B\",\n",
    "    \"qwen25-05b\":       \"llm-peft-ppm_qwen25-05b\",\n",
    "    \"llama32-1b\":       \"llm-peft-ppm_llama32-1b\",\n",
    "    \"gemma-2-2b\":       \"llm-peft-ppm_gemma-2-2b\",\n",
    "}\n",
    "\n",
    "def build_global_results():\n",
    "    all_results = []\n",
    "    for backbone, project_name in BACKBONE_PROJECTS.items():\n",
    "        df_tmp = fetch_experiments(project=project_name, entity=entity, include_metrics=True)\n",
    "        df_tmp[\"backbone\"] = backbone\n",
    "        df_tmp[\"project\"] = project_name\n",
    "        all_results.append(df_tmp)\n",
    "\n",
    "    gr = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "    safe_cols = [\n",
    "        \"id\", \"log\", \"backbone\", \"project\", \"fine_tuning\",\n",
    "        \"total_params\", \"trainable_params\", \"seed\", \"_runtime\", \"_timestamp\",\n",
    "        \"categorical_features\", \"categorical_targets\",\n",
    "        \"continuous_features\", \"continuous_targets\", \"device\", \"model\", \"name\",\n",
    "\n",
    "        \"test_next_activity_acc\",\n",
    "        \"test_next_activity_loss\",\n",
    "        \"test_next_remaining_time_loss\",\n",
    "        \"test_next_time_to_next_event_loss\",\n",
    "        \"best_test_next_activity_acc\",\n",
    "        \"best_test_next_activity_loss\",\n",
    "        \"best_test_next_remaining_time_loss\",\n",
    "        \"best_test_next_time_to_next_event_loss\",\n",
    "\n",
    "        \"batch_size\",\n",
    "        \"embedding_size\",\n",
    "        \"epochs\",\n",
    "        \"freeze_layers\",\n",
    "        \"grad_clip\",\n",
    "        \"hidden_size\",\n",
    "        \"lr\",\n",
    "        \"n_layers\",\n",
    "        \"rnn_type\",\n",
    "        \"strategy\",\n",
    "        \"weight_decay\",\n",
    "        \"lora_alpha\",\n",
    "        \"r\",\n",
    "        \"few_shot_k\",\n",
    "    ]\n",
    "\n",
    "    safe_cols = [c for c in safe_cols if c in gr.columns]\n",
    "    gr = gr[safe_cols]\n",
    "    return gr\n",
    "\n",
    "\n",
    "if os.path.exists(pkl_path):\n",
    "    try:\n",
    "        global_results = pd.read_pickle(pkl_path)\n",
    "    except Exception as e:\n",
    "        print(\"Fehler beim Laden von global_results.pkl, baue neu:\", repr(e))\n",
    "        global_results = build_global_results()\n",
    "        global_results.to_pickle(pkl_path)\n",
    "else:\n",
    "    global_results = build_global_results()\n",
    "    global_results.to_pickle(pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "723b0b89",
   "metadata": {
    "title": "Checking best models"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>log</th>\n",
       "      <th>backbone</th>\n",
       "      <th>project</th>\n",
       "      <th>fine_tuning</th>\n",
       "      <th>total_params</th>\n",
       "      <th>trainable_params</th>\n",
       "      <th>seed</th>\n",
       "      <th>_runtime</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>rnn_type</th>\n",
       "      <th>strategy</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>lora_alpha</th>\n",
       "      <th>r</th>\n",
       "      <th>few_shot_k</th>\n",
       "      <th>na_norm</th>\n",
       "      <th>rt_norm</th>\n",
       "      <th>nt_norm</th>\n",
       "      <th>mt_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pox3cg0n</td>\n",
       "      <td>BPI20PrepaidTravelCosts</td>\n",
       "      <td>majority</td>\n",
       "      <td>llm-peft-ppm_majority_baseline</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.127169</td>\n",
       "      <td>1.762725e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.130048</td>\n",
       "      <td>0.944634</td>\n",
       "      <td>0.940268</td>\n",
       "      <td>2.014950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whfyo8uu</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>majority</td>\n",
       "      <td>llm-peft-ppm_majority_baseline</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.600980</td>\n",
       "      <td>1.762849e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.252459</td>\n",
       "      <td>0.955857</td>\n",
       "      <td>0.943034</td>\n",
       "      <td>2.151350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oy378knj</td>\n",
       "      <td>BPI20TravelPermitData</td>\n",
       "      <td>majority</td>\n",
       "      <td>llm-peft-ppm_majority_baseline</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.808587</td>\n",
       "      <td>1.762850e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.087553</td>\n",
       "      <td>0.951915</td>\n",
       "      <td>0.961259</td>\n",
       "      <td>2.000726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3gchqw9a</td>\n",
       "      <td>BPI20RequestForPayment</td>\n",
       "      <td>majority</td>\n",
       "      <td>llm-peft-ppm_majority_baseline</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.075565</td>\n",
       "      <td>1.762850e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.188769</td>\n",
       "      <td>0.968881</td>\n",
       "      <td>0.975401</td>\n",
       "      <td>2.133051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cl197f3r</td>\n",
       "      <td>BPI17</td>\n",
       "      <td>majority</td>\n",
       "      <td>llm-peft-ppm_majority_baseline</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.474805</td>\n",
       "      <td>1.762850e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.170084</td>\n",
       "      <td>0.972109</td>\n",
       "      <td>0.963413</td>\n",
       "      <td>2.105607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vl6y1axq</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>rnn</td>\n",
       "      <td>llm-peft-ppm_rnn</td>\n",
       "      <td>None</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>64.434233</td>\n",
       "      <td>1.764079e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.898347</td>\n",
       "      <td>0.890896</td>\n",
       "      <td>0.959974</td>\n",
       "      <td>2.749217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wwv4s6ta</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>rnn</td>\n",
       "      <td>llm-peft-ppm_rnn</td>\n",
       "      <td>None</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>65.573150</td>\n",
       "      <td>1.764080e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.866947</td>\n",
       "      <td>0.885115</td>\n",
       "      <td>0.957324</td>\n",
       "      <td>2.709386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xjcuy92g</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>rnn</td>\n",
       "      <td>llm-peft-ppm_rnn</td>\n",
       "      <td>None</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>66.748843</td>\n",
       "      <td>1.764080e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.883914</td>\n",
       "      <td>0.882064</td>\n",
       "      <td>0.956911</td>\n",
       "      <td>2.722889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>r5ax60vx</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>rnn</td>\n",
       "      <td>llm-peft-ppm_rnn</td>\n",
       "      <td>None</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>60.193704</td>\n",
       "      <td>1.764080e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.876448</td>\n",
       "      <td>0.886308</td>\n",
       "      <td>0.959447</td>\n",
       "      <td>2.722204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s5xrzrsn</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>rnn</td>\n",
       "      <td>llm-peft-ppm_rnn</td>\n",
       "      <td>None</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>68.910497</td>\n",
       "      <td>1.764080e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.904076</td>\n",
       "      <td>0.889049</td>\n",
       "      <td>0.956773</td>\n",
       "      <td>2.749898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                      log  backbone  \\\n",
       "0  pox3cg0n  BPI20PrepaidTravelCosts  majority   \n",
       "1  whfyo8uu                    BPI12  majority   \n",
       "2  oy378knj    BPI20TravelPermitData  majority   \n",
       "3  3gchqw9a   BPI20RequestForPayment  majority   \n",
       "4  cl197f3r                    BPI17  majority   \n",
       "5  vl6y1axq                    BPI12       rnn   \n",
       "6  wwv4s6ta                    BPI12       rnn   \n",
       "7  xjcuy92g                    BPI12       rnn   \n",
       "8  r5ax60vx                    BPI12       rnn   \n",
       "9  s5xrzrsn                    BPI12       rnn   \n",
       "\n",
       "                          project fine_tuning  total_params  trainable_params  \\\n",
       "0  llm-peft-ppm_majority_baseline        None           1.0               1.0   \n",
       "1  llm-peft-ppm_majority_baseline        None           1.0               1.0   \n",
       "2  llm-peft-ppm_majority_baseline        None           1.0               1.0   \n",
       "3  llm-peft-ppm_majority_baseline        None           1.0               1.0   \n",
       "4  llm-peft-ppm_majority_baseline        None           1.0               1.0   \n",
       "5                llm-peft-ppm_rnn        None       88733.0           88733.0   \n",
       "6                llm-peft-ppm_rnn        None       88733.0           88733.0   \n",
       "7                llm-peft-ppm_rnn        None       88733.0           88733.0   \n",
       "8                llm-peft-ppm_rnn        None       88733.0           88733.0   \n",
       "9                llm-peft-ppm_rnn        None       88733.0           88733.0   \n",
       "\n",
       "   seed    _runtime    _timestamp  ... rnn_type strategy weight_decay  \\\n",
       "0   NaN    1.127169  1.762725e+09  ...     lstm   concat         0.10   \n",
       "1   NaN   35.600980  1.762849e+09  ...     lstm   concat         0.10   \n",
       "2   NaN   23.808587  1.762850e+09  ...     lstm   concat         0.10   \n",
       "3   NaN   21.075565  1.762850e+09  ...     lstm   concat         0.10   \n",
       "4   NaN  107.474805  1.762850e+09  ...     lstm   concat         0.10   \n",
       "5  41.0   64.434233  1.764079e+09  ...     lstm      sum         0.01   \n",
       "6  42.0   65.573150  1.764080e+09  ...     lstm      sum         0.01   \n",
       "7  43.0   66.748843  1.764080e+09  ...     lstm      sum         0.01   \n",
       "8  44.0   60.193704  1.764080e+09  ...     lstm      sum         0.01   \n",
       "9  45.0   68.910497  1.764080e+09  ...     lstm      sum         0.01   \n",
       "\n",
       "  lora_alpha     r few_shot_k   na_norm   rt_norm   nt_norm  mt_score  \n",
       "0       None  None        NaN  0.130048  0.944634  0.940268  2.014950  \n",
       "1       None  None        NaN  0.252459  0.955857  0.943034  2.151350  \n",
       "2       None  None        NaN  0.087553  0.951915  0.961259  2.000726  \n",
       "3       None  None        NaN  0.188769  0.968881  0.975401  2.133051  \n",
       "4       None  None        NaN  0.170084  0.972109  0.963413  2.105607  \n",
       "5       None  None        NaN  0.898347  0.890896  0.959974  2.749217  \n",
       "6       None  None        NaN  0.866947  0.885115  0.957324  2.709386  \n",
       "7       None  None        NaN  0.883914  0.882064  0.956911  2.722889  \n",
       "8       None  None        NaN  0.876448  0.886308  0.959447  2.722204  \n",
       "9       None  None        NaN  0.904076  0.889049  0.956773  2.749898  \n",
       "\n",
       "[10 rows x 43 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\n",
    "    \"id\",\n",
    "    \"log\",\n",
    "    \"backbone\",\n",
    "    \"project\",\n",
    "    \"fine_tuning\",\n",
    "    \"total_params\",\n",
    "    \"trainable_params\",\n",
    "    \"test_next_activity_acc\",\n",
    "    \"test_next_activity_loss\",\n",
    "    \"test_next_remaining_time_loss\",\n",
    "    \"test_next_time_to_next_event_loss\",\n",
    "    \"best_test_next_activity_acc\",\n",
    "    \"best_test_next_activity_loss\",\n",
    "    \"best_test_next_remaining_time_loss\",\n",
    "    \"best_test_next_time_to_next_event_loss\",\n",
    "    \"_runtime\",\n",
    "    \"mt_score\",\n",
    "]\n",
    "\n",
    "df = global_results.copy()\n",
    "df = df[\n",
    "    df[\"test_next_activity_acc\"].notna()\n",
    "    & df[\"test_next_remaining_time_loss\"].notna()\n",
    "    & df[\"test_next_time_to_next_event_loss\"].notna()\n",
    "].copy()\n",
    "\n",
    "sc_acc = MinMaxScaler()\n",
    "sc_rt  = MinMaxScaler()\n",
    "sc_nt  = MinMaxScaler()\n",
    "\n",
    "df[\"na_norm\"] = sc_acc.fit_transform(df[[\"test_next_activity_acc\"]])\n",
    "df[\"rt_norm\"] = sc_rt.fit_transform(-df[[\"test_next_remaining_time_loss\"]])\n",
    "df[\"nt_norm\"] = sc_nt.fit_transform(-df[[\"test_next_time_to_next_event_loss\"]])\n",
    "df[\"mt_score\"] = df[\"na_norm\"] + df[\"rt_norm\"] + df[\"nt_norm\"]\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1682d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    \"test_next_activity_acc\",\n",
    "    \"test_next_activity_loss\",\n",
    "    \"test_next_remaining_time_loss\",\n",
    "    \"test_next_time_to_next_event_loss\",\n",
    "    \"best_test_next_activity_acc\",\n",
    "    \"best_test_next_activity_loss\",\n",
    "    \"best_test_next_remaining_time_loss\",\n",
    "    \"best_test_next_time_to_next_event_loss\",\n",
    "]\n",
    "\n",
    "def agg_over_seeds(group: pd.DataFrame) -> pd.Series:\n",
    "    out = {\"n_runs\": len(group)}\n",
    "    if \"mt_score\" in group.columns:\n",
    "        out[\"mt_score_mean\"] = group[\"mt_score\"].mean()\n",
    "        out[\"mt_score_std\"] = group[\"mt_score\"].std()\n",
    "    if \"_runtime\" in group.columns:\n",
    "        out[\"_runtime_mean\"] = group[\"_runtime\"].mean()\n",
    "        out[\"_runtime_std\"]  = group[\"_runtime\"].std()\n",
    "    for m in METRICS:\n",
    "        if m in group.columns:\n",
    "            vals = group[m].dropna()\n",
    "            out[m + \"_mean\"] = vals.mean()\n",
    "            out[m + \"_std\"] = vals.std()\n",
    "    return pd.Series(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "889f1a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter columns: ['batch_size', 'embedding_size', 'epochs', 'freeze_layers', 'grad_clip', 'hidden_size', 'lr', 'n_layers', 'rnn_type', 'strategy', 'weight_decay']\n"
     ]
    }
   ],
   "source": [
    "majority = df[df[\"backbone\"] == \"majority\"].copy()\n",
    "majority_grouped = (\n",
    "    majority\n",
    "    .groupby([\"log\", \"backbone\"], dropna=False)\n",
    "    .apply(agg_over_seeds)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "BASELINE_BACKBONES = [\"rnn\", \"transformer\", \"tabpfn\", \"saprpt\"]\n",
    "baseline = df[df[\"backbone\"].isin(BASELINE_BACKBONES)].copy()\n",
    "\n",
    "NON_HP_COLS = set(\n",
    "    [\n",
    "        \"id\",\"log\",\"backbone\",\"categorical_features\",\"categorical_targets\",\n",
    "        \"continuous_features\",\"continuous_targets\",\"device\",\"project\",\"model\",\n",
    "        \"name\",\"fine_tuning\",\"lora_alpha\", \"r\", \"few_shot_k\", \"seed\",\"_runtime\",\"_timestamp\",\n",
    "        \"na_norm\",\"rt_norm\",\"nt_norm\",\"mt_score\",\"majority_stat\",\n",
    "        \"total_params\",\"trainable_params\",\"best_train_next_remaining_time_loss\",\n",
    "        \"_step\",\"best_train_next_activity_loss\",\"train_next_time_to_next_event_loss\",\n",
    "        \"best_train_next_time_to_next_event_loss\",\"train_next_activity_acc\",\n",
    "        \"train_next_activity_loss\",\"_wandb.runtime\",\"best_train_next_activity_acc\",\n",
    "        \"train_next_remaining_time_loss\",\"persist_model\",\"project_name\",\"wandb\",\n",
    "    ]\n",
    "    + METRICS\n",
    ")\n",
    "\n",
    "HP_COLS = [c for c in baseline.columns if c not in NON_HP_COLS]\n",
    "print(\"Hyperparameter columns:\", HP_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8c1e4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved baseline summary to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/baseline_best_settings_mean_std.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "      <th>backbone</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>embedding_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>freeze_layers</th>\n",
       "      <th>grad_clip</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>...</th>\n",
       "      <th>Backbone_pretty</th>\n",
       "      <th>test_next_activity_acc_mean_std</th>\n",
       "      <th>test_next_activity_loss_mean_std</th>\n",
       "      <th>test_next_remaining_time_loss_mean_std</th>\n",
       "      <th>test_next_time_to_next_event_loss_mean_std</th>\n",
       "      <th>best_test_next_activity_acc_mean_std</th>\n",
       "      <th>best_test_next_activity_loss_mean_std</th>\n",
       "      <th>best_test_next_remaining_time_loss_mean_std</th>\n",
       "      <th>best_test_next_time_to_next_event_loss_mean_std</th>\n",
       "      <th>Runtime (h)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>rnn</td>\n",
       "      <td>32.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7757 ± 0.0142</td>\n",
       "      <td>0.7689 ± 0.042</td>\n",
       "      <td>1.7738 ± 0.0889</td>\n",
       "      <td>1.3352 ± 0.0302</td>\n",
       "      <td>0.7799 ± 0.0095</td>\n",
       "      <td>0.758 ± 0.0285</td>\n",
       "      <td>1.7033 ± 0.1138</td>\n",
       "      <td>1.3205 ± 0.014</td>\n",
       "      <td>0.01943 ± 0.00025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>saprpt</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SAP-RPT</td>\n",
       "      <td>0.6294 ± 0.0121</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>2.1601 ± 0.1146</td>\n",
       "      <td>1.6706 ± 0.372</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.00500 ± 0.00093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>tabpfn</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>TabPFN</td>\n",
       "      <td>0.6364 ± 0.0153</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>2.2338 ± 0.0937</td>\n",
       "      <td>1.6877 ± 0.4063</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.12074 ± 0.00085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>transformer</td>\n",
       "      <td>32.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.7562 ± 0.0246</td>\n",
       "      <td>0.7139 ± 0.1077</td>\n",
       "      <td>2.8388 ± 0.1209</td>\n",
       "      <td>1.3671 ± 0.0495</td>\n",
       "      <td>0.7687 ± 0.016</td>\n",
       "      <td>0.6635 ± 0.0383</td>\n",
       "      <td>2.6204 ± 0.1508</td>\n",
       "      <td>1.3364 ± 0.016</td>\n",
       "      <td>0.00758 ± 0.00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BPI17</td>\n",
       "      <td>rnn</td>\n",
       "      <td>256.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8535 ± 0.0013</td>\n",
       "      <td>0.4193 ± 0.0068</td>\n",
       "      <td>0.6725 ± 0.0325</td>\n",
       "      <td>0.7629 ± 0.0159</td>\n",
       "      <td>0.8535 ± 0.0013</td>\n",
       "      <td>0.4193 ± 0.0068</td>\n",
       "      <td>0.6097 ± 0.0138</td>\n",
       "      <td>0.7629 ± 0.0159</td>\n",
       "      <td>0.04166 ± 0.00022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BPI17</td>\n",
       "      <td>saprpt</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SAP-RPT</td>\n",
       "      <td>0.6472 ± 0.0268</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>1.3056 ± 0.2773</td>\n",
       "      <td>1.1287 ± 0.1969</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.00440 ± 0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BPI17</td>\n",
       "      <td>tabpfn</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>TabPFN</td>\n",
       "      <td>0.669 ± 0.0194</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>1.6011 ± 0.0589</td>\n",
       "      <td>1.1679 ± 0.2366</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.12188 ± 0.00312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BPI17</td>\n",
       "      <td>transformer</td>\n",
       "      <td>32.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.8556 ± 0.0058</td>\n",
       "      <td>0.4141 ± 0.0136</td>\n",
       "      <td>1.156 ± 0.0803</td>\n",
       "      <td>0.8836 ± 0.0296</td>\n",
       "      <td>0.8596 ± 0.0024</td>\n",
       "      <td>0.407 ± 0.0142</td>\n",
       "      <td>1.1343 ± 0.0847</td>\n",
       "      <td>0.8433 ± 0.0401</td>\n",
       "      <td>0.01953 ± 0.00030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BPI20PrepaidTravelCosts</td>\n",
       "      <td>rnn</td>\n",
       "      <td>32.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7841 ± 0.0201</td>\n",
       "      <td>0.6578 ± 0.0553</td>\n",
       "      <td>1.0744 ± 0.0308</td>\n",
       "      <td>1.1906 ± 0.0485</td>\n",
       "      <td>0.7897 ± 0.0134</td>\n",
       "      <td>0.6549 ± 0.0492</td>\n",
       "      <td>0.9536 ± 0.027</td>\n",
       "      <td>1.1239 ± 0.0216</td>\n",
       "      <td>0.00316 ± 0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BPI20PrepaidTravelCosts</td>\n",
       "      <td>saprpt</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SAP-RPT</td>\n",
       "      <td>0.7646 ± 0.0054</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>1.041 ± 0.0605</td>\n",
       "      <td>1.0863 ± 0.2173</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.00448 ± 0.00007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BPI20PrepaidTravelCosts</td>\n",
       "      <td>tabpfn</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>TabPFN</td>\n",
       "      <td>0.6637 ± 0.0121</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>1.1278 ± 0.0716</td>\n",
       "      <td>1.1919 ± 0.2369</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.01156 ± 0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BPI20PrepaidTravelCosts</td>\n",
       "      <td>transformer</td>\n",
       "      <td>32.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.7821 ± 0.0061</td>\n",
       "      <td>0.6683 ± 0.0118</td>\n",
       "      <td>1.1187 ± 0.0865</td>\n",
       "      <td>1.237 ± 0.0537</td>\n",
       "      <td>0.7994 ± 0.0105</td>\n",
       "      <td>0.6527 ± 0.0174</td>\n",
       "      <td>0.9541 ± 0.0334</td>\n",
       "      <td>1.0688 ± 0.0115</td>\n",
       "      <td>0.00162 ± 0.00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BPI20RequestForPayment</td>\n",
       "      <td>rnn</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8777 ± 0.0234</td>\n",
       "      <td>0.3678 ± 0.0387</td>\n",
       "      <td>0.6826 ± 0.0213</td>\n",
       "      <td>0.7504 ± 0.0088</td>\n",
       "      <td>0.886 ± 0.0114</td>\n",
       "      <td>0.3647 ± 0.0376</td>\n",
       "      <td>0.6795 ± 0.0219</td>\n",
       "      <td>0.7444 ± 0.0072</td>\n",
       "      <td>0.00952 ± 0.00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BPI20RequestForPayment</td>\n",
       "      <td>saprpt</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SAP-RPT</td>\n",
       "      <td>0.7434 ± 0.0096</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.6383 ± 0.0255</td>\n",
       "      <td>0.7122 ± 0.0769</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.00452 ± 0.00017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BPI20RequestForPayment</td>\n",
       "      <td>tabpfn</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>TabPFN</td>\n",
       "      <td>0.7439 ± 0.0088</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.7148 ± 0.034</td>\n",
       "      <td>0.7176 ± 0.0719</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.03380 ± 0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BPI20RequestForPayment</td>\n",
       "      <td>transformer</td>\n",
       "      <td>32.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.8937 ± 0.0013</td>\n",
       "      <td>0.2719 ± 0.0012</td>\n",
       "      <td>0.6571 ± 0.009</td>\n",
       "      <td>0.7407 ± 0.0091</td>\n",
       "      <td>0.8954 ± 0.001</td>\n",
       "      <td>0.2639 ± 0.0012</td>\n",
       "      <td>0.6438 ± 0.0042</td>\n",
       "      <td>0.7187 ± 0.0037</td>\n",
       "      <td>0.00471 ± 0.00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BPI20TravelPermitData</td>\n",
       "      <td>rnn</td>\n",
       "      <td>32.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7302 ± 0.0031</td>\n",
       "      <td>0.9502 ± 0.014</td>\n",
       "      <td>1.0098 ± 0.0383</td>\n",
       "      <td>1.052 ± 0.0308</td>\n",
       "      <td>0.7314 ± 0.0026</td>\n",
       "      <td>0.9381 ± 0.0158</td>\n",
       "      <td>0.7632 ± 0.0399</td>\n",
       "      <td>0.8585 ± 0.0104</td>\n",
       "      <td>0.01171 ± 0.00011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BPI20TravelPermitData</td>\n",
       "      <td>saprpt</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SAP-RPT</td>\n",
       "      <td>0.6869 ± 0.013</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.9545 ± 0.0682</td>\n",
       "      <td>1.0428 ± 0.0515</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.00449 ± 0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BPI20TravelPermitData</td>\n",
       "      <td>tabpfn</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>TabPFN</td>\n",
       "      <td>0.6229 ± 0.012</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>1.091 ± 0.0495</td>\n",
       "      <td>1.1187 ± 0.0619</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.12027 ± 0.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BPI20TravelPermitData</td>\n",
       "      <td>transformer</td>\n",
       "      <td>16.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.7183 ± 0.0019</td>\n",
       "      <td>0.8407 ± 0.0143</td>\n",
       "      <td>0.8088 ± 0.0386</td>\n",
       "      <td>0.8717 ± 0.0301</td>\n",
       "      <td>0.7191 ± 0.0022</td>\n",
       "      <td>0.8369 ± 0.0147</td>\n",
       "      <td>0.7829 ± 0.0103</td>\n",
       "      <td>0.8473 ± 0.0178</td>\n",
       "      <td>0.00808 ± 0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>majority</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Majority</td>\n",
       "      <td>0.226 ± nan</td>\n",
       "      <td>6.2004 ± nan</td>\n",
       "      <td>1.3884 ± nan</td>\n",
       "      <td>1.5434 ± nan</td>\n",
       "      <td>0.226 ± nan</td>\n",
       "      <td>6.2004 ± nan</td>\n",
       "      <td>1.3884 ± nan</td>\n",
       "      <td>1.5434 ± nan</td>\n",
       "      <td>0.00989 ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BPI17</td>\n",
       "      <td>majority</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Majority</td>\n",
       "      <td>0.1523 ± nan</td>\n",
       "      <td>6.7908 ± nan</td>\n",
       "      <td>1.0963 ± nan</td>\n",
       "      <td>1.2125 ± nan</td>\n",
       "      <td>0.1523 ± nan</td>\n",
       "      <td>6.7908 ± nan</td>\n",
       "      <td>1.0963 ± nan</td>\n",
       "      <td>1.2125 ± nan</td>\n",
       "      <td>0.02985 ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BPI20PrepaidTravelCosts</td>\n",
       "      <td>majority</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Majority</td>\n",
       "      <td>0.1164 ± nan</td>\n",
       "      <td>7.0789 ± nan</td>\n",
       "      <td>1.5902 ± nan</td>\n",
       "      <td>1.5883 ± nan</td>\n",
       "      <td>0.1164 ± nan</td>\n",
       "      <td>7.0789 ± nan</td>\n",
       "      <td>1.5902 ± nan</td>\n",
       "      <td>1.5883 ± nan</td>\n",
       "      <td>0.00031 ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BPI20RequestForPayment</td>\n",
       "      <td>majority</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Majority</td>\n",
       "      <td>0.169 ± nan</td>\n",
       "      <td>6.6539 ± nan</td>\n",
       "      <td>1.1543 ± nan</td>\n",
       "      <td>1.0179 ± nan</td>\n",
       "      <td>0.169 ± nan</td>\n",
       "      <td>6.6539 ± nan</td>\n",
       "      <td>1.1543 ± nan</td>\n",
       "      <td>1.0179 ± nan</td>\n",
       "      <td>0.00585 ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BPI20TravelPermitData</td>\n",
       "      <td>majority</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Majority</td>\n",
       "      <td>0.0784 ± nan</td>\n",
       "      <td>7.3902 ± nan</td>\n",
       "      <td>1.4593 ± nan</td>\n",
       "      <td>1.2475 ± nan</td>\n",
       "      <td>0.0784 ± nan</td>\n",
       "      <td>7.3902 ± nan</td>\n",
       "      <td>1.4593 ± nan</td>\n",
       "      <td>1.2475 ± nan</td>\n",
       "      <td>0.00661 ± nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        log     backbone  batch_size  embedding_size  epochs  \\\n",
       "0                     BPI12          rnn        32.0           128.0    25.0   \n",
       "1                     BPI12       saprpt        16.0            16.0    25.0   \n",
       "2                     BPI12       tabpfn        16.0            16.0    25.0   \n",
       "3                     BPI12  transformer        32.0           128.0    10.0   \n",
       "4                     BPI17          rnn       256.0            32.0    25.0   \n",
       "5                     BPI17       saprpt        16.0            16.0    25.0   \n",
       "6                     BPI17       tabpfn        16.0            16.0    25.0   \n",
       "7                     BPI17  transformer        32.0           128.0    10.0   \n",
       "8   BPI20PrepaidTravelCosts          rnn        32.0           128.0    25.0   \n",
       "9   BPI20PrepaidTravelCosts       saprpt        16.0            16.0    25.0   \n",
       "10  BPI20PrepaidTravelCosts       tabpfn        16.0            16.0    25.0   \n",
       "11  BPI20PrepaidTravelCosts  transformer        32.0           128.0    10.0   \n",
       "12   BPI20RequestForPayment          rnn        32.0            32.0    25.0   \n",
       "13   BPI20RequestForPayment       saprpt        16.0            16.0    25.0   \n",
       "14   BPI20RequestForPayment       tabpfn        16.0            16.0    25.0   \n",
       "15   BPI20RequestForPayment  transformer        32.0           128.0    10.0   \n",
       "16    BPI20TravelPermitData          rnn        32.0           256.0    25.0   \n",
       "17    BPI20TravelPermitData       saprpt        16.0            16.0    25.0   \n",
       "18    BPI20TravelPermitData       tabpfn        16.0            16.0    25.0   \n",
       "19    BPI20TravelPermitData  transformer        16.0           256.0    10.0   \n",
       "20                    BPI12     majority         NaN             NaN     NaN   \n",
       "21                    BPI17     majority         NaN             NaN     NaN   \n",
       "22  BPI20PrepaidTravelCosts     majority         NaN             NaN     NaN   \n",
       "23   BPI20RequestForPayment     majority         NaN             NaN     NaN   \n",
       "24    BPI20TravelPermitData     majority         NaN             NaN     NaN   \n",
       "\n",
       "    freeze_layers  grad_clip  hidden_size       lr  n_layers  ...  \\\n",
       "0             NaN        5.0        512.0  0.00005       1.0  ...   \n",
       "1             NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "2             NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "3             NaN        5.0        128.0  0.00100       2.0  ...   \n",
       "4             NaN        5.0        512.0  0.00010       1.0  ...   \n",
       "5             NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "6             NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "7             NaN        5.0        128.0  0.00100       1.0  ...   \n",
       "8             NaN        5.0        128.0  0.00050       1.0  ...   \n",
       "9             NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "10            NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "11            NaN        5.0        128.0  0.00050       2.0  ...   \n",
       "12            NaN        5.0        512.0  0.00010       1.0  ...   \n",
       "13            NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "14            NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "15            NaN        5.0        128.0  0.00100       2.0  ...   \n",
       "16            NaN        5.0        128.0  0.00050       1.0  ...   \n",
       "17            NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "18            NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "19            NaN        5.0        256.0  0.00050       2.0  ...   \n",
       "20            NaN        NaN          NaN      NaN       NaN  ...   \n",
       "21            NaN        NaN          NaN      NaN       NaN  ...   \n",
       "22            NaN        NaN          NaN      NaN       NaN  ...   \n",
       "23            NaN        NaN          NaN      NaN       NaN  ...   \n",
       "24            NaN        NaN          NaN      NaN       NaN  ...   \n",
       "\n",
       "   Backbone_pretty test_next_activity_acc_mean_std  \\\n",
       "0              RNN                 0.7757 ± 0.0142   \n",
       "1          SAP-RPT                 0.6294 ± 0.0121   \n",
       "2           TabPFN                 0.6364 ± 0.0153   \n",
       "3      Transformer                 0.7562 ± 0.0246   \n",
       "4              RNN                 0.8535 ± 0.0013   \n",
       "5          SAP-RPT                 0.6472 ± 0.0268   \n",
       "6           TabPFN                  0.669 ± 0.0194   \n",
       "7      Transformer                 0.8556 ± 0.0058   \n",
       "8              RNN                 0.7841 ± 0.0201   \n",
       "9          SAP-RPT                 0.7646 ± 0.0054   \n",
       "10          TabPFN                 0.6637 ± 0.0121   \n",
       "11     Transformer                 0.7821 ± 0.0061   \n",
       "12             RNN                 0.8777 ± 0.0234   \n",
       "13         SAP-RPT                 0.7434 ± 0.0096   \n",
       "14          TabPFN                 0.7439 ± 0.0088   \n",
       "15     Transformer                 0.8937 ± 0.0013   \n",
       "16             RNN                 0.7302 ± 0.0031   \n",
       "17         SAP-RPT                  0.6869 ± 0.013   \n",
       "18          TabPFN                  0.6229 ± 0.012   \n",
       "19     Transformer                 0.7183 ± 0.0019   \n",
       "20        Majority                     0.226 ± nan   \n",
       "21        Majority                    0.1523 ± nan   \n",
       "22        Majority                    0.1164 ± nan   \n",
       "23        Majority                     0.169 ± nan   \n",
       "24        Majority                    0.0784 ± nan   \n",
       "\n",
       "    test_next_activity_loss_mean_std  test_next_remaining_time_loss_mean_std  \\\n",
       "0                     0.7689 ± 0.042                         1.7738 ± 0.0889   \n",
       "1                          nan ± nan                         2.1601 ± 0.1146   \n",
       "2                          nan ± nan                         2.2338 ± 0.0937   \n",
       "3                    0.7139 ± 0.1077                         2.8388 ± 0.1209   \n",
       "4                    0.4193 ± 0.0068                         0.6725 ± 0.0325   \n",
       "5                          nan ± nan                         1.3056 ± 0.2773   \n",
       "6                          nan ± nan                         1.6011 ± 0.0589   \n",
       "7                    0.4141 ± 0.0136                          1.156 ± 0.0803   \n",
       "8                    0.6578 ± 0.0553                         1.0744 ± 0.0308   \n",
       "9                          nan ± nan                          1.041 ± 0.0605   \n",
       "10                         nan ± nan                         1.1278 ± 0.0716   \n",
       "11                   0.6683 ± 0.0118                         1.1187 ± 0.0865   \n",
       "12                   0.3678 ± 0.0387                         0.6826 ± 0.0213   \n",
       "13                         nan ± nan                         0.6383 ± 0.0255   \n",
       "14                         nan ± nan                          0.7148 ± 0.034   \n",
       "15                   0.2719 ± 0.0012                          0.6571 ± 0.009   \n",
       "16                    0.9502 ± 0.014                         1.0098 ± 0.0383   \n",
       "17                         nan ± nan                         0.9545 ± 0.0682   \n",
       "18                         nan ± nan                          1.091 ± 0.0495   \n",
       "19                   0.8407 ± 0.0143                         0.8088 ± 0.0386   \n",
       "20                      6.2004 ± nan                            1.3884 ± nan   \n",
       "21                      6.7908 ± nan                            1.0963 ± nan   \n",
       "22                      7.0789 ± nan                            1.5902 ± nan   \n",
       "23                      6.6539 ± nan                            1.1543 ± nan   \n",
       "24                      7.3902 ± nan                            1.4593 ± nan   \n",
       "\n",
       "    test_next_time_to_next_event_loss_mean_std  \\\n",
       "0                              1.3352 ± 0.0302   \n",
       "1                               1.6706 ± 0.372   \n",
       "2                              1.6877 ± 0.4063   \n",
       "3                              1.3671 ± 0.0495   \n",
       "4                              0.7629 ± 0.0159   \n",
       "5                              1.1287 ± 0.1969   \n",
       "6                              1.1679 ± 0.2366   \n",
       "7                              0.8836 ± 0.0296   \n",
       "8                              1.1906 ± 0.0485   \n",
       "9                              1.0863 ± 0.2173   \n",
       "10                             1.1919 ± 0.2369   \n",
       "11                              1.237 ± 0.0537   \n",
       "12                             0.7504 ± 0.0088   \n",
       "13                             0.7122 ± 0.0769   \n",
       "14                             0.7176 ± 0.0719   \n",
       "15                             0.7407 ± 0.0091   \n",
       "16                              1.052 ± 0.0308   \n",
       "17                             1.0428 ± 0.0515   \n",
       "18                             1.1187 ± 0.0619   \n",
       "19                             0.8717 ± 0.0301   \n",
       "20                                1.5434 ± nan   \n",
       "21                                1.2125 ± nan   \n",
       "22                                1.5883 ± nan   \n",
       "23                                1.0179 ± nan   \n",
       "24                                1.2475 ± nan   \n",
       "\n",
       "    best_test_next_activity_acc_mean_std  \\\n",
       "0                        0.7799 ± 0.0095   \n",
       "1                              nan ± nan   \n",
       "2                              nan ± nan   \n",
       "3                         0.7687 ± 0.016   \n",
       "4                        0.8535 ± 0.0013   \n",
       "5                              nan ± nan   \n",
       "6                              nan ± nan   \n",
       "7                        0.8596 ± 0.0024   \n",
       "8                        0.7897 ± 0.0134   \n",
       "9                              nan ± nan   \n",
       "10                             nan ± nan   \n",
       "11                       0.7994 ± 0.0105   \n",
       "12                        0.886 ± 0.0114   \n",
       "13                             nan ± nan   \n",
       "14                             nan ± nan   \n",
       "15                        0.8954 ± 0.001   \n",
       "16                       0.7314 ± 0.0026   \n",
       "17                             nan ± nan   \n",
       "18                             nan ± nan   \n",
       "19                       0.7191 ± 0.0022   \n",
       "20                           0.226 ± nan   \n",
       "21                          0.1523 ± nan   \n",
       "22                          0.1164 ± nan   \n",
       "23                           0.169 ± nan   \n",
       "24                          0.0784 ± nan   \n",
       "\n",
       "    best_test_next_activity_loss_mean_std  \\\n",
       "0                          0.758 ± 0.0285   \n",
       "1                               nan ± nan   \n",
       "2                               nan ± nan   \n",
       "3                         0.6635 ± 0.0383   \n",
       "4                         0.4193 ± 0.0068   \n",
       "5                               nan ± nan   \n",
       "6                               nan ± nan   \n",
       "7                          0.407 ± 0.0142   \n",
       "8                         0.6549 ± 0.0492   \n",
       "9                               nan ± nan   \n",
       "10                              nan ± nan   \n",
       "11                        0.6527 ± 0.0174   \n",
       "12                        0.3647 ± 0.0376   \n",
       "13                              nan ± nan   \n",
       "14                              nan ± nan   \n",
       "15                        0.2639 ± 0.0012   \n",
       "16                        0.9381 ± 0.0158   \n",
       "17                              nan ± nan   \n",
       "18                              nan ± nan   \n",
       "19                        0.8369 ± 0.0147   \n",
       "20                           6.2004 ± nan   \n",
       "21                           6.7908 ± nan   \n",
       "22                           7.0789 ± nan   \n",
       "23                           6.6539 ± nan   \n",
       "24                           7.3902 ± nan   \n",
       "\n",
       "    best_test_next_remaining_time_loss_mean_std  \\\n",
       "0                               1.7033 ± 0.1138   \n",
       "1                                     nan ± nan   \n",
       "2                                     nan ± nan   \n",
       "3                               2.6204 ± 0.1508   \n",
       "4                               0.6097 ± 0.0138   \n",
       "5                                     nan ± nan   \n",
       "6                                     nan ± nan   \n",
       "7                               1.1343 ± 0.0847   \n",
       "8                                0.9536 ± 0.027   \n",
       "9                                     nan ± nan   \n",
       "10                                    nan ± nan   \n",
       "11                              0.9541 ± 0.0334   \n",
       "12                              0.6795 ± 0.0219   \n",
       "13                                    nan ± nan   \n",
       "14                                    nan ± nan   \n",
       "15                              0.6438 ± 0.0042   \n",
       "16                              0.7632 ± 0.0399   \n",
       "17                                    nan ± nan   \n",
       "18                                    nan ± nan   \n",
       "19                              0.7829 ± 0.0103   \n",
       "20                                 1.3884 ± nan   \n",
       "21                                 1.0963 ± nan   \n",
       "22                                 1.5902 ± nan   \n",
       "23                                 1.1543 ± nan   \n",
       "24                                 1.4593 ± nan   \n",
       "\n",
       "    best_test_next_time_to_next_event_loss_mean_std        Runtime (h)  \n",
       "0                                    1.3205 ± 0.014  0.01943 ± 0.00025  \n",
       "1                                         nan ± nan  0.00500 ± 0.00093  \n",
       "2                                         nan ± nan  0.12074 ± 0.00085  \n",
       "3                                    1.3364 ± 0.016  0.00758 ± 0.00008  \n",
       "4                                   0.7629 ± 0.0159  0.04166 ± 0.00022  \n",
       "5                                         nan ± nan  0.00440 ± 0.00005  \n",
       "6                                         nan ± nan  0.12188 ± 0.00312  \n",
       "7                                   0.8433 ± 0.0401  0.01953 ± 0.00030  \n",
       "8                                   1.1239 ± 0.0216  0.00316 ± 0.00005  \n",
       "9                                         nan ± nan  0.00448 ± 0.00007  \n",
       "10                                        nan ± nan  0.01156 ± 0.00005  \n",
       "11                                  1.0688 ± 0.0115  0.00162 ± 0.00003  \n",
       "12                                  0.7444 ± 0.0072  0.00952 ± 0.00008  \n",
       "13                                        nan ± nan  0.00452 ± 0.00017  \n",
       "14                                        nan ± nan  0.03380 ± 0.00020  \n",
       "15                                  0.7187 ± 0.0037  0.00471 ± 0.00003  \n",
       "16                                  0.8585 ± 0.0104  0.01171 ± 0.00011  \n",
       "17                                        nan ± nan  0.00449 ± 0.00005  \n",
       "18                                        nan ± nan  0.12027 ± 0.00014  \n",
       "19                                  0.8473 ± 0.0178  0.00808 ± 0.00005  \n",
       "20                                     1.5434 ± nan      0.00989 ± nan  \n",
       "21                                     1.2125 ± nan      0.02985 ± nan  \n",
       "22                                     1.5883 ± nan      0.00031 ± nan  \n",
       "23                                     1.0179 ± nan      0.00585 ± nan  \n",
       "24                                     1.2475 ± nan      0.00661 ± nan  \n",
       "\n",
       "[25 rows x 43 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_cols = [\"log\", \"backbone\"] + HP_COLS\n",
    "\n",
    "baseline_grouped = (\n",
    "    baseline\n",
    "    .groupby(group_cols, dropna=False)\n",
    "    .apply(agg_over_seeds)   # deine Funktion von oben\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "score_col = \"mt_score_mean\"\n",
    "if score_col not in baseline_grouped.columns:\n",
    "    score_col = \"test_next_activity_acc_mean\"\n",
    "\n",
    "idx_best = (\n",
    "    baseline_grouped\n",
    "    .groupby([\"log\", \"backbone\"])[score_col]\n",
    "    .idxmax()\n",
    ")\n",
    "baseline_best = baseline_grouped.loc[idx_best].reset_index(drop=True)\n",
    "\n",
    "baseline_all = pd.concat([baseline_best, majority_grouped], ignore_index=True)\n",
    "\n",
    "DATASET_MAP = {\n",
    "    \"BPI12\": \"BPI12\",\n",
    "    \"BPI17\": \"BPI17\",\n",
    "    \"BPI20PrepaidTravelCosts\": \"BPI20PTC\",\n",
    "    \"BPI20RequestForPayment\": \"BPI20RfP\",\n",
    "    \"BPI20TravelPermitData\": \"BPI20TPD\",\n",
    "}\n",
    "BACKBONE_MAP = {\n",
    "    \"majority\": \"Majority\",\n",
    "    \"rnn\": \"RNN\",\n",
    "    \"transformer\": \"Transformer\",\n",
    "    \"tabpfn\": \"TabPFN\",\n",
    "    \"saprpt\": \"SAP-RPT\",\n",
    "}\n",
    "\n",
    "baseline_all[\"Dataset\"] = baseline_all[\"log\"].map(DATASET_MAP).fillna(baseline_all[\"log\"])\n",
    "baseline_all[\"Backbone_pretty\"] = baseline_all[\"backbone\"].map(BACKBONE_MAP).fillna(baseline_all[\"backbone\"])\n",
    "\n",
    "for m in METRICS:\n",
    "    mean_col = m + \"_mean\"\n",
    "    std_col  = m + \"_std\"\n",
    "    if mean_col in baseline_all.columns and std_col in baseline_all.columns:\n",
    "        baseline_all[m + \"_mean_std\"] = (\n",
    "            baseline_all[mean_col].round(4).astype(str)\n",
    "            + \" ± \"\n",
    "            + baseline_all[std_col].round(4).astype(str)\n",
    "        )\n",
    "        \n",
    "if \"_runtime_mean\" in baseline_all.columns:\n",
    "    baseline_all[\"runtime_mean_h\"] = baseline_all[\"_runtime_mean\"] / 3600.0\n",
    "if \"_runtime_std\" in baseline_all.columns:\n",
    "    baseline_all[\"runtime_std_h\"]  = baseline_all[\"_runtime_std\"]  / 3600.0\n",
    "\n",
    "if {\"runtime_mean_h\", \"runtime_std_h\"}.issubset(baseline_all.columns):\n",
    "    mean_str = baseline_all[\"runtime_mean_h\"].map(lambda x: f\"{x:.5f}\")\n",
    "    std_str  = baseline_all[\"runtime_std_h\"].map(lambda x: f\"{x:.5f}\")\n",
    "\n",
    "    baseline_all[\"Runtime (h)\"] = mean_str + \" ± \" + std_str\n",
    "    \n",
    "cols_to_drop = [\"_runtime_mean\", \"_runtime_std\", \"runtime_mean_h\", \"runtime_std_h\"]\n",
    "cols_to_drop = [c for c in cols_to_drop if c in baseline_all.columns]\n",
    "\n",
    "baseline_all = baseline_all.drop(columns=cols_to_drop)\n",
    "\n",
    "csv_path = os.path.join(output_dir_csv, \"baseline_best_settings_mean_std.csv\")\n",
    "baseline_all.to_csv(csv_path, index=False)\n",
    "print(\"Saved baseline summary to:\", csv_path)\n",
    "\n",
    "baseline_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "872e9b00",
   "metadata": {
    "title": "Multi-task models"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Hyperparameter columns: ['batch_size', 'embedding_size', 'epochs', 'freeze_layers', 'grad_clip', 'hidden_size', 'lr', 'n_layers', 'rnn_type', 'strategy', 'weight_decay', 'lora_alpha', 'r', 'few_shot_k']\n",
      "Saved LLM summary to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/llm_all_settings_by_method_mean_std.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "      <th>backbone</th>\n",
       "      <th>Setting</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>embedding_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>freeze_layers</th>\n",
       "      <th>grad_clip</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>...</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Backbone_pretty</th>\n",
       "      <th>test_next_activity_acc_mean_std</th>\n",
       "      <th>test_next_activity_loss_mean_std</th>\n",
       "      <th>test_next_remaining_time_loss_mean_std</th>\n",
       "      <th>test_next_time_to_next_event_loss_mean_std</th>\n",
       "      <th>best_test_next_activity_acc_mean_std</th>\n",
       "      <th>best_test_next_activity_loss_mean_std</th>\n",
       "      <th>best_test_next_remaining_time_loss_mean_std</th>\n",
       "      <th>best_test_next_time_to_next_event_loss_mean_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>FewShot-Freezing</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.0799 ± 0.0341</td>\n",
       "      <td>3.6757 ± 0.2217</td>\n",
       "      <td>1.712 ± 0.236</td>\n",
       "      <td>1.609 ± 0.0568</td>\n",
       "      <td>0.0876 ± 0.0281</td>\n",
       "      <td>3.4803 ± 0.1926</td>\n",
       "      <td>1.3363 ± 0.123</td>\n",
       "      <td>1.5519 ± 0.0226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>FewShot-LoRA</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.0751 ± 0.0496</td>\n",
       "      <td>4.1549 ± 0.8314</td>\n",
       "      <td>3.5247 ± 2.3271</td>\n",
       "      <td>2.502 ± 1.3303</td>\n",
       "      <td>0.0953 ± 0.0496</td>\n",
       "      <td>3.1654 ± 0.2169</td>\n",
       "      <td>1.4307 ± 0.2371</td>\n",
       "      <td>1.6082 ± 0.0677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.3912 ± 0.0314</td>\n",
       "      <td>1.4898 ± 0.0318</td>\n",
       "      <td>2.0048 ± 0.0841</td>\n",
       "      <td>1.5121 ± 0.0317</td>\n",
       "      <td>0.4028 ± 0.0211</td>\n",
       "      <td>1.4816 ± 0.0364</td>\n",
       "      <td>1.9842 ± 0.0928</td>\n",
       "      <td>1.4755 ± 0.0157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>Freezing-[-1, -2]</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>10</td>\n",
       "      <td>-1,-2</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.7409 ± 0.0644</td>\n",
       "      <td>0.7587 ± 0.1567</td>\n",
       "      <td>2.9607 ± 0.0668</td>\n",
       "      <td>1.407 ± 0.0574</td>\n",
       "      <td>0.7921 ± 0.0109</td>\n",
       "      <td>0.6666 ± 0.0472</td>\n",
       "      <td>2.1902 ± 0.1723</td>\n",
       "      <td>1.3602 ± 0.0079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>Freezing-[-1]</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.7481 ± 0.0678</td>\n",
       "      <td>0.8252 ± 0.3164</td>\n",
       "      <td>2.6484 ± 0.1867</td>\n",
       "      <td>1.4281 ± 0.0205</td>\n",
       "      <td>0.8007 ± 0.0061</td>\n",
       "      <td>0.6464 ± 0.0429</td>\n",
       "      <td>2.2036 ± 0.1755</td>\n",
       "      <td>1.3601 ± 0.0117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>Freezing-[0, 1]</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>10</td>\n",
       "      <td>0,1</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.7328 ± 0.0603</td>\n",
       "      <td>0.7753 ± 0.0927</td>\n",
       "      <td>2.413 ± 0.1309</td>\n",
       "      <td>1.3021 ± 0.0234</td>\n",
       "      <td>0.797 ± 0.0121</td>\n",
       "      <td>0.6983 ± 0.0244</td>\n",
       "      <td>2.3113 ± 0.1783</td>\n",
       "      <td>1.2989 ± 0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>Freezing-[0]</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.7857 ± 0.0103</td>\n",
       "      <td>0.729 ± 0.0074</td>\n",
       "      <td>2.4203 ± 0.1474</td>\n",
       "      <td>1.3369 ± 0.0233</td>\n",
       "      <td>0.7933 ± 0.0051</td>\n",
       "      <td>0.7206 ± 0.0217</td>\n",
       "      <td>2.2122 ± 0.0645</td>\n",
       "      <td>1.3219 ± 0.0238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>LoRA</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.625 ± 0.0467</td>\n",
       "      <td>1.1342 ± 0.1744</td>\n",
       "      <td>2.3835 ± 0.2465</td>\n",
       "      <td>1.4898 ± 0.0821</td>\n",
       "      <td>0.6512 ± 0.0557</td>\n",
       "      <td>1.0486 ± 0.1395</td>\n",
       "      <td>2.0852 ± 0.11</td>\n",
       "      <td>1.4166 ± 0.0593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>ZeroShot</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.0298 ± 0.0184</td>\n",
       "      <td>4.4444 ± 0.6145</td>\n",
       "      <td>4.3306 ± 3.2487</td>\n",
       "      <td>3.6357 ± 2.514</td>\n",
       "      <td>0.0298 ± 0.0184</td>\n",
       "      <td>4.4444 ± 0.6145</td>\n",
       "      <td>4.3306 ± 3.2487</td>\n",
       "      <td>3.6357 ± 2.514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>FewShot-Freezing</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>768</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.0372 ± 0.0315</td>\n",
       "      <td>3.5797 ± 0.3214</td>\n",
       "      <td>1.9015 ± 0.8402</td>\n",
       "      <td>1.6738 ± 0.0887</td>\n",
       "      <td>0.0387 ± 0.0323</td>\n",
       "      <td>3.5797 ± 0.3214</td>\n",
       "      <td>1.8622 ± 0.8651</td>\n",
       "      <td>1.5788 ± 0.0816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>FewShot-LoRA</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>768</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.066 ± 0.0435</td>\n",
       "      <td>3.7202 ± 0.3176</td>\n",
       "      <td>2.3615 ± 0.6155</td>\n",
       "      <td>1.8859 ± 0.3613</td>\n",
       "      <td>0.1164 ± 0.0438</td>\n",
       "      <td>3.2111 ± 0.0963</td>\n",
       "      <td>1.4217 ± 0.2947</td>\n",
       "      <td>1.5557 ± 0.0218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>768</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.4803 ± 0.0131</td>\n",
       "      <td>1.5799 ± 0.0667</td>\n",
       "      <td>2.4276 ± 0.1278</td>\n",
       "      <td>1.4812 ± 0.0203</td>\n",
       "      <td>0.4837 ± 0.0199</td>\n",
       "      <td>1.5797 ± 0.0667</td>\n",
       "      <td>2.2677 ± 0.0831</td>\n",
       "      <td>1.4791 ± 0.0194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Freezing-[-1, -2]</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>10</td>\n",
       "      <td>-1,-2</td>\n",
       "      <td>5</td>\n",
       "      <td>768</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.6947 ± 0.0256</td>\n",
       "      <td>0.9061 ± 0.057</td>\n",
       "      <td>2.6129 ± 0.1035</td>\n",
       "      <td>1.462 ± 0.0251</td>\n",
       "      <td>0.6954 ± 0.0242</td>\n",
       "      <td>0.9034 ± 0.0582</td>\n",
       "      <td>2.026 ± 0.1606</td>\n",
       "      <td>1.4404 ± 0.0239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Freezing-[-1]</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>768</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.6911 ± 0.0075</td>\n",
       "      <td>0.9258 ± 0.039</td>\n",
       "      <td>2.4571 ± 0.0836</td>\n",
       "      <td>1.4513 ± 0.0207</td>\n",
       "      <td>0.6911 ± 0.0075</td>\n",
       "      <td>0.9258 ± 0.039</td>\n",
       "      <td>2.0822 ± 0.1661</td>\n",
       "      <td>1.4288 ± 0.0158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Freezing-[0, 1]</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>10</td>\n",
       "      <td>0,1</td>\n",
       "      <td>5</td>\n",
       "      <td>768</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.7404 ± 0.0289</td>\n",
       "      <td>0.7458 ± 0.0581</td>\n",
       "      <td>2.4466 ± 0.0754</td>\n",
       "      <td>1.4039 ± 0.0141</td>\n",
       "      <td>0.7568 ± 0.0197</td>\n",
       "      <td>0.7256 ± 0.0445</td>\n",
       "      <td>2.1075 ± 0.1452</td>\n",
       "      <td>1.3891 ± 0.0152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      log    backbone            Setting  batch_size  embedding_size  epochs  \\\n",
       "0   BPI12  gemma-2-2b   FewShot-Freezing           8            2304      10   \n",
       "1   BPI12  gemma-2-2b       FewShot-LoRA           8            2304      10   \n",
       "2   BPI12  gemma-2-2b           Freezing           8            2304      10   \n",
       "3   BPI12  gemma-2-2b  Freezing-[-1, -2]           8            2304      10   \n",
       "4   BPI12  gemma-2-2b      Freezing-[-1]           8            2304      10   \n",
       "5   BPI12  gemma-2-2b    Freezing-[0, 1]           8            2304      10   \n",
       "6   BPI12  gemma-2-2b       Freezing-[0]           8            2304      10   \n",
       "7   BPI12  gemma-2-2b               LoRA           8            2304      10   \n",
       "8   BPI12  gemma-2-2b           ZeroShot           8            2304       0   \n",
       "9   BPI12        gpt2   FewShot-Freezing           8             768      10   \n",
       "10  BPI12        gpt2       FewShot-LoRA           8             768      10   \n",
       "11  BPI12        gpt2           Freezing           8             768      10   \n",
       "12  BPI12        gpt2  Freezing-[-1, -2]           8             768      10   \n",
       "13  BPI12        gpt2      Freezing-[-1]           8             768      10   \n",
       "14  BPI12        gpt2    Freezing-[0, 1]           8             768      10   \n",
       "\n",
       "   freeze_layers  grad_clip  hidden_size       lr  ...  Dataset  \\\n",
       "0            NaN          5         2304  0.00005  ...    BPI12   \n",
       "1            NaN          5         2304  0.00005  ...    BPI12   \n",
       "2            NaN          5         2304  0.00005  ...    BPI12   \n",
       "3          -1,-2          5         2304  0.00005  ...    BPI12   \n",
       "4             -1          5         2304  0.00005  ...    BPI12   \n",
       "5            0,1          5         2304  0.00005  ...    BPI12   \n",
       "6              0          5         2304  0.00005  ...    BPI12   \n",
       "7            NaN          5         2304  0.00005  ...    BPI12   \n",
       "8            NaN          5         2304  0.00005  ...    BPI12   \n",
       "9            NaN          5          768  0.00005  ...    BPI12   \n",
       "10           NaN          5          768  0.00005  ...    BPI12   \n",
       "11           NaN          5          768  0.00005  ...    BPI12   \n",
       "12         -1,-2          5          768  0.00005  ...    BPI12   \n",
       "13            -1          5          768  0.00005  ...    BPI12   \n",
       "14           0,1          5          768  0.00005  ...    BPI12   \n",
       "\n",
       "   Backbone_pretty test_next_activity_acc_mean_std  \\\n",
       "0       Gemma-2-2B                 0.0799 ± 0.0341   \n",
       "1       Gemma-2-2B                 0.0751 ± 0.0496   \n",
       "2       Gemma-2-2B                 0.3912 ± 0.0314   \n",
       "3       Gemma-2-2B                 0.7409 ± 0.0644   \n",
       "4       Gemma-2-2B                 0.7481 ± 0.0678   \n",
       "5       Gemma-2-2B                 0.7328 ± 0.0603   \n",
       "6       Gemma-2-2B                 0.7857 ± 0.0103   \n",
       "7       Gemma-2-2B                  0.625 ± 0.0467   \n",
       "8       Gemma-2-2B                 0.0298 ± 0.0184   \n",
       "9             GPT2                 0.0372 ± 0.0315   \n",
       "10            GPT2                  0.066 ± 0.0435   \n",
       "11            GPT2                 0.4803 ± 0.0131   \n",
       "12            GPT2                 0.6947 ± 0.0256   \n",
       "13            GPT2                 0.6911 ± 0.0075   \n",
       "14            GPT2                 0.7404 ± 0.0289   \n",
       "\n",
       "    test_next_activity_loss_mean_std  test_next_remaining_time_loss_mean_std  \\\n",
       "0                    3.6757 ± 0.2217                           1.712 ± 0.236   \n",
       "1                    4.1549 ± 0.8314                         3.5247 ± 2.3271   \n",
       "2                    1.4898 ± 0.0318                         2.0048 ± 0.0841   \n",
       "3                    0.7587 ± 0.1567                         2.9607 ± 0.0668   \n",
       "4                    0.8252 ± 0.3164                         2.6484 ± 0.1867   \n",
       "5                    0.7753 ± 0.0927                          2.413 ± 0.1309   \n",
       "6                     0.729 ± 0.0074                         2.4203 ± 0.1474   \n",
       "7                    1.1342 ± 0.1744                         2.3835 ± 0.2465   \n",
       "8                    4.4444 ± 0.6145                         4.3306 ± 3.2487   \n",
       "9                    3.5797 ± 0.3214                         1.9015 ± 0.8402   \n",
       "10                   3.7202 ± 0.3176                         2.3615 ± 0.6155   \n",
       "11                   1.5799 ± 0.0667                         2.4276 ± 0.1278   \n",
       "12                    0.9061 ± 0.057                         2.6129 ± 0.1035   \n",
       "13                    0.9258 ± 0.039                         2.4571 ± 0.0836   \n",
       "14                   0.7458 ± 0.0581                         2.4466 ± 0.0754   \n",
       "\n",
       "    test_next_time_to_next_event_loss_mean_std  \\\n",
       "0                               1.609 ± 0.0568   \n",
       "1                               2.502 ± 1.3303   \n",
       "2                              1.5121 ± 0.0317   \n",
       "3                               1.407 ± 0.0574   \n",
       "4                              1.4281 ± 0.0205   \n",
       "5                              1.3021 ± 0.0234   \n",
       "6                              1.3369 ± 0.0233   \n",
       "7                              1.4898 ± 0.0821   \n",
       "8                               3.6357 ± 2.514   \n",
       "9                              1.6738 ± 0.0887   \n",
       "10                             1.8859 ± 0.3613   \n",
       "11                             1.4812 ± 0.0203   \n",
       "12                              1.462 ± 0.0251   \n",
       "13                             1.4513 ± 0.0207   \n",
       "14                             1.4039 ± 0.0141   \n",
       "\n",
       "    best_test_next_activity_acc_mean_std  \\\n",
       "0                        0.0876 ± 0.0281   \n",
       "1                        0.0953 ± 0.0496   \n",
       "2                        0.4028 ± 0.0211   \n",
       "3                        0.7921 ± 0.0109   \n",
       "4                        0.8007 ± 0.0061   \n",
       "5                         0.797 ± 0.0121   \n",
       "6                        0.7933 ± 0.0051   \n",
       "7                        0.6512 ± 0.0557   \n",
       "8                        0.0298 ± 0.0184   \n",
       "9                        0.0387 ± 0.0323   \n",
       "10                       0.1164 ± 0.0438   \n",
       "11                       0.4837 ± 0.0199   \n",
       "12                       0.6954 ± 0.0242   \n",
       "13                       0.6911 ± 0.0075   \n",
       "14                       0.7568 ± 0.0197   \n",
       "\n",
       "    best_test_next_activity_loss_mean_std  \\\n",
       "0                         3.4803 ± 0.1926   \n",
       "1                         3.1654 ± 0.2169   \n",
       "2                         1.4816 ± 0.0364   \n",
       "3                         0.6666 ± 0.0472   \n",
       "4                         0.6464 ± 0.0429   \n",
       "5                         0.6983 ± 0.0244   \n",
       "6                         0.7206 ± 0.0217   \n",
       "7                         1.0486 ± 0.1395   \n",
       "8                         4.4444 ± 0.6145   \n",
       "9                         3.5797 ± 0.3214   \n",
       "10                        3.2111 ± 0.0963   \n",
       "11                        1.5797 ± 0.0667   \n",
       "12                        0.9034 ± 0.0582   \n",
       "13                         0.9258 ± 0.039   \n",
       "14                        0.7256 ± 0.0445   \n",
       "\n",
       "    best_test_next_remaining_time_loss_mean_std  \\\n",
       "0                                1.3363 ± 0.123   \n",
       "1                               1.4307 ± 0.2371   \n",
       "2                               1.9842 ± 0.0928   \n",
       "3                               2.1902 ± 0.1723   \n",
       "4                               2.2036 ± 0.1755   \n",
       "5                               2.3113 ± 0.1783   \n",
       "6                               2.2122 ± 0.0645   \n",
       "7                                 2.0852 ± 0.11   \n",
       "8                               4.3306 ± 3.2487   \n",
       "9                               1.8622 ± 0.8651   \n",
       "10                              1.4217 ± 0.2947   \n",
       "11                              2.2677 ± 0.0831   \n",
       "12                               2.026 ± 0.1606   \n",
       "13                              2.0822 ± 0.1661   \n",
       "14                              2.1075 ± 0.1452   \n",
       "\n",
       "    best_test_next_time_to_next_event_loss_mean_std  \n",
       "0                                   1.5519 ± 0.0226  \n",
       "1                                   1.6082 ± 0.0677  \n",
       "2                                   1.4755 ± 0.0157  \n",
       "3                                   1.3602 ± 0.0079  \n",
       "4                                   1.3601 ± 0.0117  \n",
       "5                                    1.2989 ± 0.019  \n",
       "6                                   1.3219 ± 0.0238  \n",
       "7                                   1.4166 ± 0.0593  \n",
       "8                                    3.6357 ± 2.514  \n",
       "9                                   1.5788 ± 0.0816  \n",
       "10                                  1.5557 ± 0.0218  \n",
       "11                                  1.4791 ± 0.0194  \n",
       "12                                  1.4404 ± 0.0239  \n",
       "13                                  1.4288 ± 0.0158  \n",
       "14                                  1.3891 ± 0.0152  \n",
       "\n",
       "[15 rows x 48 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM_BACKBONES = [\"gpt2\", \"gptneo-1b3\", \"qwen25-05b\", \"llama32-1b\", \"gemma-2-2b\"]\n",
    "\n",
    "llm = df[df[\"backbone\"].isin(LLM_BACKBONES)].copy()\n",
    "\n",
    "llm[\"Setting\"] = llm.apply(map_setting, axis=1)\n",
    "\n",
    "NON_HP_COLS_LLM = set(NON_HP_COLS)\n",
    "for col in [\"lora_alpha\", \"r\", \"few_shot_k\"]:\n",
    "    NON_HP_COLS_LLM.discard(col)\n",
    "NON_HP_COLS_LLM.add(\"Setting\")\n",
    "\n",
    "HP_COLS_LLM = [c for c in llm.columns if c not in NON_HP_COLS_LLM]\n",
    "print(\"LLM Hyperparameter columns:\", HP_COLS_LLM)\n",
    "\n",
    "group_cols_llm = [\"log\", \"backbone\", \"Setting\"] + HP_COLS_LLM\n",
    "\n",
    "llm_grouped = (\n",
    "    llm\n",
    "    .groupby(group_cols_llm, dropna=False)\n",
    "    .apply(agg_over_seeds)   # gleiche Funktion wie bei Baselines\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "score_col = \"mt_score_mean\"\n",
    "if score_col not in llm_grouped.columns:\n",
    "    score_col = \"test_next_activity_acc_mean\"\n",
    "\n",
    "idx_best_llm = (\n",
    "    llm_grouped\n",
    "    .groupby([\"log\", \"backbone\", \"Setting\"])[score_col]\n",
    "    .idxmax()\n",
    ")\n",
    "\n",
    "llm_all = llm_grouped.loc[idx_best_llm].reset_index(drop=True)\n",
    "\n",
    "BACKBONE_MAP_LLM = {\n",
    "    \"gpt2\":         \"GPT2\",\n",
    "    \"gptneo-1b3\":   \"GPT-Neo-1.3B\",\n",
    "    \"qwen25-05b\":   \"Qwen2.5-0.5B\",\n",
    "    \"llama32-1b\":   \"Llama3.2-1B\",\n",
    "    \"gemma-2-2b\":   \"Gemma-2-2B\",\n",
    "}\n",
    "\n",
    "llm_all[\"Dataset\"] = llm_all[\"log\"].map(DATASET_MAP).fillna(llm_all[\"log\"])\n",
    "llm_all[\"Backbone_pretty\"] = llm_all[\"backbone\"].map(BACKBONE_MAP_LLM).fillna(llm_all[\"backbone\"])\n",
    "\n",
    "for m in METRICS:\n",
    "    mean_col = m + \"_mean\"\n",
    "    std_col  = m + \"_std\"\n",
    "    if mean_col in llm_all.columns and std_col in llm_all.columns:\n",
    "        llm_all[m + \"_mean_std\"] = (\n",
    "            llm_all[mean_col].round(4).astype(str)\n",
    "            + \" ± \"\n",
    "            + llm_all[std_col].round(4).astype(str)\n",
    "        )\n",
    "\n",
    "csv_path = os.path.join(output_dir_csv, \"llm_all_settings_by_method_mean_std.csv\")\n",
    "llm_all.to_csv(csv_path, index=False)\n",
    "print(\"Saved LLM summary to:\", csv_path)\n",
    "\n",
    "llm_all.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6952eb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting\n",
      "Freezing-[-1, -2]    125\n",
      "Freezing-[0, 1]      125\n",
      "Freezing-[0]         125\n",
      "Freezing-[-1]        125\n",
      "Freezing             125\n",
      "ZeroShot             125\n",
      "FewShot-Freezing     125\n",
      "FewShot-LoRA         125\n",
      "LoRA                 125\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "llm[\"Setting\"] = llm.apply(map_setting, axis=1)\n",
    "print(llm[\"Setting\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83d95d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined multi-task table to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/multi_task_benchmark_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "      <th>backbone</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>embedding_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>freeze_layers</th>\n",
       "      <th>grad_clip</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>...</th>\n",
       "      <th>best_test_next_activity_loss_mean_std</th>\n",
       "      <th>best_test_next_remaining_time_loss_mean_std</th>\n",
       "      <th>best_test_next_time_to_next_event_loss_mean_std</th>\n",
       "      <th>Runtime (h)</th>\n",
       "      <th>Setting</th>\n",
       "      <th>lora_alpha</th>\n",
       "      <th>r</th>\n",
       "      <th>few_shot_k</th>\n",
       "      <th>_runtime_mean</th>\n",
       "      <th>_runtime_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gptneo-1b3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.3621 ± 0.3649</td>\n",
       "      <td>1.5616 ± 0.2029</td>\n",
       "      <td>1.6504 ± 0.1312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FewShot-Freezing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>261.450618</td>\n",
       "      <td>1.303503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gptneo-1b3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1159 ± 0.0594</td>\n",
       "      <td>1.4986 ± 0.4039</td>\n",
       "      <td>1.5639 ± 0.0325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FewShot-LoRA</td>\n",
       "      <td>512.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>282.320921</td>\n",
       "      <td>0.743075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gptneo-1b3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4783 ± 0.3746</td>\n",
       "      <td>2.2858 ± 0.1486</td>\n",
       "      <td>1.4952 ± 0.0342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1456.544923</td>\n",
       "      <td>3.664458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gptneo-1b3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1,-2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4508 ± 0.2137</td>\n",
       "      <td>2.3459 ± 0.1544</td>\n",
       "      <td>1.4892 ± 0.0518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freezing-[-1, -2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1612.276569</td>\n",
       "      <td>2.908845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gptneo-1b3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4897 ± 0.2106</td>\n",
       "      <td>2.3335 ± 0.0808</td>\n",
       "      <td>1.492 ± 0.0327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Freezing-[-1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1532.044665</td>\n",
       "      <td>3.586872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     log    backbone  batch_size  embedding_size  epochs freeze_layers  \\\n",
       "0  BPI12  gptneo-1b3         8.0          2048.0    10.0           NaN   \n",
       "1  BPI12  gptneo-1b3         8.0          2048.0    10.0           NaN   \n",
       "2  BPI12  gptneo-1b3         8.0          2048.0    10.0           NaN   \n",
       "3  BPI12  gptneo-1b3         8.0          2048.0    10.0         -1,-2   \n",
       "4  BPI12  gptneo-1b3         8.0          2048.0    10.0            -1   \n",
       "\n",
       "   grad_clip  hidden_size       lr  n_layers  ...  \\\n",
       "0        5.0       2048.0  0.00005       1.0  ...   \n",
       "1        5.0       2048.0  0.00005       1.0  ...   \n",
       "2        5.0       2048.0  0.00005       1.0  ...   \n",
       "3        5.0       2048.0  0.00005       1.0  ...   \n",
       "4        5.0       2048.0  0.00005       1.0  ...   \n",
       "\n",
       "  best_test_next_activity_loss_mean_std  \\\n",
       "0                       3.3621 ± 0.3649   \n",
       "1                       3.1159 ± 0.0594   \n",
       "2                       1.4783 ± 0.3746   \n",
       "3                       1.4508 ± 0.2137   \n",
       "4                       1.4897 ± 0.2106   \n",
       "\n",
       "  best_test_next_remaining_time_loss_mean_std  \\\n",
       "0                             1.5616 ± 0.2029   \n",
       "1                             1.4986 ± 0.4039   \n",
       "2                             2.2858 ± 0.1486   \n",
       "3                             2.3459 ± 0.1544   \n",
       "4                             2.3335 ± 0.0808   \n",
       "\n",
       "   best_test_next_time_to_next_event_loss_mean_std  Runtime (h)  \\\n",
       "0                                  1.6504 ± 0.1312          NaN   \n",
       "1                                  1.5639 ± 0.0325          NaN   \n",
       "2                                  1.4952 ± 0.0342          NaN   \n",
       "3                                  1.4892 ± 0.0518          NaN   \n",
       "4                                   1.492 ± 0.0327          NaN   \n",
       "\n",
       "             Setting  lora_alpha      r  few_shot_k  _runtime_mean  \\\n",
       "0   FewShot-Freezing         NaN    NaN         8.0     261.450618   \n",
       "1       FewShot-LoRA       512.0  256.0         8.0     282.320921   \n",
       "2           Freezing         NaN    NaN         NaN    1456.544923   \n",
       "3  Freezing-[-1, -2]         NaN    NaN         NaN    1612.276569   \n",
       "4      Freezing-[-1]         NaN    NaN         NaN    1532.044665   \n",
       "\n",
       "   _runtime_std  \n",
       "0      1.303503  \n",
       "1      0.743075  \n",
       "2      3.664458  \n",
       "3      2.908845  \n",
       "4      3.586872  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi = pd.concat([baseline_all, llm_all], ignore_index=True, sort=False)\n",
    "\n",
    "multi = (\n",
    "    multi\n",
    "    .sort_values([\"Dataset\", \"Backbone_pretty\", \"Setting\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "csv_path = os.path.join(output_dir_csv, \"multi_task_benchmark_results.csv\")\n",
    "multi.to_csv(csv_path, index=False)\n",
    "print(\"Saved combined multi-task table to:\", csv_path)\n",
    "\n",
    "multi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf5071f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     _runtime\n",
      "0    1.127169\n",
      "1   35.600980\n",
      "2   23.808587\n",
      "3   21.075565\n",
      "4  107.474805\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "df = global_results.copy()\n",
    "print(df[[\"_runtime\"]].head())\n",
    "print(df[\"_runtime\"].isna().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa585d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved per-log table for BPI12 to /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/multi_task_benchmark_results_BPI12.csv\n",
      "Saved per-log table for BPI17 to /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/multi_task_benchmark_results_BPI17.csv\n",
      "Saved per-log table for BPI20PrepaidTravelCosts to /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/multi_task_benchmark_results_BPI20PrepaidTravelCosts.csv\n",
      "Saved per-log table for BPI20RequestForPayment to /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/multi_task_benchmark_results_BPI20RequestForPayment.csv\n",
      "Saved per-log table for BPI20TravelPermitData to /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/multi_task_benchmark_results_BPI20TravelPermitData.csv\n"
     ]
    }
   ],
   "source": [
    "multi_path = os.path.join(output_dir_csv, \"multi_task_benchmark_results.csv\")\n",
    "multi = pd.read_csv(multi_path)\n",
    "\n",
    "for log_name, df_log in multi.groupby(\"log\"):\n",
    "    log_dir = os.path.join(output_dir_csv, \"per_dataset\", log_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    csv_path = os.path.join(log_dir, f\"multi_task_benchmark_results_{log_name}.csv\")\n",
    "    \n",
    "    df_log.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved per-log table for {log_name} to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0c13022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LLM methods table for log=BPI12, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/llm_methods_BPI12_gemma-2-2b.csv\n",
      "Saved LLM methods table for log=BPI12, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/llm_methods_BPI12_gpt2.csv\n",
      "Saved LLM methods table for log=BPI12, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/llm_methods_BPI12_gptneo-1b3.csv\n",
      "Saved LLM methods table for log=BPI12, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/llm_methods_BPI12_llama32-1b.csv\n",
      "Saved LLM methods table for log=BPI12, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/llm_methods_BPI12_qwen25-05b.csv\n",
      "Saved LLM methods table for log=BPI17, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/llm_methods_BPI17_gemma-2-2b.csv\n",
      "Saved LLM methods table for log=BPI17, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/llm_methods_BPI17_gpt2.csv\n",
      "Saved LLM methods table for log=BPI17, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/llm_methods_BPI17_gptneo-1b3.csv\n",
      "Saved LLM methods table for log=BPI17, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/llm_methods_BPI17_llama32-1b.csv\n",
      "Saved LLM methods table for log=BPI17, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/llm_methods_BPI17_qwen25-05b.csv\n",
      "Saved LLM methods table for log=BPI20PrepaidTravelCosts, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/llm_methods_BPI20PrepaidTravelCosts_gemma-2-2b.csv\n",
      "Saved LLM methods table for log=BPI20PrepaidTravelCosts, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/llm_methods_BPI20PrepaidTravelCosts_gpt2.csv\n",
      "Saved LLM methods table for log=BPI20PrepaidTravelCosts, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/llm_methods_BPI20PrepaidTravelCosts_gptneo-1b3.csv\n",
      "Saved LLM methods table for log=BPI20PrepaidTravelCosts, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/llm_methods_BPI20PrepaidTravelCosts_llama32-1b.csv\n",
      "Saved LLM methods table for log=BPI20PrepaidTravelCosts, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/llm_methods_BPI20PrepaidTravelCosts_qwen25-05b.csv\n",
      "Saved LLM methods table for log=BPI20RequestForPayment, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/llm_methods_BPI20RequestForPayment_gemma-2-2b.csv\n",
      "Saved LLM methods table for log=BPI20RequestForPayment, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/llm_methods_BPI20RequestForPayment_gpt2.csv\n",
      "Saved LLM methods table for log=BPI20RequestForPayment, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/llm_methods_BPI20RequestForPayment_gptneo-1b3.csv\n",
      "Saved LLM methods table for log=BPI20RequestForPayment, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/llm_methods_BPI20RequestForPayment_llama32-1b.csv\n",
      "Saved LLM methods table for log=BPI20RequestForPayment, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/llm_methods_BPI20RequestForPayment_qwen25-05b.csv\n",
      "Saved LLM methods table for log=BPI20TravelPermitData, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/llm_methods_BPI20TravelPermitData_gemma-2-2b.csv\n",
      "Saved LLM methods table for log=BPI20TravelPermitData, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/llm_methods_BPI20TravelPermitData_gpt2.csv\n",
      "Saved LLM methods table for log=BPI20TravelPermitData, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/llm_methods_BPI20TravelPermitData_gptneo-1b3.csv\n",
      "Saved LLM methods table for log=BPI20TravelPermitData, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/llm_methods_BPI20TravelPermitData_llama32-1b.csv\n",
      "Saved LLM methods table for log=BPI20TravelPermitData, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/llm_methods_BPI20TravelPermitData_qwen25-05b.csv\n"
     ]
    }
   ],
   "source": [
    "multi_path = os.path.join(output_dir_csv, \"multi_task_benchmark_results.csv\")\n",
    "multi = pd.read_csv(multi_path)\n",
    "\n",
    "LLM_BACKBONES = [\"gpt2\", \"gptneo-1b3\", \"qwen25-05b\", \"llama32-1b\", \"gemma-2-2b\"]\n",
    "\n",
    "llm_multi = multi[multi[\"backbone\"].isin(LLM_BACKBONES)].copy()\n",
    "\n",
    "for (log_name, backbone), df_sub in llm_multi.groupby([\"log\", \"backbone\"]):\n",
    "    log_dir = os.path.join(output_dir_csv, \"per_dataset\", log_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    csv_path = os.path.join(log_dir, f\"llm_methods_{log_name}_{backbone}.csv\")\n",
    "\n",
    "    df_sub.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved LLM methods table for log={log_name}, backbone={backbone} to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0b9f2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved baseline vs LoRA table for BPI12 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/baseline_vs_lora_multi_task_results_BPI12.csv\n",
      "Saved baseline vs LoRA table for BPI17 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/baseline_vs_lora_multi_task_results_BPI17.csv\n",
      "Saved baseline vs LoRA table for BPI20PrepaidTravelCosts to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/baseline_vs_lora_multi_task_results_BPI20PrepaidTravelCosts.csv\n",
      "Saved baseline vs LoRA table for BPI20RequestForPayment to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/baseline_vs_lora_multi_task_results_BPI20RequestForPayment.csv\n",
      "Saved baseline vs LoRA table for BPI20TravelPermitData to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/baseline_vs_lora_multi_task_results_BPI20TravelPermitData.csv\n"
     ]
    }
   ],
   "source": [
    "multi_path = os.path.join(output_dir_csv, \"multi_task_benchmark_results.csv\")\n",
    "multi = pd.read_csv(multi_path)\n",
    "\n",
    "BASELINE_BACKBONES = [\"majority\", \"rnn\", \"transformer\", \"tabpfn\", \"saprpt\"]\n",
    "\n",
    "mask_baseline = multi[\"backbone\"].isin(BASELINE_BACKBONES)\n",
    "mask_llm_lora = (~multi[\"backbone\"].isin(BASELINE_BACKBONES)) & (multi[\"Setting\"] == \"LoRA\")\n",
    "\n",
    "subset = multi[mask_baseline | mask_llm_lora].copy()\n",
    "\n",
    "for log_name, df_log in subset.groupby(\"log\"):\n",
    "\n",
    "    log_dir = os.path.join(output_dir_csv, \"per_dataset\", log_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    csv_path_log = os.path.join(log_dir, f\"baseline_vs_lora_multi_task_results_{log_name}.csv\")\n",
    "\n",
    "    df_log.to_csv(csv_path_log, index=False)\n",
    "    print(f\"Saved baseline vs LoRA table for {log_name} to: {csv_path_log}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cd2c47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detailed boxplot for log=BPI12, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_freezing_BPI12_gemma-2-2b.png\n",
      "Saved collapsed boxplot for log=BPI12, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_collapsed_BPI12_gemma-2-2b.png\n",
      "Saved detailed boxplot for log=BPI12, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_freezing_BPI12_gpt2.png\n",
      "Saved collapsed boxplot for log=BPI12, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_collapsed_BPI12_gpt2.png\n",
      "Saved detailed boxplot for log=BPI12, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_freezing_BPI12_gptneo-1b3.png\n",
      "Saved collapsed boxplot for log=BPI12, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_collapsed_BPI12_gptneo-1b3.png\n",
      "Saved detailed boxplot for log=BPI12, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_freezing_BPI12_llama32-1b.png\n",
      "Saved collapsed boxplot for log=BPI12, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_collapsed_BPI12_llama32-1b.png\n",
      "Saved detailed boxplot for log=BPI12, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_freezing_BPI12_qwen25-05b.png\n",
      "Saved collapsed boxplot for log=BPI12, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_collapsed_BPI12_qwen25-05b.png\n",
      "Saved detailed boxplot for log=BPI17, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_freezing_BPI17_gemma-2-2b.png\n",
      "Saved collapsed boxplot for log=BPI17, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_collapsed_BPI17_gemma-2-2b.png\n",
      "Saved detailed boxplot for log=BPI17, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_freezing_BPI17_gpt2.png\n",
      "Saved collapsed boxplot for log=BPI17, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_collapsed_BPI17_gpt2.png\n",
      "Saved detailed boxplot for log=BPI17, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_freezing_BPI17_gptneo-1b3.png\n",
      "Saved collapsed boxplot for log=BPI17, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_collapsed_BPI17_gptneo-1b3.png\n",
      "Saved detailed boxplot for log=BPI17, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_freezing_BPI17_llama32-1b.png\n",
      "Saved collapsed boxplot for log=BPI17, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_collapsed_BPI17_llama32-1b.png\n",
      "Saved detailed boxplot for log=BPI17, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_freezing_BPI17_qwen25-05b.png\n",
      "Saved collapsed boxplot for log=BPI17, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_collapsed_BPI17_qwen25-05b.png\n",
      "Saved detailed boxplot for log=BPI20PrepaidTravelCosts, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_freezing_BPI20PrepaidTravelCosts_gemma-2-2b.png\n",
      "Saved collapsed boxplot for log=BPI20PrepaidTravelCosts, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_collapsed_BPI20PrepaidTravelCosts_gemma-2-2b.png\n",
      "Saved detailed boxplot for log=BPI20PrepaidTravelCosts, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_freezing_BPI20PrepaidTravelCosts_gpt2.png\n",
      "Saved collapsed boxplot for log=BPI20PrepaidTravelCosts, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_collapsed_BPI20PrepaidTravelCosts_gpt2.png\n",
      "Saved detailed boxplot for log=BPI20PrepaidTravelCosts, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_freezing_BPI20PrepaidTravelCosts_gptneo-1b3.png\n",
      "Saved collapsed boxplot for log=BPI20PrepaidTravelCosts, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_collapsed_BPI20PrepaidTravelCosts_gptneo-1b3.png\n",
      "Saved detailed boxplot for log=BPI20PrepaidTravelCosts, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_freezing_BPI20PrepaidTravelCosts_llama32-1b.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved collapsed boxplot for log=BPI20PrepaidTravelCosts, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_collapsed_BPI20PrepaidTravelCosts_llama32-1b.png\n",
      "Saved detailed boxplot for log=BPI20PrepaidTravelCosts, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_freezing_BPI20PrepaidTravelCosts_qwen25-05b.png\n",
      "Saved collapsed boxplot for log=BPI20PrepaidTravelCosts, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_collapsed_BPI20PrepaidTravelCosts_qwen25-05b.png\n",
      "Saved detailed boxplot for log=BPI20RequestForPayment, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_freezing_BPI20RequestForPayment_gemma-2-2b.png\n",
      "Saved collapsed boxplot for log=BPI20RequestForPayment, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_collapsed_BPI20RequestForPayment_gemma-2-2b.png\n",
      "Saved detailed boxplot for log=BPI20RequestForPayment, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_freezing_BPI20RequestForPayment_gpt2.png\n",
      "Saved collapsed boxplot for log=BPI20RequestForPayment, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_collapsed_BPI20RequestForPayment_gpt2.png\n",
      "Saved detailed boxplot for log=BPI20RequestForPayment, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_freezing_BPI20RequestForPayment_gptneo-1b3.png\n",
      "Saved collapsed boxplot for log=BPI20RequestForPayment, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_collapsed_BPI20RequestForPayment_gptneo-1b3.png\n",
      "Saved detailed boxplot for log=BPI20RequestForPayment, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_freezing_BPI20RequestForPayment_llama32-1b.png\n",
      "Saved collapsed boxplot for log=BPI20RequestForPayment, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_collapsed_BPI20RequestForPayment_llama32-1b.png\n",
      "Saved detailed boxplot for log=BPI20RequestForPayment, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_freezing_BPI20RequestForPayment_qwen25-05b.png\n",
      "Saved collapsed boxplot for log=BPI20RequestForPayment, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_collapsed_BPI20RequestForPayment_qwen25-05b.png\n",
      "Saved detailed boxplot for log=BPI20TravelPermitData, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_freezing_BPI20TravelPermitData_gemma-2-2b.png\n",
      "Saved collapsed boxplot for log=BPI20TravelPermitData, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_collapsed_BPI20TravelPermitData_gemma-2-2b.png\n",
      "Saved detailed boxplot for log=BPI20TravelPermitData, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_freezing_BPI20TravelPermitData_gpt2.png\n",
      "Saved collapsed boxplot for log=BPI20TravelPermitData, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_collapsed_BPI20TravelPermitData_gpt2.png\n",
      "Saved detailed boxplot for log=BPI20TravelPermitData, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_freezing_BPI20TravelPermitData_gptneo-1b3.png\n",
      "Saved collapsed boxplot for log=BPI20TravelPermitData, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_collapsed_BPI20TravelPermitData_gptneo-1b3.png\n",
      "Saved detailed boxplot for log=BPI20TravelPermitData, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_freezing_BPI20TravelPermitData_llama32-1b.png\n",
      "Saved collapsed boxplot for log=BPI20TravelPermitData, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_collapsed_BPI20TravelPermitData_llama32-1b.png\n",
      "Saved detailed boxplot for log=BPI20TravelPermitData, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_freezing_BPI20TravelPermitData_qwen25-05b.png\n",
      "Saved collapsed boxplot for log=BPI20TravelPermitData, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_collapsed_BPI20TravelPermitData_qwen25-05b.png\n"
     ]
    }
   ],
   "source": [
    "LLM_BACKBONES = [\"gpt2\", \"gptneo-1b3\", \"qwen25-05b\", \"llama32-1b\", \"gemma-2-2b\"]\n",
    "\n",
    "llm = df[df[\"backbone\"].isin(LLM_BACKBONES)].copy()\n",
    "llm[\"Setting\"] = llm.apply(map_setting, axis=1)\n",
    "\n",
    "def collapse_setting_for_main(setting: str) -> str:\n",
    "    if isinstance(setting, str) and setting.startswith(\"Freezing-[\"):\n",
    "        return \"Freezing\"   # -1, 0, 0,1, -1,-2 zusammengefasst\n",
    "    return setting\n",
    "\n",
    "llm[\"Setting_main\"] = llm[\"Setting\"].apply(collapse_setting_for_main)\n",
    "\n",
    "plots_base_dir = \"/ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset\"\n",
    "\n",
    "SETTING_ORDER_FULL = [\n",
    "    \"ZeroShot\",\n",
    "    \"LoRA\",\n",
    "    \"FewShot-LoRA\",\n",
    "    \"Freezing\",\n",
    "    \"Freezing-[-1]\",\n",
    "    \"Freezing-[0]\",\n",
    "    \"Freezing-[0, 1]\",\n",
    "    \"Freezing-[-1, -2]\",\n",
    "    \"FewShot-Freezing\",\n",
    "]\n",
    "\n",
    "SETTING_ORDER_MAIN = [\n",
    "    \"ZeroShot\",\n",
    "    \"LoRA\",\n",
    "    \"FewShot-LoRA\",\n",
    "    \"Freezing\",\n",
    "    \"FewShot-Freezing\",\n",
    "]\n",
    "\n",
    "PLOTS = [\n",
    "    (\"test_next_activity_acc\",           \"NA Acc.\"),\n",
    "    (\"test_next_remaining_time_loss\",    \"RT MSE\"),\n",
    "    (\"test_next_time_to_next_event_loss\",\"NT MSE\"),\n",
    "]\n",
    "\n",
    "for log_name, df_log in llm.groupby(\"log\"):\n",
    "    log_dir = os.path.join(plots_base_dir, log_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    for backbone, df_b in df_log.groupby(\"backbone\"):\n",
    "\n",
    "        settings_full = [s for s in SETTING_ORDER_FULL if s in df_b[\"Setting\"].unique()]\n",
    "        if settings_full:\n",
    "            fig, axes = plt.subplots(3, 1, figsize=(8, 9), sharex=True)\n",
    "\n",
    "            for ax, (metric, ylabel) in zip(axes, PLOTS):\n",
    "                sns.boxplot(\n",
    "                    data=df_b,\n",
    "                    x=\"Setting\",\n",
    "                    y=metric,\n",
    "                    order=settings_full,\n",
    "                    ax=ax,\n",
    "                )\n",
    "                ax.set_ylabel(ylabel)\n",
    "                ax.set_xticks(range(len(settings_full)))\n",
    "                ax.set_xticklabels(settings_full, rotation=45, ha=\"right\")\n",
    "\n",
    "            axes[-1].set_xlabel(\"Fine-tuning method (detailed)\")\n",
    "\n",
    "            fig.suptitle(f\"{log_name} – {backbone} (all Freezing variants)\", fontsize=12)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            out_path = os.path.join(log_dir, f\"llm_methods_boxplot_freezing_{log_name}_{backbone}.png\")\n",
    "            plt.savefig(out_path, dpi=300)\n",
    "            plt.close(fig)\n",
    "\n",
    "            print(f\"Saved detailed boxplot for log={log_name}, backbone={backbone} to: {out_path}\")\n",
    "\n",
    "        settings_main = [s for s in SETTING_ORDER_MAIN if s in df_b[\"Setting_main\"].unique()]\n",
    "        if settings_main:\n",
    "            fig, axes = plt.subplots(3, 1, figsize=(8, 9), sharex=True)\n",
    "\n",
    "            for ax, (metric, ylabel) in zip(axes, PLOTS):\n",
    "                sns.boxplot(\n",
    "                    data=df_b,\n",
    "                    x=\"Setting_main\",\n",
    "                    y=metric,\n",
    "                    order=settings_main,\n",
    "                    ax=ax,\n",
    "                )\n",
    "                ax.set_ylabel(ylabel)\n",
    "                ax.set_xticks(range(len(settings_main)))\n",
    "                ax.set_xticklabels(settings_main, rotation  =45, ha=\"right\")\n",
    "\n",
    "            axes[-1].set_xlabel(\"Fine-tuning method (collapsed)\")\n",
    "\n",
    "            fig.suptitle(f\"{log_name} – {backbone} (collapsed Freezing)\", fontsize=12)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            out_path = os.path.join(log_dir, f\"llm_methods_boxplot_collapsed_{log_name}_{backbone}.png\")\n",
    "            plt.savefig(out_path, dpi=300)\n",
    "            plt.close(fig)\n",
    "\n",
    "            print(f\"Saved collapsed boxplot for log={log_name}, backbone={backbone} to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77607748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LLM-backbone comparison for log=BPI12, setting=ZeroShot to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_backbones_boxplot_BPI12_ZeroShot.png\n",
      "Saved LLM-backbone comparison for log=BPI12, setting=LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_backbones_boxplot_BPI12_LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI12, setting=FewShot-LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_backbones_boxplot_BPI12_FewShot-LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI12, setting=Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_backbones_boxplot_BPI12_Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI12, setting=FewShot-Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_backbones_boxplot_BPI12_FewShot-Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI17, setting=ZeroShot to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_backbones_boxplot_BPI17_ZeroShot.png\n",
      "Saved LLM-backbone comparison for log=BPI17, setting=LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_backbones_boxplot_BPI17_LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI17, setting=FewShot-LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_backbones_boxplot_BPI17_FewShot-LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI17, setting=Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_backbones_boxplot_BPI17_Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI17, setting=FewShot-Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_backbones_boxplot_BPI17_FewShot-Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI20PrepaidTravelCosts, setting=ZeroShot to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_backbones_boxplot_BPI20PrepaidTravelCosts_ZeroShot.png\n",
      "Saved LLM-backbone comparison for log=BPI20PrepaidTravelCosts, setting=LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_backbones_boxplot_BPI20PrepaidTravelCosts_LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI20PrepaidTravelCosts, setting=FewShot-LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_backbones_boxplot_BPI20PrepaidTravelCosts_FewShot-LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI20PrepaidTravelCosts, setting=Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_backbones_boxplot_BPI20PrepaidTravelCosts_Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI20PrepaidTravelCosts, setting=FewShot-Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_backbones_boxplot_BPI20PrepaidTravelCosts_FewShot-Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI20RequestForPayment, setting=ZeroShot to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_backbones_boxplot_BPI20RequestForPayment_ZeroShot.png\n",
      "Saved LLM-backbone comparison for log=BPI20RequestForPayment, setting=LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_backbones_boxplot_BPI20RequestForPayment_LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI20RequestForPayment, setting=FewShot-LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_backbones_boxplot_BPI20RequestForPayment_FewShot-LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI20RequestForPayment, setting=Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_backbones_boxplot_BPI20RequestForPayment_Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI20RequestForPayment, setting=FewShot-Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_backbones_boxplot_BPI20RequestForPayment_FewShot-Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI20TravelPermitData, setting=ZeroShot to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_backbones_boxplot_BPI20TravelPermitData_ZeroShot.png\n",
      "Saved LLM-backbone comparison for log=BPI20TravelPermitData, setting=LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_backbones_boxplot_BPI20TravelPermitData_LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI20TravelPermitData, setting=FewShot-LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_backbones_boxplot_BPI20TravelPermitData_FewShot-LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI20TravelPermitData, setting=Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_backbones_boxplot_BPI20TravelPermitData_Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI20TravelPermitData, setting=FewShot-Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_backbones_boxplot_BPI20TravelPermitData_FewShot-Freezing.png\n"
     ]
    }
   ],
   "source": [
    "LLM_BACKBONES = [\"gpt2\", \"gptneo-1b3\", \"qwen25-05b\", \"llama32-1b\", \"gemma-2-2b\"]\n",
    "\n",
    "llm = df[df[\"backbone\"].isin(LLM_BACKBONES)].copy()\n",
    "llm[\"Setting\"] = llm.apply(map_setting, axis=1)\n",
    "\n",
    "def collapse_setting_for_main(setting: str) -> str:\n",
    "    if isinstance(setting, str) and setting.startswith(\"Freezing-[\"):\n",
    "        return \"Freezing\"   # -1, 0, 0,1, -1,-2 zusammengefasst\n",
    "    return setting\n",
    "\n",
    "llm[\"Setting_main\"] = llm[\"Setting\"].apply(collapse_setting_for_main)\n",
    "\n",
    "# Hübsche Modellnamen\n",
    "BACKBONE_MAP_LLM = {\n",
    "    \"gpt2\":         \"GPT2\",\n",
    "    \"gptneo-1b3\":   \"GPT-Neo-1.3B\",\n",
    "    \"qwen25-05b\":   \"Qwen2.5-0.5B\",\n",
    "    \"llama32-1b\":   \"Llama3.2-1B\",\n",
    "    \"gemma-2-2b\":   \"Gemma-2-2B\",\n",
    "}\n",
    "llm[\"Backbone_pretty\"] = llm[\"backbone\"].map(BACKBONE_MAP_LLM).fillna(llm[\"backbone\"])\n",
    "\n",
    "plots_base_dir = \"/ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset\"\n",
    "\n",
    "MAIN_SETTING_ORDER = [\n",
    "    \"ZeroShot\",\n",
    "    \"LoRA\",\n",
    "    \"FewShot-LoRA\",\n",
    "    \"Freezing\",\n",
    "    \"FewShot-Freezing\",\n",
    "]\n",
    "\n",
    "PLOTS = [\n",
    "    (\"test_next_activity_acc\",           \"NA Acc.\"),\n",
    "    (\"test_next_remaining_time_loss\",    \"RT MSE\"),\n",
    "    (\"test_next_time_to_next_event_loss\",\"NT MSE\"),\n",
    "]\n",
    "\n",
    "for log_name, df_log in llm.groupby(\"log\"):\n",
    "    log_dir = os.path.join(plots_base_dir, log_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    for setting in MAIN_SETTING_ORDER:\n",
    "        df_s = df_log[df_log[\"Setting_main\"] == setting].copy()\n",
    "        if df_s.empty:\n",
    "            continue\n",
    "\n",
    "        backbone_order = [\n",
    "            BACKBONE_MAP_LLM[b]\n",
    "            for b in LLM_BACKBONES\n",
    "            if b in df_s[\"backbone\"].unique()\n",
    "        ]\n",
    "        if not backbone_order:\n",
    "            continue\n",
    "\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(8, 9), sharex=True)\n",
    "\n",
    "        for ax, (metric, ylabel) in zip(axes, PLOTS):\n",
    "            sns.boxplot(\n",
    "                data=df_s,\n",
    "                x=\"Backbone_pretty\",\n",
    "                y=metric,\n",
    "                order=backbone_order,\n",
    "                ax=ax,\n",
    "            )\n",
    "            ax.set_ylabel(ylabel)\n",
    "            ax.set_xticklabels(backbone_order, rotation=45, ha=\"right\")\n",
    "\n",
    "        axes[-1].set_xlabel(\"LLM backbone\")\n",
    "\n",
    "        fig.suptitle(f\"{log_name} – {setting}\", fontsize=12)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        out_path = os.path.join(\n",
    "            log_dir,\n",
    "            f\"llm_backbones_boxplot_{log_name}_{setting}.png\"\n",
    "        )\n",
    "        plt.savefig(out_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "\n",
    "        print(f\"Saved LLM-backbone comparison for log={log_name}, setting={setting} to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bda212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fetch_single(\n",
    "#     wandb_id: str,\n",
    "#     targets=[\"na\", \"rt\", \"nt\"],\n",
    "#     project_name: str | None = None,\n",
    "#     entity: str | None = None,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Holt die Verlaufskurven (pro Epoch) für einen einzelnen W&B-Run.\n",
    "#     Gibt (na_acc, na_loss, rt_loss, nt_loss) als Listen zurück.\n",
    "#     Fehlende Targets -> entsprechende Liste = None.\n",
    "#     \"\"\"\n",
    "#     if isinstance(targets, str):\n",
    "#         targets = [targets]\n",
    "\n",
    "#     if project_name is None:\n",
    "#         raise ValueError(\"fetch_single requires an explicit project_name.\")\n",
    "\n",
    "#     if entity is None:\n",
    "#         entity = os.environ.get(\"ENTITY\")\n",
    "#         if entity is None:\n",
    "#             raise ValueError(\"ENTITY not set and no entity passed to fetch_single().\")\n",
    "\n",
    "#     api = wandb.Api()\n",
    "#     run = api.run(f\"{entity}/{project_name}/{wandb_id}\")\n",
    "#     history = list(run.scan_history())\n",
    "\n",
    "#     na_acc, na_loss, rt_loss, nt_loss = None, None, None, None\n",
    "\n",
    "#     if \"rt\" in targets:\n",
    "#         rt_loss = [\n",
    "#             row[\"test_next_remaining_time_loss\"]\n",
    "#             for row in history\n",
    "#             if \"test_next_remaining_time_loss\" in row\n",
    "#         ]\n",
    "\n",
    "#     if \"na\" in targets:\n",
    "#         na_loss = [\n",
    "#             row[\"test_next_activity_loss\"]\n",
    "#             for row in history\n",
    "#             if \"test_next_activity_loss\" in row\n",
    "#         ]\n",
    "#         na_acc = [\n",
    "#             row[\"test_next_activity_acc\"]\n",
    "#             for row in history\n",
    "#             if \"test_next_activity_acc\" in row\n",
    "#         ]\n",
    "\n",
    "#     if \"nt\" in targets:\n",
    "#         nt_loss = [\n",
    "#             row[\"test_next_time_to_next_event_loss\"]\n",
    "#             for row in history\n",
    "#             if \"test_next_time_to_next_event_loss\" in row\n",
    "#         ]\n",
    "\n",
    "#     return na_acc, na_loss, rt_loss, nt_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d76931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_csv_path = os.path.join(output_dir_csv, \"final_loss_curves_multitask.csv\")\n",
    "\n",
    "# LLM_BACKBONES = [\"gpt2\", \"gptneo-1b3\", \"qwen25-05b\", \"llama32-1b\", \"gemma-2-2b\"]\n",
    "\n",
    "# if os.path.exists(loss_csv_path):\n",
    "#     losses = pd.read_csv(loss_csv_path)\n",
    "# else:\n",
    "#     df_llm = df[df[\"backbone\"].isin(LLM_BACKBONES)].copy()\n",
    "#     best_runs = (\n",
    "#         df_llm\n",
    "#         .sort_values(\"mt_score\", ascending=False)\n",
    "#         .groupby([\"log\", \"backbone\"], as_index=False)\n",
    "#         .head(1)  # bester Run je (log, backbone)\n",
    "#     )\n",
    "\n",
    "#     losses_list = []\n",
    "\n",
    "#     for _, row in best_runs.iterrows():\n",
    "#         na_acc, na_loss, rt_loss, nt_loss = fetch_single(\n",
    "#             row.id,\n",
    "#             project_name=row.project,\n",
    "#             targets=[\"na\", \"rt\", \"nt\"],\n",
    "#         )\n",
    "\n",
    "#         tmp = pd.DataFrame({\n",
    "#             \"epoch\": range(len(na_loss)),\n",
    "#             \"na_acc\": na_acc,\n",
    "#             \"na_loss\": na_loss,\n",
    "#             \"rt_loss\": rt_loss,\n",
    "#             \"nt_loss\": nt_loss,\n",
    "#         })\n",
    "#         tmp[\"log\"] = row.log\n",
    "#         tmp[\"backbone\"] = row.backbone\n",
    "#         losses_list.append(tmp)\n",
    "\n",
    "#     losses = pd.concat(losses_list, axis=0, ignore_index=True)\n",
    "#     losses.to_csv(loss_csv_path, index=False)\n",
    "\n",
    "# print(\"Loss curves shape:\", losses.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "becd653b",
   "metadata": {
    "title": "Loss curve visualization (multi-task)"
   },
   "outputs": [],
   "source": [
    "# LOGS_TO_PLOT = sorted(losses[\"log\"].unique())\n",
    "\n",
    "# HUE_MAP = {\n",
    "#     \"gpt2\":         \"GPT2\",\n",
    "#     \"gptneo-1b3\":   \"GPT-Neo-1.3B\",\n",
    "#     \"qwen25-05b\":   \"Qwen2.5-0.5B\",\n",
    "#     \"llama32-1b\":   \"Llama3.2-1B\",\n",
    "#     \"gemma-2-2b\":   \"Gemma-2-2B\",\n",
    "# }\n",
    "\n",
    "# HUE_ORDER = [\n",
    "#     \"GPT2\",\n",
    "#     \"GPT-Neo-1.3B\",\n",
    "#     \"Qwen2.5-0.5B\",\n",
    "#     \"Llama3.2-1B\",\n",
    "#     \"Gemma-2-2B\",\n",
    "# ]\n",
    "\n",
    "# l = losses.melt(\n",
    "#     id_vars=[\"log\", \"backbone\", \"epoch\"],\n",
    "#     value_vars=[\"na_loss\", \"rt_loss\", \"nt_loss\"],\n",
    "#     var_name=\"Loss\",\n",
    "#     value_name=\"Value\",\n",
    "# ).dropna(subset=[\"Value\"])\n",
    "\n",
    "# l[\"Backbone\"] = l[\"backbone\"].map(HUE_MAP)\n",
    "# l = l[l[\"Backbone\"].notna()]\n",
    "\n",
    "# LOSS_LABELS = {\n",
    "#     \"na_loss\": \"NA Loss\",\n",
    "#     \"rt_loss\": \"RT Loss\",\n",
    "#     \"nt_loss\": \"NT Loss\",\n",
    "# }\n",
    "\n",
    "# fig, axes = plt.subplots(\n",
    "#     3, len(LOGS_TO_PLOT),\n",
    "#     figsize=(4 * len(LOGS_TO_PLOT), 8),\n",
    "#     sharex=True\n",
    "# )\n",
    "# axes_iter = iter(axes.flatten())\n",
    "\n",
    "# legend_handles, legend_labels = None, None  # später für globale Legende\n",
    "\n",
    "# for loss_name in [\"na_loss\", \"rt_loss\", \"nt_loss\"]:\n",
    "#     for log_name in LOGS_TO_PLOT:\n",
    "#         ax = next(axes_iter)\n",
    "#         tmp = l[(l[\"Loss\"] == loss_name) & (l[\"log\"] == log_name)]\n",
    "\n",
    "#         sns.lineplot(\n",
    "#             data=tmp,\n",
    "#             x=\"epoch\",\n",
    "#             y=\"Value\",\n",
    "#             hue=\"Backbone\",\n",
    "#             hue_order=[h for h in HUE_ORDER if h in tmp[\"Backbone\"].unique()],\n",
    "#             ax=ax,\n",
    "#             linewidth=2.0,\n",
    "#         )\n",
    "\n",
    "#         ax.set_xlabel(\"Epoch\")\n",
    "#         ax.set_ylabel(LOSS_LABELS[loss_name])\n",
    "#         ax.set_title(log_name)\n",
    "\n",
    "#         # Legend nur einmal abgreifen\n",
    "#         leg = ax.get_legend()\n",
    "#         if leg is not None:\n",
    "#             handles, labels = leg.legend_handles, [t.get_text() for t in leg.get_texts()]\n",
    "#             legend_handles, legend_labels = handles, labels\n",
    "#             leg.remove()\n",
    "\n",
    "# # globale Legende unter der Figure\n",
    "# if legend_handles is not None:\n",
    "#     fig.legend(\n",
    "#         legend_handles,\n",
    "#         legend_labels,\n",
    "#         title=\"\",\n",
    "#         loc=\"lower center\",\n",
    "#         ncol=len(legend_labels),\n",
    "#         bbox_to_anchor=(0.5, -0.02),\n",
    "#     )\n",
    "\n",
    "# plt.tight_layout(rect=(0, 0.05, 1, 1))  # unten Platz für die Legende lassen\n",
    "\n",
    "# plot_path = os.path.join(output_dir_plots, \"loss_curves_multitask_llms.png\")\n",
    "# plt.savefig(plot_path, dpi=300)\n",
    "# plt.close(fig)\n",
    "\n",
    "# print(\"Saved loss curve plot to:\", plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2b476c2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# # Parameter-Summary direkt aus df (Roh-Runs)\n",
    "\n",
    "# param_summary = (\n",
    "#     df[[\"log\", \"backbone\", \"total_params\", \"trainable_params\"]]\n",
    "#     .dropna(subset=[\"total_params\", \"trainable_params\"])\n",
    "#     .drop_duplicates()\n",
    "#     .copy()\n",
    "# )\n",
    "\n",
    "# param_summary[\"trainable_percent\"] = (\n",
    "#     param_summary[\"trainable_params\"] / param_summary[\"total_params\"] * 100\n",
    "# )\n",
    "\n",
    "# param_summary[\"trainable_percent_fmt\"] = (\n",
    "#     param_summary[\"trainable_percent\"].round(1).astype(str) + \"%\"\n",
    "# )\n",
    "\n",
    "# param_summary[\"total_params_fmt\"] = param_summary[\"total_params\"].apply(\n",
    "#     lambda x: np.format_float_scientific(x, precision=1)\n",
    "# )\n",
    "\n",
    "# param_summary[\"# params\\n(%trainable)\"] = (\n",
    "#     param_summary[\"total_params_fmt\"]\n",
    "#     + \" (\"\n",
    "#     + param_summary[\"trainable_percent_fmt\"]\n",
    "#     + \")\"\n",
    "# )\n",
    "\n",
    "# csv_path = os.path.join(output_dir_csv, \"param_summary_multitask.csv\")\n",
    "# param_summary.to_csv(csv_path, index=False)\n",
    "\n",
    "# print(\"PARAMETER SUMMARY (per log, backbone)\")\n",
    "# print(param_summary[[\"log\", \"backbone\", \"# params\\n(%trainable)\"]].to_string(index=False))\n",
    "# print(\"Saved to:\", csv_path)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "llm-peft-ppm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
