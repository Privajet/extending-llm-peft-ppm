{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b979f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results\n",
      "project_root in sys.path: True\n",
      "ENTITY: privajet-university-of-mannheim\n",
      "WANDB_MODE: offline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import wandb\n",
    "\n",
    "project_root = os.path.abspath(\"..\")\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from ppm.wandb_utils import fetch_experiments\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ.setdefault(\"ENTITY\", \"privajet-university-of-mannheim\")\n",
    "entity = os.environ[\"ENTITY\"]\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"project_root in sys.path:\", project_root in sys.path)\n",
    "print(\"ENTITY:\", entity)\n",
    "print(\"WANDB_MODE:\", os.environ.get(\"WANDB_MODE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d407aeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_csv = \"/ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv\"\n",
    "output_dir_plots = \"/ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots\"\n",
    "os.makedirs(output_dir_csv, exist_ok=True)\n",
    "os.makedirs(output_dir_plots, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6adf8acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all lines pandas\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    \"figure.figsize\": (6, 4),          \n",
    "    \"font.size\": 10,                   \n",
    "    \"axes.labelsize\": 10,              \n",
    "    \"axes.titlesize\": 10,              \n",
    "    \"legend.fontsize\": 9,              \n",
    "    \"xtick.labelsize\": 9,              \n",
    "    \"ytick.labelsize\": 9,\n",
    "    \"lines.linewidth\": 1.5,            \n",
    "    \"lines.markersize\": 5,             \n",
    "    \"axes.grid\": True,                 \n",
    "    \"grid.linestyle\": \"--\",\n",
    "    \"grid.linewidth\": 0.5,\n",
    "    \"legend.frameon\": False,           \n",
    "    \"pdf.fonttype\": 42,                \n",
    "    \"ps.fonttype\": 42,\n",
    "    \"savefig.bbox\": \"tight\",           \n",
    "    \"savefig.dpi\": 300,                \n",
    "})\n",
    "\n",
    "colors = [\n",
    "    \"#9467bd\",\n",
    "    \"#2ca02c\",\n",
    "    \"#bcbd22\",\n",
    "    \"#7f7f7f\",\n",
    "    \"#e377c2\",\n",
    "    \"#8c564b\",\n",
    "    \"#d62728\",\n",
    "    \"#17becf\",\n",
    "    \"#1f77b4\",\n",
    "    \"#ff7f0e\",\n",
    "]\n",
    "\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(color=colors)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45623d55",
   "metadata": {
    "title": "Experimental setup"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log</th>\n",
       "      <th># cases</th>\n",
       "      <th># evt.</th>\n",
       "      <th># act.</th>\n",
       "      <th>Trace length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BPI20PrepaidTravelCosts</td>\n",
       "      <td>2099</td>\n",
       "      <td>18246</td>\n",
       "      <td>29</td>\n",
       "      <td>8.6927±2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BPI20RequestForPayment</td>\n",
       "      <td>6886</td>\n",
       "      <td>36796</td>\n",
       "      <td>19</td>\n",
       "      <td>5.3436±1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BPI20TravelPermitData</td>\n",
       "      <td>7065</td>\n",
       "      <td>86581</td>\n",
       "      <td>51</td>\n",
       "      <td>12.2549±5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>13087</td>\n",
       "      <td>262200</td>\n",
       "      <td>24</td>\n",
       "      <td>20.0351±19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BPI17</td>\n",
       "      <td>31509</td>\n",
       "      <td>1202267</td>\n",
       "      <td>26</td>\n",
       "      <td>38.1563±16.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Log  # cases   # evt.  # act.  Trace length\n",
       "0  BPI20PrepaidTravelCosts     2099    18246      29    8.6927±2.3\n",
       "1   BPI20RequestForPayment     6886    36796      19    5.3436±1.5\n",
       "2    BPI20TravelPermitData     7065    86581      51   12.2549±5.6\n",
       "3                    BPI12    13087   262200      24  20.0351±19.9\n",
       "4                    BPI17    31509  1202267      26  38.1563±16.7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties = pd.read_csv(\n",
    "    \"/ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/log_properties.csv\"\n",
    ")\n",
    "properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4440f2ca",
   "metadata": {
    "title": "Architecture illustration"
   },
   "outputs": [],
   "source": [
    "# from ppm.models import NextEventPredictor\n",
    "# import torch \n",
    "\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "# device = \"cuda\" if use_cuda else \"cpu\"\n",
    "# print(\"Using device:\", device)\n",
    "\n",
    "# rnn_example = NextEventPredictor(\n",
    "#     embedding_size=32,\n",
    "#     categorical_cols=[\"activity\"],\n",
    "#     numerical_cols=[\"accumulated_time\"],\n",
    "#     categorical_sizes={\"activity\": 20},\n",
    "#     categorical_targets=[\"activity\"],\n",
    "#     numerical_targets=[\"remaining_time\"],\n",
    "#     backbone_name=\"rnn\",\n",
    "#     backbone_hidden_size=64,\n",
    "#     backbone_n_layers=2,\n",
    "#     padding_idx=0,\n",
    "#     strategy=\"sum\",\n",
    "#     backbone_pretrained=False,\n",
    "#     backbone_finetuning=None,\n",
    "#     backbone_type=\"lstm\",\n",
    "#     device=device,\n",
    "# )\n",
    "# pprint(rnn_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "689e01c4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def _to_int_or_none(x):\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
    "        return None\n",
    "    try:\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def map_setting(row):\n",
    "    ft = row.get(\"fine_tuning\")\n",
    "    k_raw = row.get(\"few_shot_k\", None)\n",
    "    fl    = row.get(\"freeze_layers\", None)\n",
    "    ep_raw = row.get(\"epochs\", None)\n",
    "\n",
    "    k  = _to_int_or_none(k_raw)\n",
    "    ep = _to_int_or_none(ep_raw)\n",
    "\n",
    "    # LoRA Few-Shot\n",
    "    if ft == \"lora\" and k == 8:\n",
    "        return \"FewShot-LoRA\"\n",
    "\n",
    "    # LoRA Full\n",
    "    if ft == \"lora\" and k is None:\n",
    "        return \"LoRA\"\n",
    "\n",
    "    # Zero-Shot (epochs = 0)\n",
    "    if ft == \"freeze\" and ep == 0:\n",
    "        return \"ZeroShot\"\n",
    "\n",
    "    # Freezing Few-Shot\n",
    "    if ft == \"freeze\" and k == 8:\n",
    "        return \"FewShot-Freezing\"\n",
    "\n",
    "    # Freezing standard (keine freeze_layers angegeben)\n",
    "    if ft == \"freeze\" and fl in (None, \"\", [], ()):\n",
    "        return \"Freezing\"\n",
    "\n",
    "    # Freezing layer configs (z.B. -1, -2 / 0, 1)\n",
    "    if ft == \"freeze\" and fl is not None:\n",
    "        if isinstance(fl, (list, tuple)):\n",
    "            fl_clean = [_to_int_or_none(x) for x in fl]\n",
    "        else:\n",
    "            tokens = str(fl).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \" \").split()\n",
    "            fl_clean = [_to_int_or_none(x) for x in tokens]\n",
    "        fl_clean = [x for x in fl_clean if x is not None]\n",
    "        return f\"Freezing-{fl_clean}\"\n",
    "\n",
    "    return \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95ea8e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_path = os.path.join(output_dir_csv, \"global_results.pkl\")\n",
    "\n",
    "BACKBONE_PROJECTS = {\n",
    "    \"majority\":         \"llm-peft-ppm_majority_baseline\",\n",
    "    \"rnn\":              \"llm-peft-ppm_rnn\",\n",
    "    \"transformer\":      \"llm-peft-ppm_transformer_baseline\",\n",
    "    \"tabpfn\":           \"llm-peft-ppm_tabpfn_baseline\",\n",
    "    \"saprpt\":           \"llm-peft-ppm_saprpt_baseline\",\n",
    "    \"gpt2\":             \"llm-peft-ppm_gpt2\",\n",
    "    \"gptneo-1b3\":       \"llm-peft-ppm_gpt-neo-1.3B\",\n",
    "    \"qwen25-05b\":       \"llm-peft-ppm_qwen25-05b\",\n",
    "    \"llama32-1b\":       \"llm-peft-ppm_llama32-1b\",\n",
    "    \"gemma-2-2b\":       \"llm-peft-ppm_gemma-2-2b\",\n",
    "}\n",
    "\n",
    "def build_global_results():\n",
    "    all_results = []\n",
    "    for backbone, project_name in BACKBONE_PROJECTS.items():\n",
    "        df_tmp = fetch_experiments(project=project_name, entity=entity, include_metrics=True)\n",
    "        df_tmp[\"backbone\"] = backbone\n",
    "        df_tmp[\"project\"] = project_name\n",
    "        all_results.append(df_tmp)\n",
    "\n",
    "    gr = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "    safe_cols = [\n",
    "        \"id\", \"log\", \"backbone\", \"project\", \"fine_tuning\",\n",
    "        \"total_params\", \"trainable_params\", \"seed\", \"_runtime\", \"_timestamp\",\n",
    "        \"categorical_features\", \"categorical_targets\",\n",
    "        \"continuous_features\", \"continuous_targets\", \"device\", \"model\", \"name\",\n",
    "\n",
    "        \"test_next_activity_acc\",\n",
    "        \"test_next_activity_loss\",\n",
    "        \"test_next_remaining_time_loss\",\n",
    "        \"test_next_time_to_next_event_loss\",\n",
    "        \"best_test_next_activity_acc\",\n",
    "        \"best_test_next_activity_loss\",\n",
    "        \"best_test_next_remaining_time_loss\",\n",
    "        \"best_test_next_time_to_next_event_loss\",\n",
    "\n",
    "        \"batch_size\",\n",
    "        \"embedding_size\",\n",
    "        \"epochs\",\n",
    "        \"freeze_layers\",\n",
    "        \"grad_clip\",\n",
    "        \"hidden_size\",\n",
    "        \"lr\",\n",
    "        \"n_layers\",\n",
    "        \"rnn_type\",\n",
    "        \"strategy\",\n",
    "        \"weight_decay\",\n",
    "        \"lora_alpha\",\n",
    "        \"r\",\n",
    "        \"few_shot_k\",\n",
    "    ]\n",
    "\n",
    "    safe_cols = [c for c in safe_cols if c in gr.columns]\n",
    "    gr = gr[safe_cols]\n",
    "    return gr\n",
    "\n",
    "\n",
    "if os.path.exists(pkl_path):\n",
    "    try:\n",
    "        global_results = pd.read_pickle(pkl_path)\n",
    "    except Exception as e:\n",
    "        print(\"Fehler beim Laden von global_results.pkl, baue neu:\", repr(e))\n",
    "        global_results = build_global_results()\n",
    "        global_results.to_pickle(pkl_path)\n",
    "else:\n",
    "    global_results = build_global_results()\n",
    "    global_results.to_pickle(pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "723b0b89",
   "metadata": {
    "title": "Checking best models"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>log</th>\n",
       "      <th>backbone</th>\n",
       "      <th>project</th>\n",
       "      <th>fine_tuning</th>\n",
       "      <th>total_params</th>\n",
       "      <th>trainable_params</th>\n",
       "      <th>seed</th>\n",
       "      <th>_runtime</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>...</th>\n",
       "      <th>rnn_type</th>\n",
       "      <th>strategy</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>lora_alpha</th>\n",
       "      <th>r</th>\n",
       "      <th>few_shot_k</th>\n",
       "      <th>na_norm</th>\n",
       "      <th>rt_norm</th>\n",
       "      <th>nt_norm</th>\n",
       "      <th>mt_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pox3cg0n</td>\n",
       "      <td>BPI20PrepaidTravelCosts</td>\n",
       "      <td>majority</td>\n",
       "      <td>llm-peft-ppm_majority_baseline</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.127169</td>\n",
       "      <td>1.762725e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.129842</td>\n",
       "      <td>0.944634</td>\n",
       "      <td>0.940268</td>\n",
       "      <td>2.014744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>whfyo8uu</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>majority</td>\n",
       "      <td>llm-peft-ppm_majority_baseline</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.600980</td>\n",
       "      <td>1.762849e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.252059</td>\n",
       "      <td>0.955857</td>\n",
       "      <td>0.943034</td>\n",
       "      <td>2.150950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oy378knj</td>\n",
       "      <td>BPI20TravelPermitData</td>\n",
       "      <td>majority</td>\n",
       "      <td>llm-peft-ppm_majority_baseline</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.808587</td>\n",
       "      <td>1.762850e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.087414</td>\n",
       "      <td>0.951915</td>\n",
       "      <td>0.961259</td>\n",
       "      <td>2.000588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3gchqw9a</td>\n",
       "      <td>BPI20RequestForPayment</td>\n",
       "      <td>majority</td>\n",
       "      <td>llm-peft-ppm_majority_baseline</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.075565</td>\n",
       "      <td>1.762850e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.188470</td>\n",
       "      <td>0.968881</td>\n",
       "      <td>0.975401</td>\n",
       "      <td>2.132752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cl197f3r</td>\n",
       "      <td>BPI17</td>\n",
       "      <td>majority</td>\n",
       "      <td>llm-peft-ppm_majority_baseline</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.474805</td>\n",
       "      <td>1.762850e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>concat</td>\n",
       "      <td>0.10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.169815</td>\n",
       "      <td>0.972109</td>\n",
       "      <td>0.963413</td>\n",
       "      <td>2.105338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vl6y1axq</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>rnn</td>\n",
       "      <td>llm-peft-ppm_rnn</td>\n",
       "      <td>None</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>64.434233</td>\n",
       "      <td>1.764079e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.896924</td>\n",
       "      <td>0.890896</td>\n",
       "      <td>0.959974</td>\n",
       "      <td>2.747794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wwv4s6ta</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>rnn</td>\n",
       "      <td>llm-peft-ppm_rnn</td>\n",
       "      <td>None</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>65.573150</td>\n",
       "      <td>1.764080e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.865574</td>\n",
       "      <td>0.885115</td>\n",
       "      <td>0.957324</td>\n",
       "      <td>2.708013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xjcuy92g</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>rnn</td>\n",
       "      <td>llm-peft-ppm_rnn</td>\n",
       "      <td>None</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>66.748843</td>\n",
       "      <td>1.764080e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.882514</td>\n",
       "      <td>0.882064</td>\n",
       "      <td>0.956911</td>\n",
       "      <td>2.721489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>r5ax60vx</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>rnn</td>\n",
       "      <td>llm-peft-ppm_rnn</td>\n",
       "      <td>None</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>60.193704</td>\n",
       "      <td>1.764080e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875060</td>\n",
       "      <td>0.886308</td>\n",
       "      <td>0.959447</td>\n",
       "      <td>2.720816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s5xrzrsn</td>\n",
       "      <td>BPI12</td>\n",
       "      <td>rnn</td>\n",
       "      <td>llm-peft-ppm_rnn</td>\n",
       "      <td>None</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>88733.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>68.910497</td>\n",
       "      <td>1.764080e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>lstm</td>\n",
       "      <td>sum</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.902644</td>\n",
       "      <td>0.889049</td>\n",
       "      <td>0.956773</td>\n",
       "      <td>2.748466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                      log  backbone  \\\n",
       "0  pox3cg0n  BPI20PrepaidTravelCosts  majority   \n",
       "1  whfyo8uu                    BPI12  majority   \n",
       "2  oy378knj    BPI20TravelPermitData  majority   \n",
       "3  3gchqw9a   BPI20RequestForPayment  majority   \n",
       "4  cl197f3r                    BPI17  majority   \n",
       "5  vl6y1axq                    BPI12       rnn   \n",
       "6  wwv4s6ta                    BPI12       rnn   \n",
       "7  xjcuy92g                    BPI12       rnn   \n",
       "8  r5ax60vx                    BPI12       rnn   \n",
       "9  s5xrzrsn                    BPI12       rnn   \n",
       "\n",
       "                          project fine_tuning  total_params  trainable_params  \\\n",
       "0  llm-peft-ppm_majority_baseline        None           1.0               1.0   \n",
       "1  llm-peft-ppm_majority_baseline        None           1.0               1.0   \n",
       "2  llm-peft-ppm_majority_baseline        None           1.0               1.0   \n",
       "3  llm-peft-ppm_majority_baseline        None           1.0               1.0   \n",
       "4  llm-peft-ppm_majority_baseline        None           1.0               1.0   \n",
       "5                llm-peft-ppm_rnn        None       88733.0           88733.0   \n",
       "6                llm-peft-ppm_rnn        None       88733.0           88733.0   \n",
       "7                llm-peft-ppm_rnn        None       88733.0           88733.0   \n",
       "8                llm-peft-ppm_rnn        None       88733.0           88733.0   \n",
       "9                llm-peft-ppm_rnn        None       88733.0           88733.0   \n",
       "\n",
       "   seed    _runtime    _timestamp  ... rnn_type strategy weight_decay  \\\n",
       "0   NaN    1.127169  1.762725e+09  ...     lstm   concat         0.10   \n",
       "1   NaN   35.600980  1.762849e+09  ...     lstm   concat         0.10   \n",
       "2   NaN   23.808587  1.762850e+09  ...     lstm   concat         0.10   \n",
       "3   NaN   21.075565  1.762850e+09  ...     lstm   concat         0.10   \n",
       "4   NaN  107.474805  1.762850e+09  ...     lstm   concat         0.10   \n",
       "5  41.0   64.434233  1.764079e+09  ...     lstm      sum         0.01   \n",
       "6  42.0   65.573150  1.764080e+09  ...     lstm      sum         0.01   \n",
       "7  43.0   66.748843  1.764080e+09  ...     lstm      sum         0.01   \n",
       "8  44.0   60.193704  1.764080e+09  ...     lstm      sum         0.01   \n",
       "9  45.0   68.910497  1.764080e+09  ...     lstm      sum         0.01   \n",
       "\n",
       "  lora_alpha     r few_shot_k   na_norm   rt_norm   nt_norm  mt_score  \n",
       "0       None  None        NaN  0.129842  0.944634  0.940268  2.014744  \n",
       "1       None  None        NaN  0.252059  0.955857  0.943034  2.150950  \n",
       "2       None  None        NaN  0.087414  0.951915  0.961259  2.000588  \n",
       "3       None  None        NaN  0.188470  0.968881  0.975401  2.132752  \n",
       "4       None  None        NaN  0.169815  0.972109  0.963413  2.105338  \n",
       "5       None  None        NaN  0.896924  0.890896  0.959974  2.747794  \n",
       "6       None  None        NaN  0.865574  0.885115  0.957324  2.708013  \n",
       "7       None  None        NaN  0.882514  0.882064  0.956911  2.721489  \n",
       "8       None  None        NaN  0.875060  0.886308  0.959447  2.720816  \n",
       "9       None  None        NaN  0.902644  0.889049  0.956773  2.748466  \n",
       "\n",
       "[10 rows x 43 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\n",
    "    \"id\",\n",
    "    \"log\",\n",
    "    \"backbone\",\n",
    "    \"project\",\n",
    "    \"fine_tuning\",\n",
    "    \"total_params\",\n",
    "    \"trainable_params\",\n",
    "    \"test_next_activity_acc\",\n",
    "    \"test_next_activity_loss\",\n",
    "    \"test_next_remaining_time_loss\",\n",
    "    \"test_next_time_to_next_event_loss\",\n",
    "    \"best_test_next_activity_acc\",\n",
    "    \"best_test_next_activity_loss\",\n",
    "    \"best_test_next_remaining_time_loss\",\n",
    "    \"best_test_next_time_to_next_event_loss\",\n",
    "    \"_runtime\",\n",
    "    \"mt_score\",\n",
    "]\n",
    "\n",
    "df = global_results.copy()\n",
    "df = df[\n",
    "    df[\"test_next_activity_acc\"].notna()\n",
    "    & df[\"test_next_remaining_time_loss\"].notna()\n",
    "    & df[\"test_next_time_to_next_event_loss\"].notna()\n",
    "].copy()\n",
    "\n",
    "sc_acc = MinMaxScaler()\n",
    "sc_rt  = MinMaxScaler()\n",
    "sc_nt  = MinMaxScaler()\n",
    "\n",
    "df[\"na_norm\"] = sc_acc.fit_transform(df[[\"test_next_activity_acc\"]])\n",
    "df[\"rt_norm\"] = sc_rt.fit_transform(-df[[\"test_next_remaining_time_loss\"]])\n",
    "df[\"nt_norm\"] = sc_nt.fit_transform(-df[[\"test_next_time_to_next_event_loss\"]])\n",
    "df[\"mt_score\"] = df[\"na_norm\"] + df[\"rt_norm\"] + df[\"nt_norm\"]\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1682d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    \"test_next_activity_acc\",\n",
    "    \"test_next_activity_loss\",\n",
    "    \"test_next_remaining_time_loss\",\n",
    "    \"test_next_time_to_next_event_loss\",\n",
    "    \"best_test_next_activity_acc\",\n",
    "    \"best_test_next_activity_loss\",\n",
    "    \"best_test_next_remaining_time_loss\",\n",
    "    \"best_test_next_time_to_next_event_loss\",\n",
    "]\n",
    "\n",
    "def agg_over_seeds(group: pd.DataFrame) -> pd.Series:\n",
    "    out = {\"n_runs\": len(group)}\n",
    "    for c in [\"total_params\", \"trainable_params\"]:\n",
    "        if c in group.columns:\n",
    "            out[c] = group[c].iloc[0]\n",
    "    if \"mt_score\" in group.columns:\n",
    "        out[\"mt_score_mean\"] = group[\"mt_score\"].mean()\n",
    "        out[\"mt_score_std\"] = group[\"mt_score\"].std()\n",
    "    if \"_runtime\" in group.columns:\n",
    "        out[\"_runtime_mean\"] = group[\"_runtime\"].mean()\n",
    "        out[\"_runtime_std\"]  = group[\"_runtime\"].std()\n",
    "    for m in METRICS:\n",
    "        if m in group.columns:\n",
    "            vals = group[m].dropna()\n",
    "            out[m + \"_mean\"] = vals.mean()\n",
    "            out[m + \"_std\"] = vals.std()\n",
    "    return pd.Series(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "889f1a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter columns: ['batch_size', 'embedding_size', 'epochs', 'freeze_layers', 'grad_clip', 'hidden_size', 'lr', 'n_layers', 'rnn_type', 'strategy', 'weight_decay']\n"
     ]
    }
   ],
   "source": [
    "majority = df[df[\"backbone\"] == \"majority\"].copy()\n",
    "majority_grouped = (\n",
    "    majority\n",
    "    .groupby([\"log\", \"backbone\"], dropna=False)\n",
    "    .apply(agg_over_seeds)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "BASELINE_BACKBONES = [\"rnn\", \"transformer\", \"tabpfn\", \"saprpt\"]\n",
    "baseline = df[df[\"backbone\"].isin(BASELINE_BACKBONES)].copy()\n",
    "\n",
    "NON_HP_COLS = set(\n",
    "    [\n",
    "        \"id\",\"log\",\"backbone\",\"categorical_features\",\"categorical_targets\",\n",
    "        \"continuous_features\",\"continuous_targets\",\"device\",\"project\",\"model\",\n",
    "        \"name\",\"fine_tuning\",\"lora_alpha\", \"r\", \"few_shot_k\", \"seed\",\"_runtime\",\"_timestamp\",\n",
    "        \"na_norm\",\"rt_norm\",\"nt_norm\",\"mt_score\",\"majority_stat\",\n",
    "        \"total_params\",\"trainable_params\",\"best_train_next_remaining_time_loss\",\n",
    "        \"_step\",\"best_train_next_activity_loss\",\"train_next_time_to_next_event_loss\",\n",
    "        \"best_train_next_time_to_next_event_loss\",\"train_next_activity_acc\",\n",
    "        \"train_next_activity_loss\",\"_wandb.runtime\",\"best_train_next_activity_acc\",\n",
    "        \"train_next_remaining_time_loss\",\"persist_model\",\"project_name\",\"wandb\",\n",
    "    ]\n",
    "    + METRICS\n",
    ")\n",
    "\n",
    "HP_COLS = [c for c in baseline.columns if c not in NON_HP_COLS]\n",
    "print(\"Hyperparameter columns:\", HP_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8c1e4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved baseline summary to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/baseline_best_settings_mean_std.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "      <th>backbone</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>embedding_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>freeze_layers</th>\n",
       "      <th>grad_clip</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>...</th>\n",
       "      <th>Backbone_pretty</th>\n",
       "      <th>test_next_activity_acc_mean_std</th>\n",
       "      <th>test_next_activity_loss_mean_std</th>\n",
       "      <th>test_next_remaining_time_loss_mean_std</th>\n",
       "      <th>test_next_time_to_next_event_loss_mean_std</th>\n",
       "      <th>best_test_next_activity_acc_mean_std</th>\n",
       "      <th>best_test_next_activity_loss_mean_std</th>\n",
       "      <th>best_test_next_remaining_time_loss_mean_std</th>\n",
       "      <th>best_test_next_time_to_next_event_loss_mean_std</th>\n",
       "      <th>Runtime (h)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>rnn</td>\n",
       "      <td>32.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7757 ± 0.0142</td>\n",
       "      <td>0.7689 ± 0.042</td>\n",
       "      <td>1.7738 ± 0.0889</td>\n",
       "      <td>1.3352 ± 0.0302</td>\n",
       "      <td>0.7799 ± 0.0095</td>\n",
       "      <td>0.758 ± 0.0285</td>\n",
       "      <td>1.7033 ± 0.1138</td>\n",
       "      <td>1.3205 ± 0.014</td>\n",
       "      <td>0.01943 ± 0.00025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>saprpt</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SAP-RPT</td>\n",
       "      <td>0.6294 ± 0.0121</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>2.1601 ± 0.1146</td>\n",
       "      <td>1.6706 ± 0.372</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.00500 ± 0.00093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>tabpfn</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>TabPFN</td>\n",
       "      <td>0.6364 ± 0.0153</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>2.2338 ± 0.0937</td>\n",
       "      <td>1.6877 ± 0.4063</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.12074 ± 0.00085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>transformer</td>\n",
       "      <td>32.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.7562 ± 0.0246</td>\n",
       "      <td>0.7139 ± 0.1077</td>\n",
       "      <td>2.8388 ± 0.1209</td>\n",
       "      <td>1.3671 ± 0.0495</td>\n",
       "      <td>0.7687 ± 0.016</td>\n",
       "      <td>0.6635 ± 0.0383</td>\n",
       "      <td>2.6204 ± 0.1508</td>\n",
       "      <td>1.3364 ± 0.016</td>\n",
       "      <td>0.00758 ± 0.00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BPI17</td>\n",
       "      <td>rnn</td>\n",
       "      <td>256.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8535 ± 0.0013</td>\n",
       "      <td>0.4193 ± 0.0068</td>\n",
       "      <td>0.6725 ± 0.0325</td>\n",
       "      <td>0.7629 ± 0.0159</td>\n",
       "      <td>0.8535 ± 0.0013</td>\n",
       "      <td>0.4193 ± 0.0068</td>\n",
       "      <td>0.6097 ± 0.0138</td>\n",
       "      <td>0.7629 ± 0.0159</td>\n",
       "      <td>0.04166 ± 0.00022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BPI17</td>\n",
       "      <td>saprpt</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SAP-RPT</td>\n",
       "      <td>0.6472 ± 0.0268</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>1.3056 ± 0.2773</td>\n",
       "      <td>1.1287 ± 0.1969</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.00440 ± 0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BPI17</td>\n",
       "      <td>tabpfn</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>TabPFN</td>\n",
       "      <td>0.669 ± 0.0194</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>1.6011 ± 0.0589</td>\n",
       "      <td>1.1679 ± 0.2366</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.12188 ± 0.00312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BPI17</td>\n",
       "      <td>transformer</td>\n",
       "      <td>32.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.8556 ± 0.0058</td>\n",
       "      <td>0.4141 ± 0.0136</td>\n",
       "      <td>1.156 ± 0.0803</td>\n",
       "      <td>0.8836 ± 0.0296</td>\n",
       "      <td>0.8596 ± 0.0024</td>\n",
       "      <td>0.407 ± 0.0142</td>\n",
       "      <td>1.1343 ± 0.0847</td>\n",
       "      <td>0.8433 ± 0.0401</td>\n",
       "      <td>0.01953 ± 0.00030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BPI20PrepaidTravelCosts</td>\n",
       "      <td>rnn</td>\n",
       "      <td>32.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7841 ± 0.0201</td>\n",
       "      <td>0.6578 ± 0.0553</td>\n",
       "      <td>1.0744 ± 0.0308</td>\n",
       "      <td>1.1906 ± 0.0485</td>\n",
       "      <td>0.7897 ± 0.0134</td>\n",
       "      <td>0.6549 ± 0.0492</td>\n",
       "      <td>0.9536 ± 0.027</td>\n",
       "      <td>1.1239 ± 0.0216</td>\n",
       "      <td>0.00316 ± 0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BPI20PrepaidTravelCosts</td>\n",
       "      <td>saprpt</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SAP-RPT</td>\n",
       "      <td>0.7646 ± 0.0054</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>1.041 ± 0.0605</td>\n",
       "      <td>1.0863 ± 0.2173</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.00448 ± 0.00007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BPI20PrepaidTravelCosts</td>\n",
       "      <td>tabpfn</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>TabPFN</td>\n",
       "      <td>0.6637 ± 0.0121</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>1.1278 ± 0.0716</td>\n",
       "      <td>1.1919 ± 0.2369</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.01156 ± 0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BPI20PrepaidTravelCosts</td>\n",
       "      <td>transformer</td>\n",
       "      <td>32.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.7821 ± 0.0061</td>\n",
       "      <td>0.6683 ± 0.0118</td>\n",
       "      <td>1.1187 ± 0.0865</td>\n",
       "      <td>1.237 ± 0.0537</td>\n",
       "      <td>0.7994 ± 0.0105</td>\n",
       "      <td>0.6527 ± 0.0174</td>\n",
       "      <td>0.9541 ± 0.0334</td>\n",
       "      <td>1.0688 ± 0.0115</td>\n",
       "      <td>0.00162 ± 0.00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BPI20RequestForPayment</td>\n",
       "      <td>rnn</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>RNN</td>\n",
       "      <td>0.8777 ± 0.0234</td>\n",
       "      <td>0.3678 ± 0.0387</td>\n",
       "      <td>0.6826 ± 0.0213</td>\n",
       "      <td>0.7504 ± 0.0088</td>\n",
       "      <td>0.886 ± 0.0114</td>\n",
       "      <td>0.3647 ± 0.0376</td>\n",
       "      <td>0.6795 ± 0.0219</td>\n",
       "      <td>0.7444 ± 0.0072</td>\n",
       "      <td>0.00952 ± 0.00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BPI20RequestForPayment</td>\n",
       "      <td>saprpt</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SAP-RPT</td>\n",
       "      <td>0.7434 ± 0.0096</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.6383 ± 0.0255</td>\n",
       "      <td>0.7122 ± 0.0769</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.00452 ± 0.00017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BPI20RequestForPayment</td>\n",
       "      <td>tabpfn</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>TabPFN</td>\n",
       "      <td>0.7439 ± 0.0088</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.7148 ± 0.034</td>\n",
       "      <td>0.7176 ± 0.0719</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.03380 ± 0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BPI20RequestForPayment</td>\n",
       "      <td>transformer</td>\n",
       "      <td>32.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.8937 ± 0.0013</td>\n",
       "      <td>0.2719 ± 0.0012</td>\n",
       "      <td>0.6571 ± 0.009</td>\n",
       "      <td>0.7407 ± 0.0091</td>\n",
       "      <td>0.8954 ± 0.001</td>\n",
       "      <td>0.2639 ± 0.0012</td>\n",
       "      <td>0.6438 ± 0.0042</td>\n",
       "      <td>0.7187 ± 0.0037</td>\n",
       "      <td>0.00471 ± 0.00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BPI20TravelPermitData</td>\n",
       "      <td>rnn</td>\n",
       "      <td>32.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>RNN</td>\n",
       "      <td>0.7302 ± 0.0031</td>\n",
       "      <td>0.9502 ± 0.014</td>\n",
       "      <td>1.0098 ± 0.0383</td>\n",
       "      <td>1.052 ± 0.0308</td>\n",
       "      <td>0.7314 ± 0.0026</td>\n",
       "      <td>0.9381 ± 0.0158</td>\n",
       "      <td>0.7632 ± 0.0399</td>\n",
       "      <td>0.8585 ± 0.0104</td>\n",
       "      <td>0.01171 ± 0.00011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BPI20TravelPermitData</td>\n",
       "      <td>saprpt</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SAP-RPT</td>\n",
       "      <td>0.6869 ± 0.013</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.9545 ± 0.0682</td>\n",
       "      <td>1.0428 ± 0.0515</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.00449 ± 0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BPI20TravelPermitData</td>\n",
       "      <td>tabpfn</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>TabPFN</td>\n",
       "      <td>0.6229 ± 0.012</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>1.091 ± 0.0495</td>\n",
       "      <td>1.1187 ± 0.0619</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>nan ± nan</td>\n",
       "      <td>0.12027 ± 0.00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BPI20TravelPermitData</td>\n",
       "      <td>transformer</td>\n",
       "      <td>16.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.7183 ± 0.0019</td>\n",
       "      <td>0.8407 ± 0.0143</td>\n",
       "      <td>0.8088 ± 0.0386</td>\n",
       "      <td>0.8717 ± 0.0301</td>\n",
       "      <td>0.7191 ± 0.0022</td>\n",
       "      <td>0.8369 ± 0.0147</td>\n",
       "      <td>0.7829 ± 0.0103</td>\n",
       "      <td>0.8473 ± 0.0178</td>\n",
       "      <td>0.00808 ± 0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>majority</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Majority</td>\n",
       "      <td>0.226 ± nan</td>\n",
       "      <td>6.2004 ± nan</td>\n",
       "      <td>1.3884 ± nan</td>\n",
       "      <td>1.5434 ± nan</td>\n",
       "      <td>0.226 ± nan</td>\n",
       "      <td>6.2004 ± nan</td>\n",
       "      <td>1.3884 ± nan</td>\n",
       "      <td>1.5434 ± nan</td>\n",
       "      <td>0.00989 ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BPI17</td>\n",
       "      <td>majority</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Majority</td>\n",
       "      <td>0.1523 ± nan</td>\n",
       "      <td>6.7908 ± nan</td>\n",
       "      <td>1.0963 ± nan</td>\n",
       "      <td>1.2125 ± nan</td>\n",
       "      <td>0.1523 ± nan</td>\n",
       "      <td>6.7908 ± nan</td>\n",
       "      <td>1.0963 ± nan</td>\n",
       "      <td>1.2125 ± nan</td>\n",
       "      <td>0.02985 ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BPI20PrepaidTravelCosts</td>\n",
       "      <td>majority</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Majority</td>\n",
       "      <td>0.1164 ± nan</td>\n",
       "      <td>7.0789 ± nan</td>\n",
       "      <td>1.5902 ± nan</td>\n",
       "      <td>1.5883 ± nan</td>\n",
       "      <td>0.1164 ± nan</td>\n",
       "      <td>7.0789 ± nan</td>\n",
       "      <td>1.5902 ± nan</td>\n",
       "      <td>1.5883 ± nan</td>\n",
       "      <td>0.00031 ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BPI20RequestForPayment</td>\n",
       "      <td>majority</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Majority</td>\n",
       "      <td>0.169 ± nan</td>\n",
       "      <td>6.6539 ± nan</td>\n",
       "      <td>1.1543 ± nan</td>\n",
       "      <td>1.0179 ± nan</td>\n",
       "      <td>0.169 ± nan</td>\n",
       "      <td>6.6539 ± nan</td>\n",
       "      <td>1.1543 ± nan</td>\n",
       "      <td>1.0179 ± nan</td>\n",
       "      <td>0.00585 ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BPI20TravelPermitData</td>\n",
       "      <td>majority</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Majority</td>\n",
       "      <td>0.0784 ± nan</td>\n",
       "      <td>7.3902 ± nan</td>\n",
       "      <td>1.4593 ± nan</td>\n",
       "      <td>1.2475 ± nan</td>\n",
       "      <td>0.0784 ± nan</td>\n",
       "      <td>7.3902 ± nan</td>\n",
       "      <td>1.4593 ± nan</td>\n",
       "      <td>1.2475 ± nan</td>\n",
       "      <td>0.00661 ± nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        log     backbone  batch_size  embedding_size  epochs  \\\n",
       "0                     BPI12          rnn        32.0           128.0    25.0   \n",
       "1                     BPI12       saprpt        16.0            16.0    25.0   \n",
       "2                     BPI12       tabpfn        16.0            16.0    25.0   \n",
       "3                     BPI12  transformer        32.0           128.0    10.0   \n",
       "4                     BPI17          rnn       256.0            32.0    25.0   \n",
       "5                     BPI17       saprpt        16.0            16.0    25.0   \n",
       "6                     BPI17       tabpfn        16.0            16.0    25.0   \n",
       "7                     BPI17  transformer        32.0           128.0    10.0   \n",
       "8   BPI20PrepaidTravelCosts          rnn        32.0           128.0    25.0   \n",
       "9   BPI20PrepaidTravelCosts       saprpt        16.0            16.0    25.0   \n",
       "10  BPI20PrepaidTravelCosts       tabpfn        16.0            16.0    25.0   \n",
       "11  BPI20PrepaidTravelCosts  transformer        32.0           128.0    10.0   \n",
       "12   BPI20RequestForPayment          rnn        32.0            32.0    25.0   \n",
       "13   BPI20RequestForPayment       saprpt        16.0            16.0    25.0   \n",
       "14   BPI20RequestForPayment       tabpfn        16.0            16.0    25.0   \n",
       "15   BPI20RequestForPayment  transformer        32.0           128.0    10.0   \n",
       "16    BPI20TravelPermitData          rnn        32.0           256.0    25.0   \n",
       "17    BPI20TravelPermitData       saprpt        16.0            16.0    25.0   \n",
       "18    BPI20TravelPermitData       tabpfn        16.0            16.0    25.0   \n",
       "19    BPI20TravelPermitData  transformer        16.0           256.0    10.0   \n",
       "20                    BPI12     majority         NaN             NaN     NaN   \n",
       "21                    BPI17     majority         NaN             NaN     NaN   \n",
       "22  BPI20PrepaidTravelCosts     majority         NaN             NaN     NaN   \n",
       "23   BPI20RequestForPayment     majority         NaN             NaN     NaN   \n",
       "24    BPI20TravelPermitData     majority         NaN             NaN     NaN   \n",
       "\n",
       "    freeze_layers  grad_clip  hidden_size       lr  n_layers  ...  \\\n",
       "0             NaN        5.0        512.0  0.00005       1.0  ...   \n",
       "1             NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "2             NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "3             NaN        5.0        128.0  0.00100       2.0  ...   \n",
       "4             NaN        5.0        512.0  0.00010       1.0  ...   \n",
       "5             NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "6             NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "7             NaN        5.0        128.0  0.00100       1.0  ...   \n",
       "8             NaN        5.0        128.0  0.00050       1.0  ...   \n",
       "9             NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "10            NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "11            NaN        5.0        128.0  0.00050       2.0  ...   \n",
       "12            NaN        5.0        512.0  0.00010       1.0  ...   \n",
       "13            NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "14            NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "15            NaN        5.0        128.0  0.00100       2.0  ...   \n",
       "16            NaN        5.0        128.0  0.00050       1.0  ...   \n",
       "17            NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "18            NaN        5.0         32.0  0.00010       1.0  ...   \n",
       "19            NaN        5.0        256.0  0.00050       2.0  ...   \n",
       "20            NaN        NaN          NaN      NaN       NaN  ...   \n",
       "21            NaN        NaN          NaN      NaN       NaN  ...   \n",
       "22            NaN        NaN          NaN      NaN       NaN  ...   \n",
       "23            NaN        NaN          NaN      NaN       NaN  ...   \n",
       "24            NaN        NaN          NaN      NaN       NaN  ...   \n",
       "\n",
       "   Backbone_pretty test_next_activity_acc_mean_std  \\\n",
       "0              RNN                 0.7757 ± 0.0142   \n",
       "1          SAP-RPT                 0.6294 ± 0.0121   \n",
       "2           TabPFN                 0.6364 ± 0.0153   \n",
       "3      Transformer                 0.7562 ± 0.0246   \n",
       "4              RNN                 0.8535 ± 0.0013   \n",
       "5          SAP-RPT                 0.6472 ± 0.0268   \n",
       "6           TabPFN                  0.669 ± 0.0194   \n",
       "7      Transformer                 0.8556 ± 0.0058   \n",
       "8              RNN                 0.7841 ± 0.0201   \n",
       "9          SAP-RPT                 0.7646 ± 0.0054   \n",
       "10          TabPFN                 0.6637 ± 0.0121   \n",
       "11     Transformer                 0.7821 ± 0.0061   \n",
       "12             RNN                 0.8777 ± 0.0234   \n",
       "13         SAP-RPT                 0.7434 ± 0.0096   \n",
       "14          TabPFN                 0.7439 ± 0.0088   \n",
       "15     Transformer                 0.8937 ± 0.0013   \n",
       "16             RNN                 0.7302 ± 0.0031   \n",
       "17         SAP-RPT                  0.6869 ± 0.013   \n",
       "18          TabPFN                  0.6229 ± 0.012   \n",
       "19     Transformer                 0.7183 ± 0.0019   \n",
       "20        Majority                     0.226 ± nan   \n",
       "21        Majority                    0.1523 ± nan   \n",
       "22        Majority                    0.1164 ± nan   \n",
       "23        Majority                     0.169 ± nan   \n",
       "24        Majority                    0.0784 ± nan   \n",
       "\n",
       "    test_next_activity_loss_mean_std  test_next_remaining_time_loss_mean_std  \\\n",
       "0                     0.7689 ± 0.042                         1.7738 ± 0.0889   \n",
       "1                          nan ± nan                         2.1601 ± 0.1146   \n",
       "2                          nan ± nan                         2.2338 ± 0.0937   \n",
       "3                    0.7139 ± 0.1077                         2.8388 ± 0.1209   \n",
       "4                    0.4193 ± 0.0068                         0.6725 ± 0.0325   \n",
       "5                          nan ± nan                         1.3056 ± 0.2773   \n",
       "6                          nan ± nan                         1.6011 ± 0.0589   \n",
       "7                    0.4141 ± 0.0136                          1.156 ± 0.0803   \n",
       "8                    0.6578 ± 0.0553                         1.0744 ± 0.0308   \n",
       "9                          nan ± nan                          1.041 ± 0.0605   \n",
       "10                         nan ± nan                         1.1278 ± 0.0716   \n",
       "11                   0.6683 ± 0.0118                         1.1187 ± 0.0865   \n",
       "12                   0.3678 ± 0.0387                         0.6826 ± 0.0213   \n",
       "13                         nan ± nan                         0.6383 ± 0.0255   \n",
       "14                         nan ± nan                          0.7148 ± 0.034   \n",
       "15                   0.2719 ± 0.0012                          0.6571 ± 0.009   \n",
       "16                    0.9502 ± 0.014                         1.0098 ± 0.0383   \n",
       "17                         nan ± nan                         0.9545 ± 0.0682   \n",
       "18                         nan ± nan                          1.091 ± 0.0495   \n",
       "19                   0.8407 ± 0.0143                         0.8088 ± 0.0386   \n",
       "20                      6.2004 ± nan                            1.3884 ± nan   \n",
       "21                      6.7908 ± nan                            1.0963 ± nan   \n",
       "22                      7.0789 ± nan                            1.5902 ± nan   \n",
       "23                      6.6539 ± nan                            1.1543 ± nan   \n",
       "24                      7.3902 ± nan                            1.4593 ± nan   \n",
       "\n",
       "    test_next_time_to_next_event_loss_mean_std  \\\n",
       "0                              1.3352 ± 0.0302   \n",
       "1                               1.6706 ± 0.372   \n",
       "2                              1.6877 ± 0.4063   \n",
       "3                              1.3671 ± 0.0495   \n",
       "4                              0.7629 ± 0.0159   \n",
       "5                              1.1287 ± 0.1969   \n",
       "6                              1.1679 ± 0.2366   \n",
       "7                              0.8836 ± 0.0296   \n",
       "8                              1.1906 ± 0.0485   \n",
       "9                              1.0863 ± 0.2173   \n",
       "10                             1.1919 ± 0.2369   \n",
       "11                              1.237 ± 0.0537   \n",
       "12                             0.7504 ± 0.0088   \n",
       "13                             0.7122 ± 0.0769   \n",
       "14                             0.7176 ± 0.0719   \n",
       "15                             0.7407 ± 0.0091   \n",
       "16                              1.052 ± 0.0308   \n",
       "17                             1.0428 ± 0.0515   \n",
       "18                             1.1187 ± 0.0619   \n",
       "19                             0.8717 ± 0.0301   \n",
       "20                                1.5434 ± nan   \n",
       "21                                1.2125 ± nan   \n",
       "22                                1.5883 ± nan   \n",
       "23                                1.0179 ± nan   \n",
       "24                                1.2475 ± nan   \n",
       "\n",
       "    best_test_next_activity_acc_mean_std  \\\n",
       "0                        0.7799 ± 0.0095   \n",
       "1                              nan ± nan   \n",
       "2                              nan ± nan   \n",
       "3                         0.7687 ± 0.016   \n",
       "4                        0.8535 ± 0.0013   \n",
       "5                              nan ± nan   \n",
       "6                              nan ± nan   \n",
       "7                        0.8596 ± 0.0024   \n",
       "8                        0.7897 ± 0.0134   \n",
       "9                              nan ± nan   \n",
       "10                             nan ± nan   \n",
       "11                       0.7994 ± 0.0105   \n",
       "12                        0.886 ± 0.0114   \n",
       "13                             nan ± nan   \n",
       "14                             nan ± nan   \n",
       "15                        0.8954 ± 0.001   \n",
       "16                       0.7314 ± 0.0026   \n",
       "17                             nan ± nan   \n",
       "18                             nan ± nan   \n",
       "19                       0.7191 ± 0.0022   \n",
       "20                           0.226 ± nan   \n",
       "21                          0.1523 ± nan   \n",
       "22                          0.1164 ± nan   \n",
       "23                           0.169 ± nan   \n",
       "24                          0.0784 ± nan   \n",
       "\n",
       "    best_test_next_activity_loss_mean_std  \\\n",
       "0                          0.758 ± 0.0285   \n",
       "1                               nan ± nan   \n",
       "2                               nan ± nan   \n",
       "3                         0.6635 ± 0.0383   \n",
       "4                         0.4193 ± 0.0068   \n",
       "5                               nan ± nan   \n",
       "6                               nan ± nan   \n",
       "7                          0.407 ± 0.0142   \n",
       "8                         0.6549 ± 0.0492   \n",
       "9                               nan ± nan   \n",
       "10                              nan ± nan   \n",
       "11                        0.6527 ± 0.0174   \n",
       "12                        0.3647 ± 0.0376   \n",
       "13                              nan ± nan   \n",
       "14                              nan ± nan   \n",
       "15                        0.2639 ± 0.0012   \n",
       "16                        0.9381 ± 0.0158   \n",
       "17                              nan ± nan   \n",
       "18                              nan ± nan   \n",
       "19                        0.8369 ± 0.0147   \n",
       "20                           6.2004 ± nan   \n",
       "21                           6.7908 ± nan   \n",
       "22                           7.0789 ± nan   \n",
       "23                           6.6539 ± nan   \n",
       "24                           7.3902 ± nan   \n",
       "\n",
       "    best_test_next_remaining_time_loss_mean_std  \\\n",
       "0                               1.7033 ± 0.1138   \n",
       "1                                     nan ± nan   \n",
       "2                                     nan ± nan   \n",
       "3                               2.6204 ± 0.1508   \n",
       "4                               0.6097 ± 0.0138   \n",
       "5                                     nan ± nan   \n",
       "6                                     nan ± nan   \n",
       "7                               1.1343 ± 0.0847   \n",
       "8                                0.9536 ± 0.027   \n",
       "9                                     nan ± nan   \n",
       "10                                    nan ± nan   \n",
       "11                              0.9541 ± 0.0334   \n",
       "12                              0.6795 ± 0.0219   \n",
       "13                                    nan ± nan   \n",
       "14                                    nan ± nan   \n",
       "15                              0.6438 ± 0.0042   \n",
       "16                              0.7632 ± 0.0399   \n",
       "17                                    nan ± nan   \n",
       "18                                    nan ± nan   \n",
       "19                              0.7829 ± 0.0103   \n",
       "20                                 1.3884 ± nan   \n",
       "21                                 1.0963 ± nan   \n",
       "22                                 1.5902 ± nan   \n",
       "23                                 1.1543 ± nan   \n",
       "24                                 1.4593 ± nan   \n",
       "\n",
       "    best_test_next_time_to_next_event_loss_mean_std        Runtime (h)  \n",
       "0                                    1.3205 ± 0.014  0.01943 ± 0.00025  \n",
       "1                                         nan ± nan  0.00500 ± 0.00093  \n",
       "2                                         nan ± nan  0.12074 ± 0.00085  \n",
       "3                                    1.3364 ± 0.016  0.00758 ± 0.00008  \n",
       "4                                   0.7629 ± 0.0159  0.04166 ± 0.00022  \n",
       "5                                         nan ± nan  0.00440 ± 0.00005  \n",
       "6                                         nan ± nan  0.12188 ± 0.00312  \n",
       "7                                   0.8433 ± 0.0401  0.01953 ± 0.00030  \n",
       "8                                   1.1239 ± 0.0216  0.00316 ± 0.00005  \n",
       "9                                         nan ± nan  0.00448 ± 0.00007  \n",
       "10                                        nan ± nan  0.01156 ± 0.00005  \n",
       "11                                  1.0688 ± 0.0115  0.00162 ± 0.00003  \n",
       "12                                  0.7444 ± 0.0072  0.00952 ± 0.00008  \n",
       "13                                        nan ± nan  0.00452 ± 0.00017  \n",
       "14                                        nan ± nan  0.03380 ± 0.00020  \n",
       "15                                  0.7187 ± 0.0037  0.00471 ± 0.00003  \n",
       "16                                  0.8585 ± 0.0104  0.01171 ± 0.00011  \n",
       "17                                        nan ± nan  0.00449 ± 0.00005  \n",
       "18                                        nan ± nan  0.12027 ± 0.00014  \n",
       "19                                  0.8473 ± 0.0178  0.00808 ± 0.00005  \n",
       "20                                     1.5434 ± nan      0.00989 ± nan  \n",
       "21                                     1.2125 ± nan      0.02985 ± nan  \n",
       "22                                     1.5883 ± nan      0.00031 ± nan  \n",
       "23                                     1.0179 ± nan      0.00585 ± nan  \n",
       "24                                     1.2475 ± nan      0.00661 ± nan  \n",
       "\n",
       "[25 rows x 45 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_cols = [\"log\", \"backbone\"] + HP_COLS\n",
    "\n",
    "baseline_grouped = (\n",
    "    baseline\n",
    "    .groupby(group_cols, dropna=False)\n",
    "    .apply(agg_over_seeds)   # deine Funktion von oben\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "score_col = \"mt_score_mean\"\n",
    "if score_col not in baseline_grouped.columns:\n",
    "    score_col = \"test_next_activity_acc_mean\"\n",
    "\n",
    "idx_best = (\n",
    "    baseline_grouped\n",
    "    .groupby([\"log\", \"backbone\"])[score_col]\n",
    "    .idxmax()\n",
    ")\n",
    "baseline_best = baseline_grouped.loc[idx_best].reset_index(drop=True)\n",
    "\n",
    "baseline_all = pd.concat([baseline_best, majority_grouped], ignore_index=True)\n",
    "\n",
    "DATASET_MAP = {\n",
    "    \"BPI12\": \"BPI12\",\n",
    "    \"BPI17\": \"BPI17\",\n",
    "    \"BPI20PrepaidTravelCosts\": \"BPI20PTC\",\n",
    "    \"BPI20RequestForPayment\": \"BPI20RfP\",\n",
    "    \"BPI20TravelPermitData\": \"BPI20TPD\",\n",
    "}\n",
    "BACKBONE_MAP = {\n",
    "    \"majority\": \"Majority\",\n",
    "    \"rnn\": \"RNN\",\n",
    "    \"transformer\": \"Transformer\",\n",
    "    \"tabpfn\": \"TabPFN\",\n",
    "    \"saprpt\": \"SAP-RPT\",\n",
    "}\n",
    "\n",
    "baseline_all[\"Dataset\"] = baseline_all[\"log\"].map(DATASET_MAP).fillna(baseline_all[\"log\"])\n",
    "baseline_all[\"Backbone_pretty\"] = baseline_all[\"backbone\"].map(BACKBONE_MAP).fillna(baseline_all[\"backbone\"])\n",
    "\n",
    "for m in METRICS:\n",
    "    mean_col = m + \"_mean\"\n",
    "    std_col  = m + \"_std\"\n",
    "    if mean_col in baseline_all.columns and std_col in baseline_all.columns:\n",
    "        baseline_all[m + \"_mean_std\"] = (\n",
    "            baseline_all[mean_col].round(4).astype(str)\n",
    "            + \" ± \"\n",
    "            + baseline_all[std_col].round(4).astype(str)\n",
    "        )\n",
    "        \n",
    "if \"_runtime_mean\" in baseline_all.columns:\n",
    "    baseline_all[\"runtime_mean_h\"] = baseline_all[\"_runtime_mean\"] / 3600.0\n",
    "if \"_runtime_std\" in baseline_all.columns:\n",
    "    baseline_all[\"runtime_std_h\"]  = baseline_all[\"_runtime_std\"]  / 3600.0\n",
    "\n",
    "if {\"runtime_mean_h\", \"runtime_std_h\"}.issubset(baseline_all.columns):\n",
    "    mean_str = baseline_all[\"runtime_mean_h\"].map(lambda x: f\"{x:.5f}\")\n",
    "    std_str  = baseline_all[\"runtime_std_h\"].map(lambda x: f\"{x:.5f}\")\n",
    "\n",
    "    baseline_all[\"Runtime (h)\"] = mean_str + \" ± \" + std_str\n",
    "    \n",
    "cols_to_drop = [\"_runtime_mean\", \"_runtime_std\", \"runtime_mean_h\", \"runtime_std_h\"]\n",
    "cols_to_drop = [c for c in cols_to_drop if c in baseline_all.columns]\n",
    "\n",
    "baseline_all = baseline_all.drop(columns=cols_to_drop)\n",
    "\n",
    "csv_path = os.path.join(output_dir_csv, \"baseline_best_settings_mean_std.csv\")\n",
    "baseline_all.to_csv(csv_path, index=False)\n",
    "print(\"Saved baseline summary to:\", csv_path)\n",
    "\n",
    "baseline_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "872e9b00",
   "metadata": {
    "title": "Multi-task models"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Hyperparameter columns: ['batch_size', 'embedding_size', 'epochs', 'freeze_layers', 'grad_clip', 'hidden_size', 'lr', 'n_layers', 'rnn_type', 'strategy', 'weight_decay', 'lora_alpha', 'r', 'few_shot_k']\n",
      "Saved LLM summary to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/llm_all_settings_by_method_mean_std.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "      <th>backbone</th>\n",
       "      <th>Setting</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>embedding_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>freeze_layers</th>\n",
       "      <th>grad_clip</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>...</th>\n",
       "      <th>Backbone_pretty</th>\n",
       "      <th>test_next_activity_acc_mean_std</th>\n",
       "      <th>test_next_activity_loss_mean_std</th>\n",
       "      <th>test_next_remaining_time_loss_mean_std</th>\n",
       "      <th>test_next_time_to_next_event_loss_mean_std</th>\n",
       "      <th>best_test_next_activity_acc_mean_std</th>\n",
       "      <th>best_test_next_activity_loss_mean_std</th>\n",
       "      <th>best_test_next_remaining_time_loss_mean_std</th>\n",
       "      <th>best_test_next_time_to_next_event_loss_mean_std</th>\n",
       "      <th>Runtime (h)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>FewShot-Freezing</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.0799 ± 0.0341</td>\n",
       "      <td>3.6757 ± 0.2217</td>\n",
       "      <td>1.712 ± 0.236</td>\n",
       "      <td>1.609 ± 0.0568</td>\n",
       "      <td>0.0876 ± 0.0281</td>\n",
       "      <td>3.4803 ± 0.1926</td>\n",
       "      <td>1.3363 ± 0.123</td>\n",
       "      <td>1.5519 ± 0.0226</td>\n",
       "      <td>0.11437 ± 0.00098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>FewShot-LoRA</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.0751 ± 0.0496</td>\n",
       "      <td>4.1549 ± 0.8314</td>\n",
       "      <td>3.5247 ± 2.3271</td>\n",
       "      <td>2.502 ± 1.3303</td>\n",
       "      <td>0.0953 ± 0.0496</td>\n",
       "      <td>3.1654 ± 0.2169</td>\n",
       "      <td>1.4307 ± 0.2371</td>\n",
       "      <td>1.6082 ± 0.0677</td>\n",
       "      <td>0.14829 ± 0.00058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.3912 ± 0.0314</td>\n",
       "      <td>1.4898 ± 0.0318</td>\n",
       "      <td>2.0048 ± 0.0841</td>\n",
       "      <td>1.5121 ± 0.0317</td>\n",
       "      <td>0.4028 ± 0.0211</td>\n",
       "      <td>1.4816 ± 0.0364</td>\n",
       "      <td>1.9842 ± 0.0928</td>\n",
       "      <td>1.4755 ± 0.0157</td>\n",
       "      <td>0.63840 ± 0.00268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>Freezing-[-1, -2]</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>10</td>\n",
       "      <td>-1,-2</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.7409 ± 0.0644</td>\n",
       "      <td>0.7587 ± 0.1567</td>\n",
       "      <td>2.9607 ± 0.0668</td>\n",
       "      <td>1.407 ± 0.0574</td>\n",
       "      <td>0.7921 ± 0.0109</td>\n",
       "      <td>0.6666 ± 0.0472</td>\n",
       "      <td>2.1902 ± 0.1723</td>\n",
       "      <td>1.3602 ± 0.0079</td>\n",
       "      <td>0.70089 ± 0.00147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>Freezing-[-1]</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.7481 ± 0.0678</td>\n",
       "      <td>0.8252 ± 0.3164</td>\n",
       "      <td>2.6484 ± 0.1867</td>\n",
       "      <td>1.4281 ± 0.0205</td>\n",
       "      <td>0.8007 ± 0.0061</td>\n",
       "      <td>0.6464 ± 0.0429</td>\n",
       "      <td>2.2036 ± 0.1755</td>\n",
       "      <td>1.3601 ± 0.0117</td>\n",
       "      <td>0.66969 ± 0.00339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>Freezing-[0, 1]</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>10</td>\n",
       "      <td>0,1</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.7328 ± 0.0603</td>\n",
       "      <td>0.7753 ± 0.0927</td>\n",
       "      <td>2.413 ± 0.1309</td>\n",
       "      <td>1.3021 ± 0.0234</td>\n",
       "      <td>0.797 ± 0.0121</td>\n",
       "      <td>0.6983 ± 0.0244</td>\n",
       "      <td>2.3113 ± 0.1783</td>\n",
       "      <td>1.2989 ± 0.019</td>\n",
       "      <td>0.70158 ± 0.00118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>Freezing-[0]</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.7857 ± 0.0103</td>\n",
       "      <td>0.729 ± 0.0074</td>\n",
       "      <td>2.4203 ± 0.1474</td>\n",
       "      <td>1.3369 ± 0.0233</td>\n",
       "      <td>0.7933 ± 0.0051</td>\n",
       "      <td>0.7206 ± 0.0217</td>\n",
       "      <td>2.2122 ± 0.0645</td>\n",
       "      <td>1.3219 ± 0.0238</td>\n",
       "      <td>0.67204 ± 0.00218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>LoRA</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.7726 ± 0.0182</td>\n",
       "      <td>0.6433 ± 0.0493</td>\n",
       "      <td>2.6577 ± 0.2777</td>\n",
       "      <td>1.4247 ± 0.0643</td>\n",
       "      <td>0.8033 ± 0.0094</td>\n",
       "      <td>0.5982 ± 0.0168</td>\n",
       "      <td>1.912 ± 0.1038</td>\n",
       "      <td>1.3099 ± 0.0157</td>\n",
       "      <td>0.72725 ± 0.00116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gemma-2-2b</td>\n",
       "      <td>ZeroShot</td>\n",
       "      <td>8</td>\n",
       "      <td>2304</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>Gemma-2-2B</td>\n",
       "      <td>0.0298 ± 0.0184</td>\n",
       "      <td>4.4444 ± 0.6145</td>\n",
       "      <td>4.3306 ± 3.2487</td>\n",
       "      <td>3.6357 ± 2.514</td>\n",
       "      <td>0.0298 ± 0.0184</td>\n",
       "      <td>4.4444 ± 0.6145</td>\n",
       "      <td>4.3306 ± 3.2487</td>\n",
       "      <td>3.6357 ± 2.514</td>\n",
       "      <td>0.01072 ± 0.00068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>FewShot-Freezing</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>768</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.0372 ± 0.0315</td>\n",
       "      <td>3.5797 ± 0.3214</td>\n",
       "      <td>1.9015 ± 0.8402</td>\n",
       "      <td>1.6738 ± 0.0887</td>\n",
       "      <td>0.0387 ± 0.0323</td>\n",
       "      <td>3.5797 ± 0.3214</td>\n",
       "      <td>1.8622 ± 0.8651</td>\n",
       "      <td>1.5788 ± 0.0816</td>\n",
       "      <td>0.00966 ± 0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>FewShot-LoRA</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>768</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.066 ± 0.0435</td>\n",
       "      <td>3.7202 ± 0.3176</td>\n",
       "      <td>2.3615 ± 0.6155</td>\n",
       "      <td>1.8859 ± 0.3613</td>\n",
       "      <td>0.1164 ± 0.0438</td>\n",
       "      <td>3.2111 ± 0.0963</td>\n",
       "      <td>1.4217 ± 0.2947</td>\n",
       "      <td>1.5557 ± 0.0218</td>\n",
       "      <td>0.01476 ± 0.00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>768</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.4803 ± 0.0131</td>\n",
       "      <td>1.5799 ± 0.0667</td>\n",
       "      <td>2.4276 ± 0.1278</td>\n",
       "      <td>1.4812 ± 0.0203</td>\n",
       "      <td>0.4837 ± 0.0199</td>\n",
       "      <td>1.5797 ± 0.0667</td>\n",
       "      <td>2.2677 ± 0.0831</td>\n",
       "      <td>1.4791 ± 0.0194</td>\n",
       "      <td>0.05725 ± 0.00027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Freezing-[-1, -2]</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>10</td>\n",
       "      <td>-1,-2</td>\n",
       "      <td>5</td>\n",
       "      <td>768</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.6947 ± 0.0256</td>\n",
       "      <td>0.9061 ± 0.057</td>\n",
       "      <td>2.6129 ± 0.1035</td>\n",
       "      <td>1.462 ± 0.0251</td>\n",
       "      <td>0.6954 ± 0.0242</td>\n",
       "      <td>0.9034 ± 0.0582</td>\n",
       "      <td>2.026 ± 0.1606</td>\n",
       "      <td>1.4404 ± 0.0239</td>\n",
       "      <td>0.06356 ± 0.00019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Freezing-[-1]</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>768</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.6911 ± 0.0075</td>\n",
       "      <td>0.9258 ± 0.039</td>\n",
       "      <td>2.4571 ± 0.0836</td>\n",
       "      <td>1.4513 ± 0.0207</td>\n",
       "      <td>0.6911 ± 0.0075</td>\n",
       "      <td>0.9258 ± 0.039</td>\n",
       "      <td>2.0822 ± 0.1661</td>\n",
       "      <td>1.4288 ± 0.0158</td>\n",
       "      <td>0.06041 ± 0.00019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>Freezing-[0, 1]</td>\n",
       "      <td>8</td>\n",
       "      <td>768</td>\n",
       "      <td>10</td>\n",
       "      <td>0,1</td>\n",
       "      <td>5</td>\n",
       "      <td>768</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>...</td>\n",
       "      <td>GPT2</td>\n",
       "      <td>0.7404 ± 0.0289</td>\n",
       "      <td>0.7458 ± 0.0581</td>\n",
       "      <td>2.4466 ± 0.0754</td>\n",
       "      <td>1.4039 ± 0.0141</td>\n",
       "      <td>0.7568 ± 0.0197</td>\n",
       "      <td>0.7256 ± 0.0445</td>\n",
       "      <td>2.1075 ± 0.1452</td>\n",
       "      <td>1.3891 ± 0.0152</td>\n",
       "      <td>0.06336 ± 0.00018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      log    backbone            Setting  batch_size  embedding_size  epochs  \\\n",
       "0   BPI12  gemma-2-2b   FewShot-Freezing           8            2304      10   \n",
       "1   BPI12  gemma-2-2b       FewShot-LoRA           8            2304      10   \n",
       "2   BPI12  gemma-2-2b           Freezing           8            2304      10   \n",
       "3   BPI12  gemma-2-2b  Freezing-[-1, -2]           8            2304      10   \n",
       "4   BPI12  gemma-2-2b      Freezing-[-1]           8            2304      10   \n",
       "5   BPI12  gemma-2-2b    Freezing-[0, 1]           8            2304      10   \n",
       "6   BPI12  gemma-2-2b       Freezing-[0]           8            2304      10   \n",
       "7   BPI12  gemma-2-2b               LoRA           8            2304      10   \n",
       "8   BPI12  gemma-2-2b           ZeroShot           8            2304       0   \n",
       "9   BPI12        gpt2   FewShot-Freezing           8             768      10   \n",
       "10  BPI12        gpt2       FewShot-LoRA           8             768      10   \n",
       "11  BPI12        gpt2           Freezing           8             768      10   \n",
       "12  BPI12        gpt2  Freezing-[-1, -2]           8             768      10   \n",
       "13  BPI12        gpt2      Freezing-[-1]           8             768      10   \n",
       "14  BPI12        gpt2    Freezing-[0, 1]           8             768      10   \n",
       "\n",
       "   freeze_layers  grad_clip  hidden_size       lr  ...  Backbone_pretty  \\\n",
       "0            NaN          5         2304  0.00005  ...       Gemma-2-2B   \n",
       "1            NaN          5         2304  0.00005  ...       Gemma-2-2B   \n",
       "2            NaN          5         2304  0.00005  ...       Gemma-2-2B   \n",
       "3          -1,-2          5         2304  0.00005  ...       Gemma-2-2B   \n",
       "4             -1          5         2304  0.00005  ...       Gemma-2-2B   \n",
       "5            0,1          5         2304  0.00005  ...       Gemma-2-2B   \n",
       "6              0          5         2304  0.00005  ...       Gemma-2-2B   \n",
       "7            NaN          5         2304  0.00005  ...       Gemma-2-2B   \n",
       "8            NaN          5         2304  0.00005  ...       Gemma-2-2B   \n",
       "9            NaN          5          768  0.00005  ...             GPT2   \n",
       "10           NaN          5          768  0.00005  ...             GPT2   \n",
       "11           NaN          5          768  0.00005  ...             GPT2   \n",
       "12         -1,-2          5          768  0.00005  ...             GPT2   \n",
       "13            -1          5          768  0.00005  ...             GPT2   \n",
       "14           0,1          5          768  0.00005  ...             GPT2   \n",
       "\n",
       "   test_next_activity_acc_mean_std test_next_activity_loss_mean_std  \\\n",
       "0                  0.0799 ± 0.0341                  3.6757 ± 0.2217   \n",
       "1                  0.0751 ± 0.0496                  4.1549 ± 0.8314   \n",
       "2                  0.3912 ± 0.0314                  1.4898 ± 0.0318   \n",
       "3                  0.7409 ± 0.0644                  0.7587 ± 0.1567   \n",
       "4                  0.7481 ± 0.0678                  0.8252 ± 0.3164   \n",
       "5                  0.7328 ± 0.0603                  0.7753 ± 0.0927   \n",
       "6                  0.7857 ± 0.0103                   0.729 ± 0.0074   \n",
       "7                  0.7726 ± 0.0182                  0.6433 ± 0.0493   \n",
       "8                  0.0298 ± 0.0184                  4.4444 ± 0.6145   \n",
       "9                  0.0372 ± 0.0315                  3.5797 ± 0.3214   \n",
       "10                  0.066 ± 0.0435                  3.7202 ± 0.3176   \n",
       "11                 0.4803 ± 0.0131                  1.5799 ± 0.0667   \n",
       "12                 0.6947 ± 0.0256                   0.9061 ± 0.057   \n",
       "13                 0.6911 ± 0.0075                   0.9258 ± 0.039   \n",
       "14                 0.7404 ± 0.0289                  0.7458 ± 0.0581   \n",
       "\n",
       "    test_next_remaining_time_loss_mean_std  \\\n",
       "0                            1.712 ± 0.236   \n",
       "1                          3.5247 ± 2.3271   \n",
       "2                          2.0048 ± 0.0841   \n",
       "3                          2.9607 ± 0.0668   \n",
       "4                          2.6484 ± 0.1867   \n",
       "5                           2.413 ± 0.1309   \n",
       "6                          2.4203 ± 0.1474   \n",
       "7                          2.6577 ± 0.2777   \n",
       "8                          4.3306 ± 3.2487   \n",
       "9                          1.9015 ± 0.8402   \n",
       "10                         2.3615 ± 0.6155   \n",
       "11                         2.4276 ± 0.1278   \n",
       "12                         2.6129 ± 0.1035   \n",
       "13                         2.4571 ± 0.0836   \n",
       "14                         2.4466 ± 0.0754   \n",
       "\n",
       "    test_next_time_to_next_event_loss_mean_std  \\\n",
       "0                               1.609 ± 0.0568   \n",
       "1                               2.502 ± 1.3303   \n",
       "2                              1.5121 ± 0.0317   \n",
       "3                               1.407 ± 0.0574   \n",
       "4                              1.4281 ± 0.0205   \n",
       "5                              1.3021 ± 0.0234   \n",
       "6                              1.3369 ± 0.0233   \n",
       "7                              1.4247 ± 0.0643   \n",
       "8                               3.6357 ± 2.514   \n",
       "9                              1.6738 ± 0.0887   \n",
       "10                             1.8859 ± 0.3613   \n",
       "11                             1.4812 ± 0.0203   \n",
       "12                              1.462 ± 0.0251   \n",
       "13                             1.4513 ± 0.0207   \n",
       "14                             1.4039 ± 0.0141   \n",
       "\n",
       "    best_test_next_activity_acc_mean_std  \\\n",
       "0                        0.0876 ± 0.0281   \n",
       "1                        0.0953 ± 0.0496   \n",
       "2                        0.4028 ± 0.0211   \n",
       "3                        0.7921 ± 0.0109   \n",
       "4                        0.8007 ± 0.0061   \n",
       "5                         0.797 ± 0.0121   \n",
       "6                        0.7933 ± 0.0051   \n",
       "7                        0.8033 ± 0.0094   \n",
       "8                        0.0298 ± 0.0184   \n",
       "9                        0.0387 ± 0.0323   \n",
       "10                       0.1164 ± 0.0438   \n",
       "11                       0.4837 ± 0.0199   \n",
       "12                       0.6954 ± 0.0242   \n",
       "13                       0.6911 ± 0.0075   \n",
       "14                       0.7568 ± 0.0197   \n",
       "\n",
       "    best_test_next_activity_loss_mean_std  \\\n",
       "0                         3.4803 ± 0.1926   \n",
       "1                         3.1654 ± 0.2169   \n",
       "2                         1.4816 ± 0.0364   \n",
       "3                         0.6666 ± 0.0472   \n",
       "4                         0.6464 ± 0.0429   \n",
       "5                         0.6983 ± 0.0244   \n",
       "6                         0.7206 ± 0.0217   \n",
       "7                         0.5982 ± 0.0168   \n",
       "8                         4.4444 ± 0.6145   \n",
       "9                         3.5797 ± 0.3214   \n",
       "10                        3.2111 ± 0.0963   \n",
       "11                        1.5797 ± 0.0667   \n",
       "12                        0.9034 ± 0.0582   \n",
       "13                         0.9258 ± 0.039   \n",
       "14                        0.7256 ± 0.0445   \n",
       "\n",
       "    best_test_next_remaining_time_loss_mean_std  \\\n",
       "0                                1.3363 ± 0.123   \n",
       "1                               1.4307 ± 0.2371   \n",
       "2                               1.9842 ± 0.0928   \n",
       "3                               2.1902 ± 0.1723   \n",
       "4                               2.2036 ± 0.1755   \n",
       "5                               2.3113 ± 0.1783   \n",
       "6                               2.2122 ± 0.0645   \n",
       "7                                1.912 ± 0.1038   \n",
       "8                               4.3306 ± 3.2487   \n",
       "9                               1.8622 ± 0.8651   \n",
       "10                              1.4217 ± 0.2947   \n",
       "11                              2.2677 ± 0.0831   \n",
       "12                               2.026 ± 0.1606   \n",
       "13                              2.0822 ± 0.1661   \n",
       "14                              2.1075 ± 0.1452   \n",
       "\n",
       "    best_test_next_time_to_next_event_loss_mean_std        Runtime (h)  \n",
       "0                                   1.5519 ± 0.0226  0.11437 ± 0.00098  \n",
       "1                                   1.6082 ± 0.0677  0.14829 ± 0.00058  \n",
       "2                                   1.4755 ± 0.0157  0.63840 ± 0.00268  \n",
       "3                                   1.3602 ± 0.0079  0.70089 ± 0.00147  \n",
       "4                                   1.3601 ± 0.0117  0.66969 ± 0.00339  \n",
       "5                                    1.2989 ± 0.019  0.70158 ± 0.00118  \n",
       "6                                   1.3219 ± 0.0238  0.67204 ± 0.00218  \n",
       "7                                   1.3099 ± 0.0157  0.72725 ± 0.00116  \n",
       "8                                    3.6357 ± 2.514  0.01072 ± 0.00068  \n",
       "9                                   1.5788 ± 0.0816  0.00966 ± 0.00005  \n",
       "10                                  1.5557 ± 0.0218  0.01476 ± 0.00008  \n",
       "11                                  1.4791 ± 0.0194  0.05725 ± 0.00027  \n",
       "12                                  1.4404 ± 0.0239  0.06356 ± 0.00019  \n",
       "13                                  1.4288 ± 0.0158  0.06041 ± 0.00019  \n",
       "14                                  1.3891 ± 0.0152  0.06336 ± 0.00018  \n",
       "\n",
       "[15 rows x 49 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM_BACKBONES = [\"gpt2\", \"gptneo-1b3\", \"qwen25-05b\", \"llama32-1b\", \"gemma-2-2b\"]\n",
    "\n",
    "llm = df[df[\"backbone\"].isin(LLM_BACKBONES)].copy()\n",
    "\n",
    "llm[\"Setting\"] = llm.apply(map_setting, axis=1)\n",
    "\n",
    "NON_HP_COLS_LLM = set(NON_HP_COLS)\n",
    "for col in [\"lora_alpha\", \"r\", \"few_shot_k\"]:\n",
    "    NON_HP_COLS_LLM.discard(col)\n",
    "NON_HP_COLS_LLM.add(\"Setting\")\n",
    "\n",
    "HP_COLS_LLM = [c for c in llm.columns if c not in NON_HP_COLS_LLM]\n",
    "print(\"LLM Hyperparameter columns:\", HP_COLS_LLM)\n",
    "\n",
    "group_cols_llm = [\"log\", \"backbone\", \"Setting\"] + HP_COLS_LLM\n",
    "\n",
    "llm_grouped = (\n",
    "    llm\n",
    "    .groupby(group_cols_llm, dropna=False)\n",
    "    .apply(agg_over_seeds)   # gleiche Funktion wie bei Baselines\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "score_col = \"mt_score_mean\"\n",
    "if score_col not in llm_grouped.columns:\n",
    "    score_col = \"test_next_activity_acc_mean\"\n",
    "\n",
    "idx_best_llm = (\n",
    "    llm_grouped\n",
    "    .groupby([\"log\", \"backbone\", \"Setting\"])[score_col]\n",
    "    .idxmax()\n",
    ")\n",
    "\n",
    "llm_all = llm_grouped.loc[idx_best_llm].reset_index(drop=True)\n",
    "\n",
    "BACKBONE_MAP_LLM = {\n",
    "    \"gpt2\":         \"GPT2\",\n",
    "    \"gptneo-1b3\":   \"GPT-Neo-1.3B\",\n",
    "    \"qwen25-05b\":   \"Qwen2.5-0.5B\",\n",
    "    \"llama32-1b\":   \"Llama3.2-1B\",\n",
    "    \"gemma-2-2b\":   \"Gemma-2-2B\",\n",
    "}\n",
    "\n",
    "llm_all[\"Dataset\"] = llm_all[\"log\"].map(DATASET_MAP).fillna(llm_all[\"log\"])\n",
    "llm_all[\"Backbone_pretty\"] = llm_all[\"backbone\"].map(BACKBONE_MAP_LLM).fillna(llm_all[\"backbone\"])\n",
    "\n",
    "for m in METRICS:\n",
    "    mean_col = m + \"_mean\"\n",
    "    std_col  = m + \"_std\"\n",
    "    if mean_col in llm_all.columns and std_col in llm_all.columns:\n",
    "        llm_all[m + \"_mean_std\"] = (\n",
    "            llm_all[mean_col].round(4).astype(str)\n",
    "            + \" ± \"\n",
    "            + llm_all[std_col].round(4).astype(str)\n",
    "        )\n",
    "        \n",
    "if \"_runtime_mean\" in llm_all.columns:\n",
    "    llm_all[\"runtime_mean_h\"] = llm_all[\"_runtime_mean\"] / 3600.0\n",
    "if \"_runtime_std\" in llm_all.columns:\n",
    "    llm_all[\"runtime_std_h\"]  = llm_all[\"_runtime_std\"]  / 3600.0\n",
    "\n",
    "if {\"runtime_mean_h\", \"runtime_std_h\"}.issubset(llm_all.columns):\n",
    "    mean_str = llm_all[\"runtime_mean_h\"].map(lambda x: f\"{x:.5f}\")\n",
    "    std_str  = llm_all[\"runtime_std_h\"].map(lambda x: f\"{x:.5f}\")\n",
    "    llm_all[\"Runtime (h)\"] = mean_str + \" ± \" + std_str\n",
    "\n",
    "cols_to_drop_llm = [\"_runtime_mean\", \"_runtime_std\", \"runtime_mean_h\", \"runtime_std_h\"]\n",
    "cols_to_drop_llm = [c for c in cols_to_drop_llm if c in llm_all.columns]\n",
    "llm_all = llm_all.drop(columns=cols_to_drop_llm)\n",
    "\n",
    "csv_path = os.path.join(output_dir_csv, \"llm_all_settings_by_method_mean_std.csv\")\n",
    "llm_all.to_csv(csv_path, index=False)\n",
    "print(\"Saved LLM summary to:\", csv_path)\n",
    "\n",
    "llm_all.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6952eb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting\n",
      "LoRA                 729\n",
      "Freezing-[-1, -2]    125\n",
      "Freezing-[0, 1]      125\n",
      "Freezing-[0]         125\n",
      "Freezing-[-1]        125\n",
      "Freezing             125\n",
      "ZeroShot             125\n",
      "FewShot-Freezing     125\n",
      "FewShot-LoRA         125\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "llm[\"Setting\"] = llm.apply(map_setting, axis=1)\n",
    "print(llm[\"Setting\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83d95d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined multi-task table to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/multi_task_benchmark_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "      <th>backbone</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>embedding_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>freeze_layers</th>\n",
       "      <th>grad_clip</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>...</th>\n",
       "      <th>test_next_time_to_next_event_loss_mean_std</th>\n",
       "      <th>best_test_next_activity_acc_mean_std</th>\n",
       "      <th>best_test_next_activity_loss_mean_std</th>\n",
       "      <th>best_test_next_remaining_time_loss_mean_std</th>\n",
       "      <th>best_test_next_time_to_next_event_loss_mean_std</th>\n",
       "      <th>Runtime (h)</th>\n",
       "      <th>Setting</th>\n",
       "      <th>lora_alpha</th>\n",
       "      <th>r</th>\n",
       "      <th>few_shot_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gptneo-1b3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7584 ± 0.1475</td>\n",
       "      <td>0.0734 ± 0.0279</td>\n",
       "      <td>3.3621 ± 0.3649</td>\n",
       "      <td>1.5616 ± 0.2029</td>\n",
       "      <td>1.6504 ± 0.1312</td>\n",
       "      <td>0.07263 ± 0.00036</td>\n",
       "      <td>FewShot-Freezing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gptneo-1b3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8453 ± 0.314</td>\n",
       "      <td>0.1002 ± 0.0504</td>\n",
       "      <td>3.1159 ± 0.0594</td>\n",
       "      <td>1.4986 ± 0.4039</td>\n",
       "      <td>1.5639 ± 0.0325</td>\n",
       "      <td>0.07842 ± 0.00021</td>\n",
       "      <td>FewShot-LoRA</td>\n",
       "      <td>512.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gptneo-1b3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.531 ± 0.0338</td>\n",
       "      <td>0.5736 ± 0.0769</td>\n",
       "      <td>1.4783 ± 0.3746</td>\n",
       "      <td>2.2858 ± 0.1486</td>\n",
       "      <td>1.4952 ± 0.0342</td>\n",
       "      <td>0.40460 ± 0.00102</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gptneo-1b3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1,-2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5124 ± 0.0677</td>\n",
       "      <td>0.5663 ± 0.071</td>\n",
       "      <td>1.4508 ± 0.2137</td>\n",
       "      <td>2.3459 ± 0.1544</td>\n",
       "      <td>1.4892 ± 0.0518</td>\n",
       "      <td>0.44785 ± 0.00081</td>\n",
       "      <td>Freezing-[-1, -2]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BPI12</td>\n",
       "      <td>gptneo-1b3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5131 ± 0.0366</td>\n",
       "      <td>0.5474 ± 0.0859</td>\n",
       "      <td>1.4897 ± 0.2106</td>\n",
       "      <td>2.3335 ± 0.0808</td>\n",
       "      <td>1.492 ± 0.0327</td>\n",
       "      <td>0.42557 ± 0.00100</td>\n",
       "      <td>Freezing-[-1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     log    backbone  batch_size  embedding_size  epochs freeze_layers  \\\n",
       "0  BPI12  gptneo-1b3         8.0          2048.0    10.0           NaN   \n",
       "1  BPI12  gptneo-1b3         8.0          2048.0    10.0           NaN   \n",
       "2  BPI12  gptneo-1b3         8.0          2048.0    10.0           NaN   \n",
       "3  BPI12  gptneo-1b3         8.0          2048.0    10.0         -1,-2   \n",
       "4  BPI12  gptneo-1b3         8.0          2048.0    10.0            -1   \n",
       "\n",
       "   grad_clip  hidden_size       lr  n_layers  ...  \\\n",
       "0        5.0       2048.0  0.00005       1.0  ...   \n",
       "1        5.0       2048.0  0.00005       1.0  ...   \n",
       "2        5.0       2048.0  0.00005       1.0  ...   \n",
       "3        5.0       2048.0  0.00005       1.0  ...   \n",
       "4        5.0       2048.0  0.00005       1.0  ...   \n",
       "\n",
       "  test_next_time_to_next_event_loss_mean_std  \\\n",
       "0                            1.7584 ± 0.1475   \n",
       "1                             1.8453 ± 0.314   \n",
       "2                             1.531 ± 0.0338   \n",
       "3                            1.5124 ± 0.0677   \n",
       "4                            1.5131 ± 0.0366   \n",
       "\n",
       "  best_test_next_activity_acc_mean_std  best_test_next_activity_loss_mean_std  \\\n",
       "0                      0.0734 ± 0.0279                        3.3621 ± 0.3649   \n",
       "1                      0.1002 ± 0.0504                        3.1159 ± 0.0594   \n",
       "2                      0.5736 ± 0.0769                        1.4783 ± 0.3746   \n",
       "3                       0.5663 ± 0.071                        1.4508 ± 0.2137   \n",
       "4                      0.5474 ± 0.0859                        1.4897 ± 0.2106   \n",
       "\n",
       "   best_test_next_remaining_time_loss_mean_std  \\\n",
       "0                              1.5616 ± 0.2029   \n",
       "1                              1.4986 ± 0.4039   \n",
       "2                              2.2858 ± 0.1486   \n",
       "3                              2.3459 ± 0.1544   \n",
       "4                              2.3335 ± 0.0808   \n",
       "\n",
       "   best_test_next_time_to_next_event_loss_mean_std        Runtime (h)  \\\n",
       "0                                  1.6504 ± 0.1312  0.07263 ± 0.00036   \n",
       "1                                  1.5639 ± 0.0325  0.07842 ± 0.00021   \n",
       "2                                  1.4952 ± 0.0342  0.40460 ± 0.00102   \n",
       "3                                  1.4892 ± 0.0518  0.44785 ± 0.00081   \n",
       "4                                   1.492 ± 0.0327  0.42557 ± 0.00100   \n",
       "\n",
       "             Setting  lora_alpha      r  few_shot_k  \n",
       "0   FewShot-Freezing         NaN    NaN         8.0  \n",
       "1       FewShot-LoRA       512.0  256.0         8.0  \n",
       "2           Freezing         NaN    NaN         NaN  \n",
       "3  Freezing-[-1, -2]         NaN    NaN         NaN  \n",
       "4      Freezing-[-1]         NaN    NaN         NaN  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi = pd.concat([baseline_all, llm_all], ignore_index=True, sort=False)\n",
    "\n",
    "multi = (\n",
    "    multi\n",
    "    .sort_values([\"Dataset\", \"Backbone_pretty\", \"Setting\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "csv_path = os.path.join(output_dir_csv, \"multi_task_benchmark_results.csv\")\n",
    "multi.to_csv(csv_path, index=False)\n",
    "print(\"Saved combined multi-task table to:\", csv_path)\n",
    "\n",
    "multi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa585d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved per-log table for BPI12 to /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/multi_task_benchmark_results_BPI12.csv\n",
      "Saved per-log table for BPI17 to /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/multi_task_benchmark_results_BPI17.csv\n",
      "Saved per-log table for BPI20PrepaidTravelCosts to /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/multi_task_benchmark_results_BPI20PrepaidTravelCosts.csv\n",
      "Saved per-log table for BPI20RequestForPayment to /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/multi_task_benchmark_results_BPI20RequestForPayment.csv\n",
      "Saved per-log table for BPI20TravelPermitData to /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/multi_task_benchmark_results_BPI20TravelPermitData.csv\n"
     ]
    }
   ],
   "source": [
    "multi_path = os.path.join(output_dir_csv, \"multi_task_benchmark_results.csv\")\n",
    "multi = pd.read_csv(multi_path)\n",
    "\n",
    "for log_name, df_log in multi.groupby(\"log\"):\n",
    "    log_dir = os.path.join(output_dir_csv, \"per_dataset\", log_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    csv_path = os.path.join(log_dir, f\"multi_task_benchmark_results_{log_name}.csv\")\n",
    "    \n",
    "    df_log.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved per-log table for {log_name} to {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0c13022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LLM methods table for log=BPI12, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/llm_methods_BPI12_gemma-2-2b.csv\n",
      "Saved LLM methods table for log=BPI12, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/llm_methods_BPI12_gpt2.csv\n",
      "Saved LLM methods table for log=BPI12, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/llm_methods_BPI12_gptneo-1b3.csv\n",
      "Saved LLM methods table for log=BPI12, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/llm_methods_BPI12_llama32-1b.csv\n",
      "Saved LLM methods table for log=BPI12, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/llm_methods_BPI12_qwen25-05b.csv\n",
      "Saved LLM methods table for log=BPI17, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/llm_methods_BPI17_gemma-2-2b.csv\n",
      "Saved LLM methods table for log=BPI17, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/llm_methods_BPI17_gpt2.csv\n",
      "Saved LLM methods table for log=BPI17, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/llm_methods_BPI17_gptneo-1b3.csv\n",
      "Saved LLM methods table for log=BPI17, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/llm_methods_BPI17_llama32-1b.csv\n",
      "Saved LLM methods table for log=BPI17, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/llm_methods_BPI17_qwen25-05b.csv\n",
      "Saved LLM methods table for log=BPI20PrepaidTravelCosts, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/llm_methods_BPI20PrepaidTravelCosts_gemma-2-2b.csv\n",
      "Saved LLM methods table for log=BPI20PrepaidTravelCosts, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/llm_methods_BPI20PrepaidTravelCosts_gpt2.csv\n",
      "Saved LLM methods table for log=BPI20PrepaidTravelCosts, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/llm_methods_BPI20PrepaidTravelCosts_gptneo-1b3.csv\n",
      "Saved LLM methods table for log=BPI20PrepaidTravelCosts, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/llm_methods_BPI20PrepaidTravelCosts_llama32-1b.csv\n",
      "Saved LLM methods table for log=BPI20PrepaidTravelCosts, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/llm_methods_BPI20PrepaidTravelCosts_qwen25-05b.csv\n",
      "Saved LLM methods table for log=BPI20RequestForPayment, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/llm_methods_BPI20RequestForPayment_gemma-2-2b.csv\n",
      "Saved LLM methods table for log=BPI20RequestForPayment, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/llm_methods_BPI20RequestForPayment_gpt2.csv\n",
      "Saved LLM methods table for log=BPI20RequestForPayment, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/llm_methods_BPI20RequestForPayment_gptneo-1b3.csv\n",
      "Saved LLM methods table for log=BPI20RequestForPayment, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/llm_methods_BPI20RequestForPayment_llama32-1b.csv\n",
      "Saved LLM methods table for log=BPI20RequestForPayment, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/llm_methods_BPI20RequestForPayment_qwen25-05b.csv\n",
      "Saved LLM methods table for log=BPI20TravelPermitData, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/llm_methods_BPI20TravelPermitData_gemma-2-2b.csv\n",
      "Saved LLM methods table for log=BPI20TravelPermitData, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/llm_methods_BPI20TravelPermitData_gpt2.csv\n",
      "Saved LLM methods table for log=BPI20TravelPermitData, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/llm_methods_BPI20TravelPermitData_gptneo-1b3.csv\n",
      "Saved LLM methods table for log=BPI20TravelPermitData, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/llm_methods_BPI20TravelPermitData_llama32-1b.csv\n",
      "Saved LLM methods table for log=BPI20TravelPermitData, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/llm_methods_BPI20TravelPermitData_qwen25-05b.csv\n"
     ]
    }
   ],
   "source": [
    "multi_path = os.path.join(output_dir_csv, \"multi_task_benchmark_results.csv\")\n",
    "multi = pd.read_csv(multi_path)\n",
    "\n",
    "LLM_BACKBONES = [\"gpt2\", \"gptneo-1b3\", \"qwen25-05b\", \"llama32-1b\", \"gemma-2-2b\"]\n",
    "\n",
    "llm_multi = multi[multi[\"backbone\"].isin(LLM_BACKBONES)].copy()\n",
    "\n",
    "for (log_name, backbone), df_sub in llm_multi.groupby([\"log\", \"backbone\"]):\n",
    "    log_dir = os.path.join(output_dir_csv, \"per_dataset\", log_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    csv_path = os.path.join(log_dir, f\"llm_methods_{log_name}_{backbone}.csv\")\n",
    "\n",
    "    df_sub.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved LLM methods table for log={log_name}, backbone={backbone} to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0b9f2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved baseline vs LoRA table for BPI12 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/baseline_vs_lora_multi_task_results_BPI12.csv\n",
      "Saved baseline vs LoRA table for BPI17 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/baseline_vs_lora_multi_task_results_BPI17.csv\n",
      "Saved baseline vs LoRA table for BPI20PrepaidTravelCosts to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/baseline_vs_lora_multi_task_results_BPI20PrepaidTravelCosts.csv\n",
      "Saved baseline vs LoRA table for BPI20RequestForPayment to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/baseline_vs_lora_multi_task_results_BPI20RequestForPayment.csv\n",
      "Saved baseline vs LoRA table for BPI20TravelPermitData to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/baseline_vs_lora_multi_task_results_BPI20TravelPermitData.csv\n"
     ]
    }
   ],
   "source": [
    "multi_path = os.path.join(output_dir_csv, \"multi_task_benchmark_results.csv\")\n",
    "multi = pd.read_csv(multi_path)\n",
    "\n",
    "BASELINE_BACKBONES = [\"majority\", \"rnn\", \"transformer\", \"tabpfn\", \"saprpt\"]\n",
    "\n",
    "mask_baseline = multi[\"backbone\"].isin(BASELINE_BACKBONES)\n",
    "mask_llm_lora = (~multi[\"backbone\"].isin(BASELINE_BACKBONES)) & (multi[\"Setting\"] == \"LoRA\")\n",
    "\n",
    "subset = multi[mask_baseline | mask_llm_lora].copy()\n",
    "\n",
    "for log_name, df_log in subset.groupby(\"log\"):\n",
    "\n",
    "    log_dir = os.path.join(output_dir_csv, \"per_dataset\", log_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    csv_path_log = os.path.join(log_dir, f\"baseline_vs_lora_multi_task_results_{log_name}.csv\")\n",
    "\n",
    "    df_log.to_csv(csv_path_log, index=False)\n",
    "    print(f\"Saved baseline vs LoRA table for {log_name} to: {csv_path_log}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1edd3673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LoRA sweeps table for log=BPI12, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/llm_methods_BPI12_gemma-2-2b_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI12, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/llm_methods_BPI12_gpt2_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI12, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/llm_methods_BPI12_gptneo-1b3_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI12, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/llm_methods_BPI12_llama32-1b_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI12, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/llm_methods_BPI12_qwen25-05b_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI17, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/llm_methods_BPI17_gemma-2-2b_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI17, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/llm_methods_BPI17_gpt2_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI17, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/llm_methods_BPI17_gptneo-1b3_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI17, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/llm_methods_BPI17_llama32-1b_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI17, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/llm_methods_BPI17_qwen25-05b_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI20PrepaidTravelCosts, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/llm_methods_BPI20PrepaidTravelCosts_gemma-2-2b_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI20PrepaidTravelCosts, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/llm_methods_BPI20PrepaidTravelCosts_gpt2_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI20PrepaidTravelCosts, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/llm_methods_BPI20PrepaidTravelCosts_gptneo-1b3_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI20PrepaidTravelCosts, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/llm_methods_BPI20PrepaidTravelCosts_llama32-1b_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI20PrepaidTravelCosts, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/llm_methods_BPI20PrepaidTravelCosts_qwen25-05b_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI20RequestForPayment, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/llm_methods_BPI20RequestForPayment_gemma-2-2b_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI20RequestForPayment, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/llm_methods_BPI20RequestForPayment_gpt2_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI20RequestForPayment, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/llm_methods_BPI20RequestForPayment_gptneo-1b3_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI20RequestForPayment, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/llm_methods_BPI20RequestForPayment_llama32-1b_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI20RequestForPayment, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/llm_methods_BPI20RequestForPayment_qwen25-05b_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI20TravelPermitData, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/llm_methods_BPI20TravelPermitData_gemma-2-2b_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI20TravelPermitData, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/llm_methods_BPI20TravelPermitData_gpt2_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI20TravelPermitData, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/llm_methods_BPI20TravelPermitData_gptneo-1b3_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI20TravelPermitData, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/llm_methods_BPI20TravelPermitData_llama32-1b_lora_sweeps.csv\n",
      "Saved LoRA sweeps table for log=BPI20TravelPermitData, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/llm_methods_BPI20TravelPermitData_qwen25-05b_lora_sweeps.csv\n"
     ]
    }
   ],
   "source": [
    "# %% LoRA-Sweeps pro Datensatz & LLM-Backbone (alle HParams, über Seeds aggregiert)\n",
    "\n",
    "LLM_BACKBONES = [\"gpt2\", \"gptneo-1b3\", \"qwen25-05b\", \"llama32-1b\", \"gemma-2-2b\"]\n",
    "\n",
    "# Nur LLM + LoRA\n",
    "lora_sweeps = df[\n",
    "    df[\"backbone\"].isin(LLM_BACKBONES)\n",
    "    & (df[\"fine_tuning\"] == \"lora\")\n",
    "].copy()\n",
    "\n",
    "# Nur \"full\" LoRA (ohne FewShot-LoRA)\n",
    "if \"few_shot_k\" in lora_sweeps.columns:\n",
    "    lora_sweeps = lora_sweeps[lora_sweeps[\"few_shot_k\"].isna()].copy()\n",
    "\n",
    "# Relevante Sweep-Hyperparameter (dein LoRA-Raum)\n",
    "HP_SWEEP_COLS = [\n",
    "    \"lr\",\n",
    "    \"batch_size\",\n",
    "    \"epochs\",\n",
    "    \"r\",\n",
    "    \"lora_alpha\",\n",
    "    \"embedding_size\",\n",
    "    \"hidden_size\",\n",
    "    \"strategy\",\n",
    "]\n",
    "HP_SWEEP_COLS = [c for c in HP_SWEEP_COLS if c in lora_sweeps.columns]\n",
    "\n",
    "# ***Ganz wichtig: hier KEIN idxmax, wir behalten ALLE Kombis***\n",
    "group_cols_sweep = [\"log\", \"backbone\"] + HP_SWEEP_COLS\n",
    "\n",
    "lora_sweeps_grouped = (\n",
    "    lora_sweeps\n",
    "    .groupby(group_cols_sweep, dropna=False)\n",
    "    .apply(agg_over_seeds)   # mittelt nur über Seeds\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "for m in METRICS:\n",
    "    mean_col = m + \"_mean\"\n",
    "    std_col  = m + \"_std\"\n",
    "    if mean_col in lora_sweeps_grouped.columns and std_col in lora_sweeps_grouped.columns:\n",
    "        lora_sweeps_grouped[m + \"_mean_std\"] = (\n",
    "            lora_sweeps_grouped[mean_col].round(4).astype(str)\n",
    "            + \" ± \"\n",
    "            + lora_sweeps_grouped[std_col].round(4).astype(str)\n",
    "        )\n",
    "\n",
    "if \"_runtime_mean\" in lora_sweeps_grouped.columns:\n",
    "    lora_sweeps_grouped[\"runtime_mean_h\"] = lora_sweeps_grouped[\"_runtime_mean\"] / 3600.0\n",
    "if \"_runtime_std\" in lora_sweeps_grouped.columns:\n",
    "    lora_sweeps_grouped[\"runtime_std_h\"]  = lora_sweeps_grouped[\"_runtime_std\"]  / 3600.0\n",
    "\n",
    "if {\"runtime_mean_h\", \"runtime_std_h\"}.issubset(lora_sweeps_grouped.columns):\n",
    "    mean_str = lora_sweeps_grouped[\"runtime_mean_h\"].map(lambda x: f\"{x:.5f}\")\n",
    "    std_str  = lora_sweeps_grouped[\"runtime_std_h\"].map(lambda x: f\"{x:.5f}\")\n",
    "    lora_sweeps_grouped[\"Runtime (h)\"] = mean_str + \" ± \" + std_str\n",
    "\n",
    "cols_to_drop_sweeps = [\"_runtime_mean\", \"_runtime_std\", \"runtime_mean_h\", \"runtime_std_h\"]\n",
    "cols_to_drop_sweeps = [c for c in cols_to_drop_sweeps if c in lora_sweeps_grouped.columns]\n",
    "lora_sweeps_grouped = lora_sweeps_grouped.drop(columns=cols_to_drop_sweeps)\n",
    "\n",
    "for (log_name, backbone), df_sub in lora_sweeps_grouped.groupby([\"log\", \"backbone\"]):\n",
    "    log_dir = os.path.join(output_dir_csv, \"per_dataset\", log_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    out_path = os.path.join(\n",
    "        log_dir,\n",
    "        f\"llm_methods_{log_name}_{backbone}_lora_sweeps.csv\"\n",
    "    )\n",
    "    df_sub.to_csv(out_path, index=False)\n",
    "    print(f\"Saved LoRA sweeps table for log={log_name}, backbone={backbone} to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cd2c47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved detailed boxplot for log=BPI12, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_freezing_BPI12_gemma-2-2b.png\n",
      "Saved collapsed boxplot for log=BPI12, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_collapsed_BPI12_gemma-2-2b.png\n",
      "Saved detailed boxplot for log=BPI12, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_freezing_BPI12_gpt2.png\n",
      "Saved collapsed boxplot for log=BPI12, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_collapsed_BPI12_gpt2.png\n",
      "Saved detailed boxplot for log=BPI12, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_freezing_BPI12_gptneo-1b3.png\n",
      "Saved collapsed boxplot for log=BPI12, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_collapsed_BPI12_gptneo-1b3.png\n",
      "Saved detailed boxplot for log=BPI12, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_freezing_BPI12_llama32-1b.png\n",
      "Saved collapsed boxplot for log=BPI12, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_collapsed_BPI12_llama32-1b.png\n",
      "Saved detailed boxplot for log=BPI12, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_freezing_BPI12_qwen25-05b.png\n",
      "Saved collapsed boxplot for log=BPI12, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_methods_boxplot_collapsed_BPI12_qwen25-05b.png\n",
      "Saved detailed boxplot for log=BPI17, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_freezing_BPI17_gemma-2-2b.png\n",
      "Saved collapsed boxplot for log=BPI17, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_collapsed_BPI17_gemma-2-2b.png\n",
      "Saved detailed boxplot for log=BPI17, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_freezing_BPI17_gpt2.png\n",
      "Saved collapsed boxplot for log=BPI17, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_collapsed_BPI17_gpt2.png\n",
      "Saved detailed boxplot for log=BPI17, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_freezing_BPI17_gptneo-1b3.png\n",
      "Saved collapsed boxplot for log=BPI17, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_collapsed_BPI17_gptneo-1b3.png\n",
      "Saved detailed boxplot for log=BPI17, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_freezing_BPI17_llama32-1b.png\n",
      "Saved collapsed boxplot for log=BPI17, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_collapsed_BPI17_llama32-1b.png\n",
      "Saved detailed boxplot for log=BPI17, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_freezing_BPI17_qwen25-05b.png\n",
      "Saved collapsed boxplot for log=BPI17, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_methods_boxplot_collapsed_BPI17_qwen25-05b.png\n",
      "Saved detailed boxplot for log=BPI20PrepaidTravelCosts, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_freezing_BPI20PrepaidTravelCosts_gemma-2-2b.png\n",
      "Saved collapsed boxplot for log=BPI20PrepaidTravelCosts, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_collapsed_BPI20PrepaidTravelCosts_gemma-2-2b.png\n",
      "Saved detailed boxplot for log=BPI20PrepaidTravelCosts, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_freezing_BPI20PrepaidTravelCosts_gpt2.png\n",
      "Saved collapsed boxplot for log=BPI20PrepaidTravelCosts, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_collapsed_BPI20PrepaidTravelCosts_gpt2.png\n",
      "Saved detailed boxplot for log=BPI20PrepaidTravelCosts, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_freezing_BPI20PrepaidTravelCosts_gptneo-1b3.png\n",
      "Saved collapsed boxplot for log=BPI20PrepaidTravelCosts, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_collapsed_BPI20PrepaidTravelCosts_gptneo-1b3.png\n",
      "Saved detailed boxplot for log=BPI20PrepaidTravelCosts, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_freezing_BPI20PrepaidTravelCosts_llama32-1b.png\n",
      "Saved collapsed boxplot for log=BPI20PrepaidTravelCosts, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_collapsed_BPI20PrepaidTravelCosts_llama32-1b.png\n",
      "Saved detailed boxplot for log=BPI20PrepaidTravelCosts, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_freezing_BPI20PrepaidTravelCosts_qwen25-05b.png\n",
      "Saved collapsed boxplot for log=BPI20PrepaidTravelCosts, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_methods_boxplot_collapsed_BPI20PrepaidTravelCosts_qwen25-05b.png\n",
      "Saved detailed boxplot for log=BPI20RequestForPayment, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_freezing_BPI20RequestForPayment_gemma-2-2b.png\n",
      "Saved collapsed boxplot for log=BPI20RequestForPayment, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_collapsed_BPI20RequestForPayment_gemma-2-2b.png\n",
      "Saved detailed boxplot for log=BPI20RequestForPayment, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_freezing_BPI20RequestForPayment_gpt2.png\n",
      "Saved collapsed boxplot for log=BPI20RequestForPayment, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_collapsed_BPI20RequestForPayment_gpt2.png\n",
      "Saved detailed boxplot for log=BPI20RequestForPayment, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_freezing_BPI20RequestForPayment_gptneo-1b3.png\n",
      "Saved collapsed boxplot for log=BPI20RequestForPayment, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_collapsed_BPI20RequestForPayment_gptneo-1b3.png\n",
      "Saved detailed boxplot for log=BPI20RequestForPayment, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_freezing_BPI20RequestForPayment_llama32-1b.png\n",
      "Saved collapsed boxplot for log=BPI20RequestForPayment, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_collapsed_BPI20RequestForPayment_llama32-1b.png\n",
      "Saved detailed boxplot for log=BPI20RequestForPayment, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_freezing_BPI20RequestForPayment_qwen25-05b.png\n",
      "Saved collapsed boxplot for log=BPI20RequestForPayment, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_methods_boxplot_collapsed_BPI20RequestForPayment_qwen25-05b.png\n",
      "Saved detailed boxplot for log=BPI20TravelPermitData, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_freezing_BPI20TravelPermitData_gemma-2-2b.png\n",
      "Saved collapsed boxplot for log=BPI20TravelPermitData, backbone=gemma-2-2b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_collapsed_BPI20TravelPermitData_gemma-2-2b.png\n",
      "Saved detailed boxplot for log=BPI20TravelPermitData, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_freezing_BPI20TravelPermitData_gpt2.png\n",
      "Saved collapsed boxplot for log=BPI20TravelPermitData, backbone=gpt2 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_collapsed_BPI20TravelPermitData_gpt2.png\n",
      "Saved detailed boxplot for log=BPI20TravelPermitData, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_freezing_BPI20TravelPermitData_gptneo-1b3.png\n",
      "Saved collapsed boxplot for log=BPI20TravelPermitData, backbone=gptneo-1b3 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_collapsed_BPI20TravelPermitData_gptneo-1b3.png\n",
      "Saved detailed boxplot for log=BPI20TravelPermitData, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_freezing_BPI20TravelPermitData_llama32-1b.png\n",
      "Saved collapsed boxplot for log=BPI20TravelPermitData, backbone=llama32-1b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_collapsed_BPI20TravelPermitData_llama32-1b.png\n",
      "Saved detailed boxplot for log=BPI20TravelPermitData, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_freezing_BPI20TravelPermitData_qwen25-05b.png\n",
      "Saved collapsed boxplot for log=BPI20TravelPermitData, backbone=qwen25-05b to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_methods_boxplot_collapsed_BPI20TravelPermitData_qwen25-05b.png\n"
     ]
    }
   ],
   "source": [
    "LLM_BACKBONES = [\"gpt2\", \"gptneo-1b3\", \"qwen25-05b\", \"llama32-1b\", \"gemma-2-2b\"]\n",
    "\n",
    "llm = df[df[\"backbone\"].isin(LLM_BACKBONES)].copy()\n",
    "llm[\"Setting\"] = llm.apply(map_setting, axis=1)\n",
    "\n",
    "def collapse_setting_for_main(setting: str) -> str:\n",
    "    if isinstance(setting, str) and setting.startswith(\"Freezing-[\"):\n",
    "        return \"Freezing\"   # -1, 0, 0,1, -1,-2 zusammengefasst\n",
    "    return setting\n",
    "\n",
    "llm[\"Setting_main\"] = llm[\"Setting\"].apply(collapse_setting_for_main)\n",
    "\n",
    "plots_base_dir = \"/ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset\"\n",
    "\n",
    "SETTING_ORDER_FULL = [\n",
    "    \"ZeroShot\",\n",
    "    \"LoRA\",\n",
    "    \"FewShot-LoRA\",\n",
    "    \"Freezing\",\n",
    "    \"Freezing-[-1]\",\n",
    "    \"Freezing-[0]\",\n",
    "    \"Freezing-[0, 1]\",\n",
    "    \"Freezing-[-1, -2]\",\n",
    "    \"FewShot-Freezing\",\n",
    "]\n",
    "\n",
    "SETTING_ORDER_MAIN = [\n",
    "    \"ZeroShot\",\n",
    "    \"LoRA\",\n",
    "    \"FewShot-LoRA\",\n",
    "    \"Freezing\",\n",
    "    \"FewShot-Freezing\",\n",
    "]\n",
    "\n",
    "PLOTS = [\n",
    "    (\"test_next_activity_acc\",           \"NA Acc.\"),\n",
    "    (\"test_next_remaining_time_loss\",    \"RT MSE\"),\n",
    "    (\"test_next_time_to_next_event_loss\",\"NT MSE\"),\n",
    "]\n",
    "\n",
    "for log_name, df_log in llm.groupby(\"log\"):\n",
    "    log_dir = os.path.join(plots_base_dir, log_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    for backbone, df_b in df_log.groupby(\"backbone\"):\n",
    "\n",
    "        settings_full = [s for s in SETTING_ORDER_FULL if s in df_b[\"Setting\"].unique()]\n",
    "        if settings_full:\n",
    "            fig, axes = plt.subplots(3, 1, figsize=(8, 9), sharex=True)\n",
    "\n",
    "            for ax, (metric, ylabel) in zip(axes, PLOTS):\n",
    "                sns.boxplot(\n",
    "                    data=df_b,\n",
    "                    x=\"Setting\",\n",
    "                    y=metric,\n",
    "                    order=settings_full,\n",
    "                    ax=ax,\n",
    "                )\n",
    "                ax.set_ylabel(ylabel)\n",
    "                ax.set_xticks(range(len(settings_full)))\n",
    "                ax.set_xticklabels(settings_full, rotation=45, ha=\"right\")\n",
    "\n",
    "            axes[-1].set_xlabel(\"Fine-tuning method (detailed)\")\n",
    "\n",
    "            fig.suptitle(f\"{log_name} – {backbone} (all Freezing variants)\", fontsize=12)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            out_path = os.path.join(log_dir, f\"llm_methods_boxplot_freezing_{log_name}_{backbone}.png\")\n",
    "            plt.savefig(out_path, dpi=300)\n",
    "            plt.close(fig)\n",
    "\n",
    "            print(f\"Saved detailed boxplot for log={log_name}, backbone={backbone} to: {out_path}\")\n",
    "\n",
    "        settings_main = [s for s in SETTING_ORDER_MAIN if s in df_b[\"Setting_main\"].unique()]\n",
    "        if settings_main:\n",
    "            fig, axes = plt.subplots(3, 1, figsize=(8, 9), sharex=True)\n",
    "\n",
    "            for ax, (metric, ylabel) in zip(axes, PLOTS):\n",
    "                sns.boxplot(\n",
    "                    data=df_b,\n",
    "                    x=\"Setting_main\",\n",
    "                    y=metric,\n",
    "                    order=settings_main,\n",
    "                    ax=ax,\n",
    "                )\n",
    "                ax.set_ylabel(ylabel)\n",
    "                ax.set_xticks(range(len(settings_main)))\n",
    "                ax.set_xticklabels(settings_main, rotation  =45, ha=\"right\")\n",
    "\n",
    "            axes[-1].set_xlabel(\"Fine-tuning method (collapsed)\")\n",
    "\n",
    "            fig.suptitle(f\"{log_name} – {backbone} (collapsed Freezing)\", fontsize=12)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            out_path = os.path.join(log_dir, f\"llm_methods_boxplot_collapsed_{log_name}_{backbone}.png\")\n",
    "            plt.savefig(out_path, dpi=300)\n",
    "            plt.close(fig)\n",
    "\n",
    "            print(f\"Saved collapsed boxplot for log={log_name}, backbone={backbone} to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77607748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LLM-backbone comparison for log=BPI12, setting=ZeroShot to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_backbones_boxplot_BPI12_ZeroShot.png\n",
      "Saved LLM-backbone comparison for log=BPI12, setting=LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_backbones_boxplot_BPI12_LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI12, setting=FewShot-LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_backbones_boxplot_BPI12_FewShot-LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI12, setting=Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_backbones_boxplot_BPI12_Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI12, setting=FewShot-Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/llm_backbones_boxplot_BPI12_FewShot-Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI17, setting=ZeroShot to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_backbones_boxplot_BPI17_ZeroShot.png\n",
      "Saved LLM-backbone comparison for log=BPI17, setting=LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_backbones_boxplot_BPI17_LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI17, setting=FewShot-LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_backbones_boxplot_BPI17_FewShot-LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI17, setting=Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_backbones_boxplot_BPI17_Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI17, setting=FewShot-Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/llm_backbones_boxplot_BPI17_FewShot-Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI20PrepaidTravelCosts, setting=ZeroShot to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_backbones_boxplot_BPI20PrepaidTravelCosts_ZeroShot.png\n",
      "Saved LLM-backbone comparison for log=BPI20PrepaidTravelCosts, setting=LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_backbones_boxplot_BPI20PrepaidTravelCosts_LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI20PrepaidTravelCosts, setting=FewShot-LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_backbones_boxplot_BPI20PrepaidTravelCosts_FewShot-LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI20PrepaidTravelCosts, setting=Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_backbones_boxplot_BPI20PrepaidTravelCosts_Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI20PrepaidTravelCosts, setting=FewShot-Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/llm_backbones_boxplot_BPI20PrepaidTravelCosts_FewShot-Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI20RequestForPayment, setting=ZeroShot to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_backbones_boxplot_BPI20RequestForPayment_ZeroShot.png\n",
      "Saved LLM-backbone comparison for log=BPI20RequestForPayment, setting=LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_backbones_boxplot_BPI20RequestForPayment_LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI20RequestForPayment, setting=FewShot-LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_backbones_boxplot_BPI20RequestForPayment_FewShot-LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI20RequestForPayment, setting=Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_backbones_boxplot_BPI20RequestForPayment_Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI20RequestForPayment, setting=FewShot-Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/llm_backbones_boxplot_BPI20RequestForPayment_FewShot-Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI20TravelPermitData, setting=ZeroShot to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_backbones_boxplot_BPI20TravelPermitData_ZeroShot.png\n",
      "Saved LLM-backbone comparison for log=BPI20TravelPermitData, setting=LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_backbones_boxplot_BPI20TravelPermitData_LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI20TravelPermitData, setting=FewShot-LoRA to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_backbones_boxplot_BPI20TravelPermitData_FewShot-LoRA.png\n",
      "Saved LLM-backbone comparison for log=BPI20TravelPermitData, setting=Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_backbones_boxplot_BPI20TravelPermitData_Freezing.png\n",
      "Saved LLM-backbone comparison for log=BPI20TravelPermitData, setting=FewShot-Freezing to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/llm_backbones_boxplot_BPI20TravelPermitData_FewShot-Freezing.png\n"
     ]
    }
   ],
   "source": [
    "LLM_BACKBONES = [\"gpt2\", \"gptneo-1b3\", \"qwen25-05b\", \"llama32-1b\", \"gemma-2-2b\"]\n",
    "\n",
    "llm = df[df[\"backbone\"].isin(LLM_BACKBONES)].copy()\n",
    "llm[\"Setting\"] = llm.apply(map_setting, axis=1)\n",
    "\n",
    "def collapse_setting_for_main(setting: str) -> str:\n",
    "    if isinstance(setting, str) and setting.startswith(\"Freezing-[\"):\n",
    "        return \"Freezing\"   # -1, 0, 0,1, -1,-2 zusammengefasst\n",
    "    return setting\n",
    "\n",
    "llm[\"Setting_main\"] = llm[\"Setting\"].apply(collapse_setting_for_main)\n",
    "\n",
    "# Hübsche Modellnamen\n",
    "BACKBONE_MAP_LLM = {\n",
    "    \"gpt2\":         \"GPT2\",\n",
    "    \"gptneo-1b3\":   \"GPT-Neo-1.3B\",\n",
    "    \"qwen25-05b\":   \"Qwen2.5-0.5B\",\n",
    "    \"llama32-1b\":   \"Llama3.2-1B\",\n",
    "    \"gemma-2-2b\":   \"Gemma-2-2B\",\n",
    "}\n",
    "llm[\"Backbone_pretty\"] = llm[\"backbone\"].map(BACKBONE_MAP_LLM).fillna(llm[\"backbone\"])\n",
    "\n",
    "plots_base_dir = \"/ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset\"\n",
    "\n",
    "MAIN_SETTING_ORDER = [\n",
    "    \"ZeroShot\",\n",
    "    \"LoRA\",\n",
    "    \"FewShot-LoRA\",\n",
    "    \"Freezing\",\n",
    "    \"FewShot-Freezing\",\n",
    "]\n",
    "\n",
    "PLOTS = [\n",
    "    (\"test_next_activity_acc\",           \"NA Acc.\"),\n",
    "    (\"test_next_remaining_time_loss\",    \"RT MSE\"),\n",
    "    (\"test_next_time_to_next_event_loss\",\"NT MSE\"),\n",
    "]\n",
    "\n",
    "for log_name, df_log in llm.groupby(\"log\"):\n",
    "    log_dir = os.path.join(plots_base_dir, log_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    for setting in MAIN_SETTING_ORDER:\n",
    "        df_s = df_log[df_log[\"Setting_main\"] == setting].copy()\n",
    "        if df_s.empty:\n",
    "            continue\n",
    "\n",
    "        backbone_order = [\n",
    "            BACKBONE_MAP_LLM[b]\n",
    "            for b in LLM_BACKBONES\n",
    "            if b in df_s[\"backbone\"].unique()\n",
    "        ]\n",
    "        if not backbone_order:\n",
    "            continue\n",
    "\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(8, 9), sharex=True)\n",
    "\n",
    "        for ax, (metric, ylabel) in zip(axes, PLOTS):\n",
    "            sns.boxplot(\n",
    "                data=df_s,\n",
    "                x=\"Backbone_pretty\",\n",
    "                y=metric,\n",
    "                order=backbone_order,\n",
    "                ax=ax,\n",
    "            )\n",
    "            ax.set_ylabel(ylabel)\n",
    "            ax.set_xticklabels(backbone_order, rotation=45, ha=\"right\")\n",
    "\n",
    "        axes[-1].set_xlabel(\"LLM backbone\")\n",
    "\n",
    "        fig.suptitle(f\"{log_name} – {setting}\", fontsize=12)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        out_path = os.path.join(\n",
    "            log_dir,\n",
    "            f\"llm_backbones_boxplot_{log_name}_{setting}.png\"\n",
    "        )\n",
    "        plt.savefig(out_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "\n",
    "        print(f\"Saved LLM-backbone comparison for log={log_name}, setting={setting} to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bda212b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss curves shape (LoRA best runs): (250, 7)\n"
     ]
    }
   ],
   "source": [
    "# Loss-Curves für beste Full-LoRA-Runs pro (log, backbone)\n",
    "\n",
    "def fetch_single(\n",
    "    wandb_id: str,\n",
    "    targets=[\"na\", \"rt\", \"nt\"],\n",
    "    project_name: str | None = None,\n",
    "    entity: str | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Holt Verlaufskurven (pro Epoch) für einen einzelnen W&B-Run.\n",
    "    Gibt (na_acc, na_loss, rt_loss, nt_loss) als Listen zurück.\n",
    "    Fehlende Targets -> entsprechende Liste = None.\n",
    "    \"\"\"\n",
    "    if isinstance(targets, str):\n",
    "        targets = [targets]\n",
    "\n",
    "    if project_name is None:\n",
    "        raise ValueError(\"fetch_single requires an explicit project_name.\")\n",
    "\n",
    "    if entity is None:\n",
    "        entity = os.environ.get(\"ENTITY\")\n",
    "        if entity is None:\n",
    "            raise ValueError(\"ENTITY not set and no entity passed to fetch_single().\")\n",
    "\n",
    "    api = wandb.Api()\n",
    "    run = api.run(f\"{entity}/{project_name}/{wandb_id}\")\n",
    "    history = list(run.scan_history())\n",
    "\n",
    "    na_acc, na_loss, rt_loss, nt_loss = None, None, None, None\n",
    "\n",
    "    if \"rt\" in targets:\n",
    "        rt_loss = [\n",
    "            row[\"test_next_remaining_time_loss\"]\n",
    "            for row in history\n",
    "            if \"test_next_remaining_time_loss\" in row\n",
    "        ]\n",
    "\n",
    "    if \"na\" in targets:\n",
    "        na_loss = [\n",
    "            row[\"test_next_activity_loss\"]\n",
    "            for row in history\n",
    "            if \"test_next_activity_loss\" in row\n",
    "        ]\n",
    "        na_acc = [\n",
    "            row[\"test_next_activity_acc\"]\n",
    "            for row in history\n",
    "            if \"test_next_activity_acc\" in row\n",
    "        ]\n",
    "\n",
    "    if \"nt\" in targets:\n",
    "        nt_loss = [\n",
    "            row[\"test_next_time_to_next_event_loss\"]\n",
    "            for row in history\n",
    "            if \"test_next_time_to_next_event_loss\" in row\n",
    "        ]\n",
    "\n",
    "    return na_acc, na_loss, rt_loss, nt_loss\n",
    "\n",
    "\n",
    "# Pfad für Loss-Curves-CSV\n",
    "loss_csv_path = os.path.join(output_dir_csv, \"loss_curves_multitask_lora_best.csv\")\n",
    "\n",
    "LLM_BACKBONES = [\"gpt2\", \"gptneo-1b3\", \"qwen25-05b\", \"llama32-1b\", \"gemma-2-2b\"]\n",
    "\n",
    "if os.path.exists(loss_csv_path):\n",
    "    losses = pd.read_csv(loss_csv_path)\n",
    "else:\n",
    "    # Nur LLM + LoRA\n",
    "    df_lora = df[\n",
    "        df[\"backbone\"].isin(LLM_BACKBONES)\n",
    "        & (df[\"fine_tuning\"] == \"lora\")\n",
    "    ].copy()\n",
    "\n",
    "    # Nur \"Full-LoRA\" (keine Few-Shot-LoRA)\n",
    "    if \"few_shot_k\" in df_lora.columns:\n",
    "        df_lora = df_lora[df_lora[\"few_shot_k\"].isna()].copy()\n",
    "\n",
    "    # Score-Spalte für beste Runs\n",
    "    score_col = \"mt_score\"\n",
    "    if score_col not in df_lora.columns:\n",
    "        score_col = \"test_next_activity_acc\"\n",
    "\n",
    "    # Bester LoRA-Run pro (log, backbone)\n",
    "    best_runs = (\n",
    "        df_lora\n",
    "        .sort_values(score_col, ascending=False)\n",
    "        .groupby([\"log\", \"backbone\"], as_index=False)\n",
    "        .head(1)\n",
    "    )\n",
    "\n",
    "    losses_list = []\n",
    "\n",
    "    for _, row in best_runs.iterrows():\n",
    "        na_acc, na_loss, rt_loss, nt_loss = fetch_single(\n",
    "            wandb_id=row[\"id\"],\n",
    "            project_name=row[\"project\"],\n",
    "            entity=entity,\n",
    "            targets=[\"na\", \"rt\", \"nt\"],\n",
    "        )\n",
    "\n",
    "        # falls etwas fehlt → überspringen\n",
    "        if na_loss is None or rt_loss is None or nt_loss is None:\n",
    "            continue\n",
    "\n",
    "        tmp = pd.DataFrame({\n",
    "            \"epoch\": range(len(na_loss)),\n",
    "            \"na_acc\": na_acc,\n",
    "            \"na_loss\": na_loss,\n",
    "            \"rt_loss\": rt_loss,\n",
    "            \"nt_loss\": nt_loss,\n",
    "        })\n",
    "        tmp[\"log\"] = row[\"log\"]\n",
    "        tmp[\"backbone\"] = row[\"backbone\"]\n",
    "        losses_list.append(tmp)\n",
    "\n",
    "    if not losses_list:\n",
    "        raise RuntimeError(\"Keine Loss-Curves für LoRA-Runs gefunden.\")\n",
    "\n",
    "    losses = pd.concat(losses_list, axis=0, ignore_index=True)\n",
    "    losses.to_csv(loss_csv_path, index=False)\n",
    "    print(\"Saved LoRA loss curves to:\", loss_csv_path)\n",
    "\n",
    "print(\"Loss curves shape (LoRA best runs):\", losses.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "becd653b",
   "metadata": {
    "title": "Loss curve visualization (multi-task)"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LoRA loss curve plot to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/loss_curves_multitask_lora_best.png\n"
     ]
    }
   ],
   "source": [
    "LOGS_TO_PLOT = sorted(losses[\"log\"].unique())\n",
    "\n",
    "HUE_MAP = {\n",
    "    \"gpt2\":         \"GPT2\",\n",
    "    \"gptneo-1b3\":   \"GPT-Neo-1.3B\",\n",
    "    \"qwen25-05b\":   \"Qwen2.5-0.5B\",\n",
    "    \"llama32-1b\":   \"Llama3.2-1B\",\n",
    "    \"gemma-2-2b\":   \"Gemma-2-2B\",\n",
    "}\n",
    "\n",
    "HUE_ORDER = [\n",
    "    \"GPT2\",\n",
    "    \"GPT-Neo-1.3B\",\n",
    "    \"Qwen2.5-0.5B\",\n",
    "    \"Llama3.2-1B\",\n",
    "    \"Gemma-2-2B\",\n",
    "]\n",
    "\n",
    "# Long-Format\n",
    "l = losses.melt(\n",
    "    id_vars=[\"log\", \"backbone\", \"epoch\"],\n",
    "    value_vars=[\"na_loss\", \"rt_loss\", \"nt_loss\"],\n",
    "    var_name=\"Loss\",\n",
    "    value_name=\"Value\",\n",
    ").dropna(subset=[\"Value\"])\n",
    "\n",
    "l[\"Backbone\"] = l[\"backbone\"].map(HUE_MAP)\n",
    "l = l[l[\"Backbone\"].notna()]\n",
    "\n",
    "LOSS_LABELS = {\n",
    "    \"na_loss\": \"NA Loss\",\n",
    "    \"rt_loss\": \"RT Loss\",\n",
    "    \"nt_loss\": \"NT Loss\",\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    3, len(LOGS_TO_PLOT),\n",
    "    figsize=(4 * len(LOGS_TO_PLOT), 8),\n",
    "    sharex=True\n",
    ")\n",
    "axes_iter = iter(axes.flatten())\n",
    "\n",
    "legend_handles, legend_labels = None, None  # globale Legende\n",
    "\n",
    "for loss_name in [\"na_loss\", \"rt_loss\", \"nt_loss\"]:\n",
    "    for log_name in LOGS_TO_PLOT:\n",
    "        ax = next(axes_iter)\n",
    "        tmp = l[(l[\"Loss\"] == loss_name) & (l[\"log\"] == log_name)]\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=tmp,\n",
    "            x=\"epoch\",\n",
    "            y=\"Value\",\n",
    "            hue=\"Backbone\",\n",
    "            hue_order=[h for h in HUE_ORDER if h in tmp[\"Backbone\"].unique()],\n",
    "            ax=ax,\n",
    "            linewidth=2.0,\n",
    "        )\n",
    "\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(LOSS_LABELS[loss_name])\n",
    "        ax.set_title(log_name)\n",
    "\n",
    "        # Legend nur einmal abgreifen\n",
    "        leg = ax.get_legend()\n",
    "        if leg is not None:\n",
    "            handles, labels = leg.legend_handles, [t.get_text() for t in leg.get_texts()]\n",
    "            legend_handles, legend_labels = handles, labels\n",
    "            leg.remove()\n",
    "\n",
    "# globale Legende unter der Figure\n",
    "if legend_handles is not None:\n",
    "    fig.legend(\n",
    "        legend_handles,\n",
    "        legend_labels,\n",
    "        title=\"\",\n",
    "        loc=\"lower center\",\n",
    "        ncol=len(legend_labels),\n",
    "        bbox_to_anchor=(0.5, -0.02),\n",
    "    )\n",
    "\n",
    "plt.tight_layout(rect=(0, 0.05, 1, 1))  # unten Platz für Legende lassen\n",
    "\n",
    "plot_path = os.path.join(output_dir_plots, \"loss_curves_multitask_lora_best.png\")\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Saved LoRA loss curve plot to:\", plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2b476c2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved param summary for BPI12 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI12/param_summary_multitask.csv\n",
      "Saved param summary for BPI17 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI17/param_summary_multitask.csv\n",
      "Saved param summary for BPI20PrepaidTravelCosts to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20PrepaidTravelCosts/param_summary_multitask.csv\n",
      "Saved param summary for BPI20RequestForPayment to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20RequestForPayment/param_summary_multitask.csv\n",
      "Saved param summary for BPI20TravelPermitData to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/csv/per_dataset/BPI20TravelPermitData/param_summary_multitask.csv\n"
     ]
    }
   ],
   "source": [
    "# PARAMETER-SUMMARY \n",
    "\n",
    "multi_path = os.path.join(output_dir_csv, \"multi_task_benchmark_results.csv\")\n",
    "multi = pd.read_csv(multi_path)\n",
    "\n",
    "# Nur Zeilen mit Parameterinfos\n",
    "param_summary = (\n",
    "    multi[\n",
    "        [\n",
    "            \"log\",\n",
    "            \"backbone\",\n",
    "            \"Setting\",\n",
    "            \"total_params\",\n",
    "            \"trainable_params\",\n",
    "        ]\n",
    "    ]\n",
    "    .dropna(subset=[\"total_params\", \"trainable_params\"])\n",
    "    .drop_duplicates()\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "# Anteil trainierbarer Parameter in %\n",
    "param_summary[\"trainable_percent\"] = (\n",
    "    param_summary[\"trainable_params\"] / param_summary[\"total_params\"] * 100.0\n",
    ")\n",
    "\n",
    "param_summary[\"trainable_percent_fmt\"] = (\n",
    "    param_summary[\"trainable_percent\"].round(1).astype(str) + \"%\"\n",
    ")\n",
    "\n",
    "# total_params schön formatiert (wissenschaftliche Notation)\n",
    "param_summary[\"total_params_fmt\"] = param_summary[\"total_params\"].apply(\n",
    "    lambda x: np.format_float_scientific(x, precision=1)\n",
    ")\n",
    "\n",
    "param_summary[\"# params\\n(%trainable)\"] = (\n",
    "    param_summary[\"total_params_fmt\"]\n",
    "    + \" (\"\n",
    "    + param_summary[\"trainable_percent_fmt\"]\n",
    "    + \")\"\n",
    ")\n",
    "\n",
    "# falls vorhanden, Dataset & hübsche Namen mitnehmen\n",
    "if \"Dataset\" in multi.columns:\n",
    "    param_summary[\"Dataset\"] = multi.set_index(\n",
    "        [\"log\", \"backbone\", \"Setting\"]\n",
    "    ).loc[\n",
    "        param_summary.set_index([\"log\", \"backbone\", \"Setting\"]).index,\n",
    "        \"Dataset\"\n",
    "    ].values\n",
    "else:\n",
    "    param_summary[\"Dataset\"] = param_summary[\"log\"]\n",
    "\n",
    "if \"Backbone_pretty\" in multi.columns:\n",
    "    param_summary[\"Backbone_pretty\"] = multi.set_index(\n",
    "        [\"log\", \"backbone\", \"Setting\"]\n",
    "    ).loc[\n",
    "        param_summary.set_index([\"log\", \"backbone\", \"Setting\"]).index,\n",
    "        \"Backbone_pretty\"\n",
    "    ].values\n",
    "else:\n",
    "    param_summary[\"Backbone_pretty\"] = param_summary[\"backbone\"]\n",
    "\n",
    "# --- pro Datensatz (log) speichern ---\n",
    "for log_name, df_log in param_summary.groupby(\"log\"):\n",
    "    log_dir = os.path.join(output_dir_csv, \"per_dataset\", log_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    csv_path = os.path.join(log_dir, \"param_summary_multitask.csv\")\n",
    "    df_log.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved param summary for {log_name} to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03f4bdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Pareto plot for log=BPI12 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/pareto_llm_lora_BPI12.png\n",
      "Saved Pareto plot for log=BPI17 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/pareto_llm_lora_BPI17.png\n",
      "Saved Pareto plot for log=BPI20PrepaidTravelCosts to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/pareto_llm_lora_BPI20PrepaidTravelCosts.png\n",
      "Saved Pareto plot for log=BPI20RequestForPayment to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/pareto_llm_lora_BPI20RequestForPayment.png\n",
      "Saved Pareto plot for log=BPI20TravelPermitData to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/pareto_llm_lora_BPI20TravelPermitData.png\n"
     ]
    }
   ],
   "source": [
    "# === PARETO: MT-Score vs. trainierbare Parameter (LoRA, best per LLM-Backbone) ===\n",
    "\n",
    "multi_path = os.path.join(output_dir_csv, \"multi_task_benchmark_results.csv\")\n",
    "multi = pd.read_csv(multi_path)\n",
    "\n",
    "# Relevante LLM-Backbones + Pretty Names\n",
    "LLM_BACKBONES = [\"gpt2\", \"gptneo-1b3\", \"qwen25-05b\", \"llama32-1b\", \"gemma-2-2b\"]\n",
    "BACKBONE_MAP_LLM = {\n",
    "    \"gpt2\":         \"GPT2\",\n",
    "    \"gptneo-1b3\":   \"GPT-Neo-1.3B\",\n",
    "    \"qwen25-05b\":   \"Qwen2.5-0.5B\",\n",
    "    \"llama32-1b\":   \"Llama3.2-1B\",\n",
    "    \"gemma-2-2b\":   \"Gemma-2-2B\",\n",
    "}\n",
    "\n",
    "# Nur LLM + LoRA + benötigte Spalten\n",
    "pareto_source = multi[\n",
    "    (multi[\"backbone\"].isin(LLM_BACKBONES))\n",
    "    & (multi[\"Setting\"] == \"LoRA\")\n",
    "    & multi[\"trainable_params\"].notna()\n",
    "    & multi[\"mt_score_mean\"].notna()\n",
    "].copy()\n",
    "\n",
    "# Pretty-Namen ergänzen (falls noch nicht vorhanden)\n",
    "if \"Backbone_pretty\" not in pareto_source.columns:\n",
    "    pareto_source[\"Backbone_pretty\"] = (\n",
    "        pareto_source[\"backbone\"]\n",
    "        .map(BACKBONE_MAP_LLM)\n",
    "        .fillna(pareto_source[\"backbone\"])\n",
    "    )\n",
    "\n",
    "plots_base_dir = \"/ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset\"\n",
    "\n",
    "for log_name, df_log in pareto_source.groupby(\"log\"):\n",
    "    # pro Datensatz: bester LoRA-Run je Backbone\n",
    "    df_best = (\n",
    "        df_log\n",
    "        .sort_values(\n",
    "            [\"backbone\", \"mt_score_mean\", \"trainable_params\"],\n",
    "            ascending=[True, False, True],  # Score ↓, bei Tie weniger Params ↑\n",
    "        )\n",
    "        .drop_duplicates(subset=[\"backbone\"], keep=\"first\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    if df_best.empty:\n",
    "        continue\n",
    "\n",
    "    # etwas breiter, damit die Legend unten gut passt\n",
    "    fig, ax = plt.subplots(figsize=(9, 4.5))\n",
    "\n",
    "    # Scatter: ein Punkt pro Backbone\n",
    "    for bb, df_b in df_best.groupby(\"backbone\"):\n",
    "        label = df_b[\"Backbone_pretty\"].iloc[0]\n",
    "        ax.scatter(\n",
    "            df_b[\"trainable_params\"],\n",
    "            df_b[\"mt_score_mean\"],\n",
    "            label=label,\n",
    "            s=70,\n",
    "        )\n",
    "\n",
    "    # Pareto-Front hervorheben (min trainable_params, max mt_score_mean)\n",
    "    df_pf = df_best.sort_values(\"trainable_params\")\n",
    "    best_so_far = -np.inf\n",
    "    pareto_mask = []\n",
    "    for _, row in df_pf.iterrows():\n",
    "        if row[\"mt_score_mean\"] >= best_so_far - 1e-9:\n",
    "            pareto_mask.append(True)\n",
    "            best_so_far = row[\"mt_score_mean\"]\n",
    "        else:\n",
    "            pareto_mask.append(False)\n",
    "    df_pf_pareto = df_pf[pareto_mask]\n",
    "\n",
    "    if not df_pf_pareto.empty:\n",
    "        ax.scatter(\n",
    "            df_pf_pareto[\"trainable_params\"],\n",
    "            df_pf_pareto[\"mt_score_mean\"],\n",
    "            s=140,\n",
    "            facecolors=\"none\",\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=1.5,\n",
    "        )\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xlabel(\"Trainable parameters (LoRA, log scale)\")\n",
    "    ax.set_ylabel(\"MT-Score (mean across seeds)\")\n",
    "    ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "    # Titel: wenn Dataset-Spalte existiert, nimm diese Bezeichnung\n",
    "    if \"Dataset\" in df_best.columns:\n",
    "        ds_label = df_best[\"Dataset\"].iloc[0]\n",
    "    else:\n",
    "        ds_label = log_name\n",
    "    ax.set_title(f\"{ds_label} – LLM LoRA Pareto (best per backbone)\")\n",
    "\n",
    "    # Legend unten über die ganze Breite\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        title=\"Backbone\",\n",
    "        loc=\"lower center\",\n",
    "        ncol=len(labels),\n",
    "        frameon=False,\n",
    "        bbox_to_anchor=(0.5, -0.02),\n",
    "    )\n",
    "\n",
    "    # Platz für die Legend unten lassen\n",
    "    plt.tight_layout(rect=(0, 0.12, 1, 1))\n",
    "\n",
    "    log_dir = os.path.join(plots_base_dir, log_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    out_path = os.path.join(log_dir, f\"pareto_llm_lora_{log_name}.png\")\n",
    "\n",
    "    plt.savefig(out_path, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"Saved Pareto plot for log={log_name} to: {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8eb02c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TRUE Pareto-front LoRA-sweeps plot for log=BPI12 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12/pareto_llm_lora_sweeps_true_BPI12.png\n",
      "Saved TRUE Pareto-front LoRA-sweeps plot for log=BPI17 to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI17/pareto_llm_lora_sweeps_true_BPI17.png\n",
      "Saved TRUE Pareto-front LoRA-sweeps plot for log=BPI20PrepaidTravelCosts to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20PrepaidTravelCosts/pareto_llm_lora_sweeps_true_BPI20PrepaidTravelCosts.png\n",
      "Saved TRUE Pareto-front LoRA-sweeps plot for log=BPI20RequestForPayment to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20RequestForPayment/pareto_llm_lora_sweeps_true_BPI20RequestForPayment.png\n",
      "Saved TRUE Pareto-front LoRA-sweeps plot for log=BPI20TravelPermitData to: /ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI20TravelPermitData/pareto_llm_lora_sweeps_true_BPI20TravelPermitData.png\n"
     ]
    }
   ],
   "source": [
    "LLM_BACKBONES = [\"gpt2\", \"gptneo-1b3\", \"qwen25-05b\", \"llama32-1b\", \"gemma-2-2b\"]\n",
    "BACKBONE_MAP_LLM = {\n",
    "    \"gpt2\":         \"GPT2\",\n",
    "    \"gptneo-1b3\":   \"GPT-Neo-1.3B\",\n",
    "    \"qwen25-05b\":   \"Qwen2.5-0.5B\",\n",
    "    \"llama32-1b\":   \"Llama3.2-1B\",\n",
    "    \"gemma-2-2b\":   \"Gemma-2-2B\",\n",
    "}\n",
    "\n",
    "# Datensatz-Kürzel (wie bisher)\n",
    "DATASET_MAP = {\n",
    "    \"BPI12\": \"BPI12\",\n",
    "    \"BPI17\": \"BPI17\",\n",
    "    \"BPI20PrepaidTravelCosts\": \"BPI20PTC\",\n",
    "    \"BPI20RequestForPayment\": \"BPI20RfP\",\n",
    "    \"BPI20TravelPermitData\": \"BPI20TPD\",\n",
    "}\n",
    "\n",
    "# 1) Alle LLM-LoRA-Runs aus den Roh-Runs df ziehen\n",
    "lora_all = df[\n",
    "    df[\"backbone\"].isin(LLM_BACKBONES)\n",
    "    & (df[\"fine_tuning\"] == \"lora\")\n",
    "].copy()\n",
    "\n",
    "# Voll-LoRA (ohne Few-Shot-LoRA)\n",
    "if \"few_shot_k\" in lora_all.columns:\n",
    "    lora_all = lora_all[lora_all[\"few_shot_k\"].isna()].copy()\n",
    "\n",
    "# nur Zeilen mit Parametern & MT-Score\n",
    "if \"mt_score\" not in lora_all.columns:\n",
    "    raise ValueError(\"Spalte 'mt_score' fehlt in df – bitte sicherstellen, dass sie vorher berechnet wird.\")\n",
    "\n",
    "lora_all = lora_all[\n",
    "    lora_all[\"trainable_params\"].notna()\n",
    "    & lora_all[\"mt_score\"].notna()\n",
    "].copy()\n",
    "\n",
    "if lora_all.empty:\n",
    "    print(\"Keine LoRA-Sweeps mit trainable_params + mt_score gefunden – Pareto-Front wird übersprungen.\")\n",
    "else:\n",
    "    # 2) HParam-Kombi definieren (deine Sweep-Parameter)\n",
    "    HP_SWEEP_COLS = [\n",
    "        \"lr\",\n",
    "        \"batch_size\",\n",
    "        \"epochs\",\n",
    "        \"r\",\n",
    "        \"lora_alpha\",\n",
    "        \"embedding_size\",\n",
    "        \"hidden_size\",\n",
    "        \"strategy\",\n",
    "    ]\n",
    "    HP_SWEEP_COLS = [c for c in HP_SWEEP_COLS if c in lora_all.columns]\n",
    "\n",
    "    group_cols_sweep = [\"log\", \"backbone\"] + HP_SWEEP_COLS\n",
    "\n",
    "    # 3) Über Seeds mitteln: MT-Score + trainable_params\n",
    "    lora_sweeps_grouped = (\n",
    "        lora_all\n",
    "        .groupby(group_cols_sweep, dropna=False)\n",
    "        .agg(\n",
    "            mt_score_mean=(\"mt_score\", \"mean\"),\n",
    "            mt_score_std=(\"mt_score\", \"std\"),\n",
    "            trainable_params=(\"trainable_params\", \"mean\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Backbone-Label\n",
    "    lora_sweeps_grouped[\"Backbone_pretty\"] = (\n",
    "        lora_sweeps_grouped[\"backbone\"]\n",
    "        .map(BACKBONE_MAP_LLM)\n",
    "        .fillna(lora_sweeps_grouped[\"backbone\"])\n",
    "    )\n",
    "\n",
    "    plots_base_dir = \"/ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset\"\n",
    "\n",
    "    # 4) Pro Datensatz: All-Sweeps + echte Pareto-Front\n",
    "    for log_name, df_log in lora_sweeps_grouped.groupby(\"log\"):\n",
    "        if df_log.empty:\n",
    "            continue\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "        # --- alle Sweeps: Linien je Backbone (wie zuvor) ---\n",
    "        for bb, df_b in df_log.groupby(\"backbone\"):\n",
    "            df_b = df_b.sort_values(\"trainable_params\")\n",
    "            label = df_b[\"Backbone_pretty\"].iloc[0]\n",
    "\n",
    "            ax.plot(\n",
    "                df_b[\"trainable_params\"],\n",
    "                df_b[\"mt_score_mean\"],\n",
    "                marker=\"o\",\n",
    "                linestyle=\"-\",\n",
    "                linewidth=1.0,\n",
    "                markersize=6,\n",
    "                label=label,\n",
    "                alpha=0.9,\n",
    "            )\n",
    "\n",
    "        # --- echte Pareto-Front über ALLE Sweeps dieses Datensatzes ---\n",
    "        # Ziele: min trainable_params, max mt_score_mean\n",
    "        df_sorted = df_log.sort_values(\"trainable_params\")\n",
    "        best_score = -np.inf\n",
    "        pareto_rows = []\n",
    "\n",
    "        for _, row in df_sorted.iterrows():\n",
    "            score = row[\"mt_score_mean\"]\n",
    "            if score >= best_score - 1e-9:\n",
    "                pareto_rows.append(row)\n",
    "                best_score = score\n",
    "\n",
    "        pareto_df = pd.DataFrame(pareto_rows)\n",
    "\n",
    "        if not pareto_df.empty:\n",
    "            pareto_df = pareto_df.sort_values(\"trainable_params\")\n",
    "            ax.plot(\n",
    "                pareto_df[\"trainable_params\"],\n",
    "                pareto_df[\"mt_score_mean\"],\n",
    "                color=\"black\",\n",
    "                linewidth=1.3,\n",
    "                marker=\"o\",\n",
    "                markersize=4,\n",
    "                label=\"Pareto front\",\n",
    "            )\n",
    "\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_xlabel(\"Trainable parameters (LoRA, log scale)\")\n",
    "        ax.set_ylabel(\"MT-Score (mean across seeds)\")\n",
    "\n",
    "        ds_label = DATASET_MAP.get(log_name, log_name)\n",
    "        ax.set_title(f\"{ds_label} – LLM LoRA sweeps (Pareto front)\")\n",
    "\n",
    "        ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "        # Legend unten zentriert wie beim anderen Plot\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        fig.legend(\n",
    "            handles,\n",
    "            labels,\n",
    "            title=\"Backbone / front\",\n",
    "            loc=\"lower center\",\n",
    "            ncol=len(labels),\n",
    "            bbox_to_anchor=(0.5, -0.02),\n",
    "        )\n",
    "\n",
    "        # Platz für Legende lassen\n",
    "        plt.tight_layout(rect=(0, 0.10, 1, 1))\n",
    "\n",
    "        log_dir = os.path.join(plots_base_dir, log_name)\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        out_path = os.path.join(log_dir, f\"pareto_llm_lora_sweeps_true_{log_name}.png\")\n",
    "\n",
    "        plt.savefig(out_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "\n",
    "        print(f\"Saved TRUE Pareto-front LoRA-sweeps plot for log={log_name} to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e13b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% === CPU-only minimal evaluation: (A) prefix-topk trace viz, (B) sampled confusion matrix ===\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -------------------------\n",
    "# User settings\n",
    "# -------------------------\n",
    "MODEL_PATH = \"/ceph/lfertig/Thesis/notebook/llm-peft-ppm/persisted_models/suffix/BPI12_gpt2_ep10_lora_seed41.pth\"\n",
    "DATASET_NAME = \"BPI12\"  # derived from model name, but keep explicit\n",
    "CACHE_DIR = Path(\"/ceph/lfertig/Thesis/notebook/llm-peft-ppm/data/BPI12/cached_train_test\")\n",
    "SAVE_DIR = Path(\"/ceph/lfertig/Thesis/notebook/llm-peft-ppm/results/plots/per_dataset/BPI12\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Quick trace visualization\n",
    "TRACE_IDX = 0\n",
    "PREFIX_LEN = 8\n",
    "TOPK = 10\n",
    "SUFFIX_STEPS = 12\n",
    "\n",
    "# Confusion matrix \"light\" (sampling)\n",
    "DO_CONFUSION_MATRIX = True\n",
    "N_SAMPLES = 2500          # reduce if too slow (e.g. 500..2000)\n",
    "MAX_CTX = 64              # context window cap (big speed win)\n",
    "TOP_CLASSES_CM = 30       # plot only top-N by support (+OTHER)\n",
    "SEED = 41\n",
    "\n",
    "# Force CPU (GPU not available)\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "# Try bf16 on CPU to reduce memory; fallback to fp32\n",
    "DTYPE = torch.bfloat16 if hasattr(torch, \"cpu\") and torch.cpu.is_bf16_supported() else torch.float32\n",
    "print(\"DEVICE:\", DEVICE, \"| DTYPE:\", DTYPE)\n",
    "\n",
    "# Speed knobs (safe)\n",
    "torch.set_grad_enabled(False)\n",
    "torch.set_num_threads(min(8, os.cpu_count() or 8))\n",
    "\n",
    "# Make transformers offline (avoid accidental downloads)\n",
    "os.environ.setdefault(\"TRANSFORMERS_OFFLINE\", \"1\")\n",
    "os.environ.setdefault(\"HF_HUB_OFFLINE\", \"1\")\n",
    "\n",
    "# -------------------------\n",
    "# Make ppm importable\n",
    "# -------------------------\n",
    "REPO_ROOT = Path(\"/ceph/lfertig/Thesis/notebook/llm-peft-ppm\").resolve()\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "from peft import LoraConfig, TaskType\n",
    "from ppm.models import NextEventPredictor\n",
    "\n",
    "# Only needed if cache sidecars not found\n",
    "from skpm.event_logs import BPI12\n",
    "from skpm.event_logs.split import unbiased\n",
    "from skpm.feature_extraction import TimestampExtractor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ppm.datasets import ContinuousTraces\n",
    "from ppm.datasets.event_logs import EventFeatures, EventLog, EventTargets\n",
    "\n",
    "# -------------------------\n",
    "# Backbone configs (as in your training script)\n",
    "# -------------------------\n",
    "PRETRAINED_CONFIGS = {\n",
    "    \"gpt2\": {\"name\": \"openai-community/gpt2\", \"embedding_size\": 768,  \"hidden_size\": 768,  \"fine_tuning_module_path\": \"h\"},\n",
    "    \"gptneo-1b3\": {\"name\": \"EleutherAI/gpt-neo-1.3B\", \"embedding_size\": 2048, \"hidden_size\": 2048, \"fine_tuning_module_path\": \"h\"},\n",
    "    \"qwen25-05b\": {\"name\": \"Qwen/Qwen2.5-0.5B\", \"embedding_size\": 896, \"hidden_size\": 896, \"fine_tuning_module_path\": \"layers\"},\n",
    "    \"llama32-1b\": {\"name\": \"unsloth/Llama-3.2-1B\", \"embedding_size\": 2048, \"hidden_size\": 2048, \"fine_tuning_module_path\": \"layers\"},\n",
    "    \"gemma-2-2b\": {\"name\": \"google/gemma-2-2b\", \"embedding_size\": 2304, \"hidden_size\": 2304, \"fine_tuning_module_path\": \"layers\"},\n",
    "}\n",
    "\n",
    "NUMERICAL_FEATURES = [\n",
    "    \"accumulated_time\",\"day_of_month\",\"day_of_week\",\"day_of_year\",\"hour_of_day\",\n",
    "    \"min_of_hour\",\"month_of_year\",\"sec_of_min\",\"secs_within_day\",\"week_of_year\",\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def parse_ckpt_name(path: str) -> dict:\n",
    "    base = os.path.basename(path).replace(\".pth\", \"\")\n",
    "    rx = re.compile(\n",
    "        r\"^(?P<log>[^_]+)_(?P<backbone>[^_]+)\"\n",
    "        r\"(?:_ep(?P<epochs>\\d+))?\"\n",
    "        r\"(?:_(?P<ft>lora|freeze))?\"\n",
    "        r\"(?:_seed(?P<seed>\\d+))?$\"\n",
    "    )\n",
    "    m = rx.match(base)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse checkpoint name: {base}\")\n",
    "    d = m.groupdict()\n",
    "    d[\"epochs\"] = int(d[\"epochs\"]) if d.get(\"epochs\") else None\n",
    "    d[\"seed\"] = int(d[\"seed\"]) if d.get(\"seed\") else None\n",
    "    return d\n",
    "\n",
    "def infer_lora_r_from_state_dict(sd: dict) -> int | None:\n",
    "    for k, v in sd.items():\n",
    "        if \"lora_A\" in k and hasattr(v, \"shape\") and len(v.shape) == 2:\n",
    "            return int(v.shape[0])\n",
    "    return None\n",
    "\n",
    "def get_lora_config(backbone: str, r: int, lora_alpha: int) -> LoraConfig:\n",
    "    if \"gptneo\" in backbone:\n",
    "        return LoraConfig(task_type=TaskType.FEATURE_EXTRACTION, r=r, lora_alpha=lora_alpha, target_modules=None, use_rslora=True)\n",
    "    if \"gpt2\" in backbone:\n",
    "        return LoraConfig(\n",
    "            task_type=TaskType.FEATURE_EXTRACTION, r=r, lora_alpha=lora_alpha, use_rslora=True,\n",
    "            target_modules=[\"attn.c_attn\",\"attn.c_proj\",\"mlp.c_fc\",\"mlp.c_proj\"],\n",
    "        )\n",
    "    return LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM, r=r, lora_alpha=lora_alpha, use_rslora=True,\n",
    "        target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"up_proj\",\"down_proj\",\"o_proj\",\"gate_proj\"],\n",
    "    )\n",
    "\n",
    "def softmax_np(x: np.ndarray) -> np.ndarray:\n",
    "    x = x - np.max(x)\n",
    "    e = np.exp(x)\n",
    "    return e / (e.sum() + 1e-12)\n",
    "\n",
    "def try_load_sidecar_cache(cache_dir: Path):\n",
    "    \"\"\"\n",
    "    Try to load cached tensors from sidecar pt files.\n",
    "    Returns dict with keys traces/cat_features/num_features/cat_targets/num_targets or None.\n",
    "    \"\"\"\n",
    "    if not cache_dir.exists():\n",
    "        return None\n",
    "\n",
    "    # Common naming patterns (you can extend if your cache uses different names)\n",
    "    pats = {\n",
    "        \"traces\":      [\"*traces*.pt\"],\n",
    "        \"cat_features\":[\"*cat_features*.pt\"],\n",
    "        \"num_features\":[\"*num_features*.pt\"],\n",
    "        \"cat_targets\": [\"*cat_targets*.pt\"],\n",
    "        \"num_targets\": [\"*num_targets*.pt\"],\n",
    "    }\n",
    "\n",
    "    picks = {}\n",
    "    for k, patterns in pats.items():\n",
    "        cands = []\n",
    "        for pat in patterns:\n",
    "            cands += sorted(cache_dir.glob(pat))\n",
    "        # Drop known \"test.pt\" which is None in your case\n",
    "        cands = [c for c in cands if c.name != \"test.pt\"]\n",
    "        picks[k] = cands[0] if len(cands) else None\n",
    "\n",
    "    if any(v is None for v in picks.values()):\n",
    "        return None\n",
    "\n",
    "    bundle = {}\n",
    "    for k, p in picks.items():\n",
    "        obj = torch.load(p, map_location=\"cpu\")\n",
    "        bundle[k] = obj\n",
    "    return bundle\n",
    "\n",
    "def prepare_data_like_training(df_raw: pd.DataFrame, unbiased_split_params: dict):\n",
    "    df = df_raw.loc[:, [\"case:concept:name\", \"concept:name\", \"time:timestamp\"]].copy()\n",
    "    keep_cases = df.groupby(\"case:concept:name\").size() > 2\n",
    "    keep_cases = keep_cases[keep_cases].index\n",
    "    df = df[df[\"case:concept:name\"].isin(keep_cases)]\n",
    "\n",
    "    df = df.sort_values(by=[\"case:concept:name\", \"time:timestamp\"])\n",
    "    df[\"time:timestamp\"] = pd.to_datetime(df[\"time:timestamp\"], utc=True)\n",
    "\n",
    "    df[\"time_to_next_event\"] = (\n",
    "        df.groupby(\"case:concept:name\")[\"time:timestamp\"].shift(-1) - df[\"time:timestamp\"]\n",
    "    ).dt.total_seconds().fillna(0).clip(lower=0)\n",
    "\n",
    "    train, test = unbiased(df, **unbiased_split_params)\n",
    "\n",
    "    ts = TimestampExtractor(\n",
    "        case_features=[\"accumulated_time\", \"remaining_time\"],\n",
    "        event_features=\"all\",\n",
    "        time_unit=\"d\",\n",
    "    )\n",
    "    train[ts.get_feature_names_out()] = ts.fit_transform(train)\n",
    "    test[ts.get_feature_names_out()] = ts.transform(test)\n",
    "\n",
    "    train = train.drop(columns=[\"time:timestamp\"])\n",
    "    test = test.drop(columns=[\"time:timestamp\"])\n",
    "\n",
    "    train = train.rename(columns={\"case:concept:name\": \"case_id\", \"concept:name\": \"activity\"})\n",
    "    test = test.rename(columns={\"case:concept:name\": \"case_id\", \"concept:name\": \"activity\"})\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    columns = NUMERICAL_FEATURES + [\"remaining_time\", \"time_to_next_event\"]\n",
    "    train.loc[:, columns] = sc.fit_transform(train[columns])\n",
    "    test.loc[:, columns] = sc.transform(test[columns])\n",
    "    return train, test\n",
    "\n",
    "def forward_next_activity_logits(model, x_cat, x_num, pad_id: int):\n",
    "    \"\"\"\n",
    "    x_cat: [B,T,Ccat] long\n",
    "    x_num: [B,T,Cnum] float\n",
    "    returns logits: [B,T,V]\n",
    "    \"\"\"\n",
    "    attn = (x_cat[..., 0] != pad_id).long()\n",
    "    out, _ = model(x_cat=x_cat, x_num=x_num, attention_mask=attn)\n",
    "    if \"next_activity\" in out:\n",
    "        return out[\"next_activity\"]\n",
    "    # fallback: first key\n",
    "    k0 = next(iter(out.keys()))\n",
    "    return out[k0]\n",
    "\n",
    "# -------------------------\n",
    "# 1) Load checkpoint\n",
    "# -------------------------\n",
    "ckpt = torch.load(MODEL_PATH, map_location=\"cpu\")\n",
    "state_dict = ckpt[\"net\"]\n",
    "stoi = ckpt.get(\"stoi\")\n",
    "itos = ckpt.get(\"itos\")\n",
    "\n",
    "meta = parse_ckpt_name(MODEL_PATH)\n",
    "log_name = meta[\"log\"]\n",
    "backbone = meta[\"backbone\"]\n",
    "epochs = meta[\"epochs\"]\n",
    "seed = meta[\"seed\"]\n",
    "print(\"Parsed:\", meta)\n",
    "\n",
    "pre = PRETRAINED_CONFIGS[backbone]\n",
    "\n",
    "# Vocab/IDs (need checkpoint vocabs ideally)\n",
    "if stoi is None or itos is None:\n",
    "    raise RuntimeError(\"Checkpoint does not contain stoi/itos. For minimal CPU evaluation, please save vocabs in ckpt.\")\n",
    "\n",
    "stoi_act = stoi[\"activity\"]\n",
    "itos_act = {int(k): v for k, v in itos[\"activity\"].items()}\n",
    "pad_id = int(stoi_act[\"<PAD>\"])\n",
    "unk_id = int(stoi_act[\"<UNK>\"])\n",
    "eos_id = int(stoi_act[\"<EOS>\"])\n",
    "vocab_size = max(itos_act.keys()) + 1\n",
    "\n",
    "# LoRA params\n",
    "r = infer_lora_r_from_state_dict(state_dict)\n",
    "if r is None:\n",
    "    raise RuntimeError(\"Could not infer LoRA r from state_dict.\")\n",
    "# alpha: try from df if available; else fallback alpha=r\n",
    "lora_alpha = None\n",
    "if \"df\" in globals():\n",
    "    cand = df.copy()\n",
    "    if \"log\" in cand.columns: cand = cand[cand[\"log\"] == log_name]\n",
    "    if \"backbone\" in cand.columns: cand = cand[cand[\"backbone\"] == backbone]\n",
    "    if \"fine_tuning\" in cand.columns: cand = cand[cand[\"fine_tuning\"] == \"lora\"]\n",
    "    if epochs is not None and \"epochs\" in cand.columns: cand = cand[cand[\"epochs\"] == epochs]\n",
    "    if seed is not None and \"seed\" in cand.columns: cand = cand[cand[\"seed\"] == seed]\n",
    "    if len(cand) and \"lora_alpha\" in cand.columns and cand[\"lora_alpha\"].notna().any():\n",
    "        lora_alpha = int(cand.loc[cand[\"lora_alpha\"].notna(), \"lora_alpha\"].iloc[0])\n",
    "if lora_alpha is None:\n",
    "    lora_alpha = int(r)\n",
    "    print(f\"[WARN] lora_alpha not found -> fallback lora_alpha=r={lora_alpha}\")\n",
    "\n",
    "lora_cfg = get_lora_config(backbone, r=r, lora_alpha=lora_alpha)\n",
    "\n",
    "# Build model (CPU)\n",
    "numerical_cols = [f\"num_{i}\" for i in range(len(NUMERICAL_FEATURES))]  # will adjust if sidecar differs\n",
    "model = NextEventPredictor(\n",
    "    embedding_size=pre[\"embedding_size\"],\n",
    "    categorical_cols=[\"activity\"],\n",
    "    categorical_sizes={\"activity\": vocab_size},\n",
    "    numerical_cols=numerical_cols,\n",
    "    categorical_targets=[\"next_activity\"],\n",
    "    numerical_targets=[\"next_remaining_time\", \"next_time_to_next_event\"],\n",
    "    padding_idx=pad_id,\n",
    "    strategy=\"sum\",\n",
    "    backbone_name=pre[\"name\"],\n",
    "    backbone_pretrained=True,\n",
    "    backbone_finetuning=lora_cfg,\n",
    "    backbone_type=None,\n",
    "    backbone_hidden_size=pre[\"hidden_size\"],\n",
    "    backbone_n_layers=None,\n",
    "    device=DEVICE,\n",
    ").to(DEVICE)\n",
    "\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "# dtype downcast on CPU if possible\n",
    "try:\n",
    "    model = model.to(dtype=DTYPE)\n",
    "except Exception as e:\n",
    "    print(\"[WARN] Could not cast model dtype:\", repr(e))\n",
    "model.eval()\n",
    "\n",
    "# -------------------------\n",
    "# 2) Get test data with minimal overhead:\n",
    "#    (a) sidecar cache tensors if they exist\n",
    "#    (b) else rebuild test split like training\n",
    "# -------------------------\n",
    "bundle = try_load_sidecar_cache(CACHE_DIR)\n",
    "if bundle is not None:\n",
    "    print(\"[OK] Using sidecar cache from:\", str(CACHE_DIR))\n",
    "    traces = bundle[\"traces\"]\n",
    "    cat_features = bundle[\"cat_features\"]\n",
    "    num_features = bundle[\"num_features\"]\n",
    "    cat_targets = bundle[\"cat_targets\"]\n",
    "    # num_targets = bundle[\"num_targets\"]\n",
    "\n",
    "    # trace indices tensor for one example\n",
    "    tr = traces[TRACE_IDX]\n",
    "    tr = tr if torch.is_tensor(tr) else torch.tensor(tr, dtype=torch.long)\n",
    "\n",
    "    x_cat = cat_features[tr]     # [T, Ccat]\n",
    "    x_num = num_features[tr]     # [T, Cnum]\n",
    "    y_cat = cat_targets[tr]      # [T, Ccat_tgt]\n",
    "\n",
    "    # adjust numerical cols to true dim\n",
    "    if x_num.shape[1] != len(numerical_cols):\n",
    "        numerical_cols = [f\"num_{i}\" for i in range(int(x_num.shape[1]))]\n",
    "        print(f\"[WARN] num dim from cache = {x_num.shape[1]} -> rebuilding model numerical_cols is required for strictness.\")\n",
    "        # For minimal hassle: we proceed anyway (many implementations only use lengths).\n",
    "else:\n",
    "    print(\"[WARN] No sidecar cache found. Rebuilding test split (slower, but works).\")\n",
    "    raw_log = BPI12()\n",
    "    train_df, test_df = prepare_data_like_training(raw_log.dataframe, raw_log.unbiased_split_params)\n",
    "\n",
    "    event_features = EventFeatures(categorical=[\"activity\"], numerical=NUMERICAL_FEATURES)\n",
    "    event_targets = EventTargets(categorical=[\"activity\"], numerical=[\"remaining_time\",\"time_to_next_event\"])\n",
    "\n",
    "    # use checkpoint vocabs to align IDs\n",
    "    vocabs = (stoi, itos)\n",
    "    train_log = EventLog(\n",
    "        dataframe=train_df, case_id=\"case_id\",\n",
    "        features=event_features, targets=event_targets,\n",
    "        train_split=True, name=log_name, vocabs=vocabs\n",
    "    )\n",
    "    test_log = EventLog(\n",
    "        dataframe=test_df, case_id=\"case_id\",\n",
    "        features=event_features, targets=event_targets,\n",
    "        train_split=False, name=log_name, vocabs=train_log.get_vocabs()\n",
    "    )\n",
    "    test_dataset = ContinuousTraces(log=test_log, refresh_cache=True, device=\"cpu\")\n",
    "    x_cat, x_num, y_cat, _ = test_dataset[TRACE_IDX]\n",
    "\n",
    "# -------------------------\n",
    "# 3) A) Minimal trace visualization: Prefix -> Top-k Next Activity\n",
    "# -------------------------\n",
    "T = int(x_cat.shape[0])\n",
    "if PREFIX_LEN < 2 or PREFIX_LEN > T:\n",
    "    PREFIX_LEN = min(max(2, PREFIX_LEN), T)\n",
    "\n",
    "# batchify + dtype\n",
    "x_cat_b = x_cat[:PREFIX_LEN].unsqueeze(0).to(DEVICE)\n",
    "x_num_b = x_num[:PREFIX_LEN].unsqueeze(0).to(DEVICE)\n",
    "if x_num_b.dtype != DTYPE:\n",
    "    try:\n",
    "        x_num_b = x_num_b.to(dtype=DTYPE)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "with torch.inference_mode():\n",
    "    logits = forward_next_activity_logits(model, x_cat_b, x_num_b, pad_id=pad_id)  # [1,L,V]\n",
    "    logits_last = logits[0, PREFIX_LEN - 1].detach().cpu().float().numpy()\n",
    "\n",
    "# remove PAD/UNK for display\n",
    "logits_last[[pad_id, unk_id]] = -1e9\n",
    "probs = softmax_np(logits_last)\n",
    "top_ids = np.argsort(probs)[::-1][:TOPK].astype(int)\n",
    "top_probs = probs[top_ids]\n",
    "top_names = [str(itos_act.get(i, i)) for i in top_ids]\n",
    "\n",
    "true_next_id = int(y_cat[PREFIX_LEN - 1, 0].item())\n",
    "true_next_name = str(itos_act.get(true_next_id, true_next_id))\n",
    "\n",
    "prefix_ids = x_cat[:PREFIX_LEN, 0].detach().cpu().numpy().astype(int).tolist()\n",
    "prefix_names = [str(itos_act.get(i, i)) for i in prefix_ids]\n",
    "\n",
    "print(\"\\nPREFIX:\")\n",
    "print(\" -> \".join(prefix_names))\n",
    "print(\"True next:\", true_next_name)\n",
    "print(\"Pred top-1:\", top_names[0], f\"(p={top_probs[0]:.3f})\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, max(3, 0.35 * TOPK)))\n",
    "ax.barh(range(len(top_ids))[::-1], top_probs)\n",
    "ax.set_yticks(range(len(top_ids))[::-1])\n",
    "ax.set_yticklabels(top_names)\n",
    "ax.set_xlabel(\"Probability\")\n",
    "ax.set_title(f\"{log_name} | {backbone} | Prefix L={PREFIX_LEN} | Top-{TOPK}\\nTrue next: {true_next_name}\")\n",
    "ax.grid(True, axis=\"x\", linewidth=0.5, alpha=0.4)\n",
    "plt.tight_layout()\n",
    "\n",
    "out_topk = SAVE_DIR / f\"trace{TRACE_IDX}_prefixL{PREFIX_LEN}_top{TOPK}_{backbone}_cpu.png\"\n",
    "plt.savefig(out_topk, dpi=300)\n",
    "plt.close(fig)\n",
    "print(\"Saved:\", out_topk)\n",
    "\n",
    "# Teacher-forced suffix table (cheap: re-use logits by running only once on a bit longer window)\n",
    "L2 = min(T, PREFIX_LEN + SUFFIX_STEPS)\n",
    "x_cat2 = x_cat[:L2].unsqueeze(0).to(DEVICE)\n",
    "x_num2 = x_num[:L2].unsqueeze(0).to(DEVICE)\n",
    "if x_num2.dtype != DTYPE:\n",
    "    try:\n",
    "        x_num2 = x_num2.to(dtype=DTYPE)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "with torch.inference_mode():\n",
    "    logits2 = forward_next_activity_logits(model, x_cat2, x_num2, pad_id=pad_id)[0].detach().cpu().float().numpy()  # [L2,V]\n",
    "\n",
    "rows = []\n",
    "t0 = PREFIX_LEN - 1\n",
    "for t in range(t0, L2):\n",
    "    lg = logits2[t].copy()\n",
    "    lg[[pad_id, unk_id]] = -1e9\n",
    "    pr = softmax_np(lg)\n",
    "    pred_id = int(np.argmax(pr))\n",
    "    rows.append({\n",
    "        \"step_ahead\": t - t0 + 1,\n",
    "        \"obs_activity\": str(itos_act.get(int(x_cat[t,0].item()), \"\")),\n",
    "        \"true_next\": str(itos_act.get(int(y_cat[t,0].item()), \"\")),\n",
    "        \"pred_next\": str(itos_act.get(pred_id, pred_id)),\n",
    "        \"p_pred\": float(pr[pred_id]),\n",
    "        \"correct\": int(pred_id == int(y_cat[t,0].item())),\n",
    "    })\n",
    "\n",
    "df_suffix = pd.DataFrame(rows)\n",
    "out_csv = SAVE_DIR / f\"trace{TRACE_IDX}_prefixL{PREFIX_LEN}_suffix_{backbone}_cpu.csv\"\n",
    "df_suffix.to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv)\n",
    "display(df_suffix)\n",
    "\n",
    "# -------------------------\n",
    "# 4) B) Confusion matrix light (sampling, max context window)\n",
    "# -------------------------\n",
    "if DO_CONFUSION_MATRIX:\n",
    "    print(\"\\n[CM-light] sampling next-step predictions...\")\n",
    "    rng = random.Random(SEED)\n",
    "\n",
    "    # Need access to multiple traces. If we used sidecar cache, use bundle traces.\n",
    "    if bundle is None:\n",
    "        # from rebuilt dataset\n",
    "        traces_all = test_dataset.traces\n",
    "        cat_features_all = test_dataset.cat_features\n",
    "        num_features_all = test_dataset.num_features\n",
    "        cat_targets_all = test_dataset.cat_targets\n",
    "    else:\n",
    "        traces_all = bundle[\"traces\"]\n",
    "        cat_features_all = bundle[\"cat_features\"]\n",
    "        num_features_all = bundle[\"num_features\"]\n",
    "        cat_targets_all = bundle[\"cat_targets\"]\n",
    "\n",
    "    y_true_list, y_pred_list = [], []\n",
    "\n",
    "    # Small batching for speed on CPU\n",
    "    BATCH = 6\n",
    "\n",
    "    def sample_one():\n",
    "        tr = traces_all[rng.randrange(len(traces_all))]\n",
    "        tr = tr if torch.is_tensor(tr) else torch.tensor(tr, dtype=torch.long)\n",
    "        if tr.numel() < 3:\n",
    "            return None\n",
    "        # choose a prediction position t (predict next at t)\n",
    "        Tloc = int(tr.numel())\n",
    "        t = rng.randrange(1, Tloc)  # t indexes label position in y_cat\n",
    "        # context window: last MAX_CTX events up to t inclusive (model predicts y at t using prefix ending at t)\n",
    "        start = max(0, (t + 1) - MAX_CTX)\n",
    "        tr_ctx = tr[start:t+1]\n",
    "        x_cat = cat_features_all[tr_ctx]\n",
    "        x_num = num_features_all[tr_ctx]\n",
    "        y_true = int(cat_targets_all[tr[t], 0] if torch.is_tensor(cat_targets_all) else cat_targets_all[tr[t]][0])\n",
    "        return x_cat, x_num, y_true\n",
    "\n",
    "    batch_cat, batch_num, batch_true = [], [], []\n",
    "    for _ in range(N_SAMPLES):\n",
    "        s = sample_one()\n",
    "        if s is None:\n",
    "            continue\n",
    "        xc, xn, yt = s\n",
    "        batch_cat.append(xc)\n",
    "        batch_num.append(xn)\n",
    "        batch_true.append(yt)\n",
    "\n",
    "        if len(batch_cat) >= BATCH:\n",
    "            # pad to same length\n",
    "            lens = [x.shape[0] for x in batch_cat]\n",
    "            Lm = max(lens)\n",
    "            Cc = batch_cat[0].shape[1]\n",
    "            Cn = batch_num[0].shape[1]\n",
    "\n",
    "            xcat = torch.full((len(batch_cat), Lm, Cc), pad_id, dtype=torch.long)\n",
    "            xnum = torch.zeros((len(batch_cat), Lm, Cn), dtype=torch.float32)\n",
    "\n",
    "            for i,(xc,xn) in enumerate(zip(batch_cat, batch_num)):\n",
    "                L = xc.shape[0]\n",
    "                xcat[i,:L,:] = xc\n",
    "                xnum[i,:L,:] = xn\n",
    "\n",
    "            xcat = xcat.to(DEVICE)\n",
    "            xnum = xnum.to(DEVICE)\n",
    "            if xnum.dtype != DTYPE:\n",
    "                try:\n",
    "                    xnum = xnum.to(dtype=DTYPE)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                logits = forward_next_activity_logits(model, xcat, xnum, pad_id=pad_id)  # [B,L,V]\n",
    "                # take last position per sample (length-1)\n",
    "                pred_ids = []\n",
    "                for i,L in enumerate(lens):\n",
    "                    lg = logits[i, L-1].detach().cpu().float().numpy()\n",
    "                    lg[[pad_id, unk_id]] = -1e9\n",
    "                    pred_ids.append(int(np.argmax(lg)))\n",
    "            y_pred_list.extend(pred_ids)\n",
    "            y_true_list.extend(batch_true)\n",
    "\n",
    "            batch_cat, batch_num, batch_true = [], [], []\n",
    "\n",
    "    # flush remaining\n",
    "    if len(batch_cat):\n",
    "        lens = [x.shape[0] for x in batch_cat]\n",
    "        Lm = max(lens)\n",
    "        Cc = batch_cat[0].shape[1]\n",
    "        Cn = batch_num[0].shape[1]\n",
    "        xcat = torch.full((len(batch_cat), Lm, Cc), pad_id, dtype=torch.long)\n",
    "        xnum = torch.zeros((len(batch_cat), Lm, Cn), dtype=torch.float32)\n",
    "        for i,(xc,xn) in enumerate(zip(batch_cat, batch_num)):\n",
    "            L = xc.shape[0]\n",
    "            xcat[i,:L,:] = xc\n",
    "            xnum[i,:L,:] = xn\n",
    "        xcat = xcat.to(DEVICE)\n",
    "        xnum = xnum.to(DEVICE)\n",
    "        if xnum.dtype != DTYPE:\n",
    "            try:\n",
    "                xnum = xnum.to(dtype=DTYPE)\n",
    "            except Exception:\n",
    "                pass\n",
    "        with torch.inference_mode():\n",
    "            logits = forward_next_activity_logits(model, xcat, xnum, pad_id=pad_id)\n",
    "            pred_ids = []\n",
    "            for i,L in enumerate(lens):\n",
    "                lg = logits[i, L-1].detach().cpu().float().numpy()\n",
    "                lg[[pad_id, unk_id]] = -1e9\n",
    "                pred_ids.append(int(np.argmax(lg)))\n",
    "        y_pred_list.extend(pred_ids)\n",
    "        y_true_list.extend(batch_true)\n",
    "\n",
    "    y_true_arr = np.array(y_true_list, dtype=int)\n",
    "    y_pred_arr = np.array(y_pred_list, dtype=int)\n",
    "\n",
    "    # filter specials from y_true\n",
    "    keep = ~np.isin(y_true_arr, [pad_id, unk_id])\n",
    "    y_true_arr = y_true_arr[keep]\n",
    "    y_pred_arr = y_pred_arr[keep]\n",
    "\n",
    "    acc = float((y_true_arr == y_pred_arr).mean()) if len(y_true_arr) else float(\"nan\")\n",
    "    print(f\"[CM-light] samples={len(y_true_arr)} | approx acc={acc:.4f}\")\n",
    "\n",
    "    # Top-N classes + OTHER for readability\n",
    "    uniq, cnt = np.unique(y_true_arr, return_counts=True)\n",
    "    order = np.argsort(cnt)[::-1]\n",
    "    top = uniq[order][:TOP_CLASSES_CM]\n",
    "    OTHER = -999999\n",
    "\n",
    "    def map_other(a):\n",
    "        out = a.copy()\n",
    "        out[~np.isin(out, top)] = OTHER\n",
    "        return out\n",
    "\n",
    "    yt = map_other(y_true_arr)\n",
    "    yp = map_other(y_pred_arr)\n",
    "    labels = list(top) + [OTHER]\n",
    "    names = [str(itos_act.get(int(i), i)) for i in top] + [\"OTHER\"]\n",
    "\n",
    "    # confusion matrix (row-normalized)\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(yt, yp, labels=labels)\n",
    "    cmn = cm.astype(float) / np.maximum(cm.sum(axis=1, keepdims=True), 1.0)\n",
    "\n",
    "    fig_w = max(8, 0.35 * len(labels))\n",
    "    fig_h = max(7, 0.35 * len(labels))\n",
    "    fig, ax = plt.subplots(figsize=(fig_w, fig_h))\n",
    "    sns.heatmap(cmn, square=True, cbar=True, xticklabels=names, yticklabels=names, linewidths=0.2, linecolor=\"white\", ax=ax)\n",
    "    ax.set_xlabel(\"Predicted next activity\")\n",
    "    ax.set_ylabel(\"True next activity\")\n",
    "    ax.set_title(f\"{log_name} | {backbone} | CM-light (N={len(y_true_arr)}, ctx<= {MAX_CTX})\\nrow-normalized, approx acc={acc:.4f}\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    out_cm = SAVE_DIR / f\"cm_light_{log_name}_{backbone}_N{len(y_true_arr)}_ctx{MAX_CTX}_cpu.png\"\n",
    "    plt.savefig(out_cm, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(\"Saved:\", out_cm)\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "llm-peft-ppm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
